{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelemiko1/effect_chain_recognition/blob/main/5_def_5effects_preprocessing_and_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiWHk0Bf3GAd"
      },
      "outputs": [],
      "source": [
        "# version of tensorflow used in this project\n",
        "!pip install tensorflow==2.7\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "# GPU used\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU82EJi5wLr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff8ebc6-bf88-4f52-f718-f8e12ba17e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.64 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "# RAM ho much\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.2f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IJMQioSJxk0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import gc\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeHyOSlmMdwQ"
      },
      "outputs": [],
      "source": [
        "# constant values\n",
        "SEGMENT_SECONDS = 2\n",
        "SAMPLING_RATE = 22050\n",
        "NUMBER_OF_SEGMENTS = 5\n",
        "SEGMENT_LENGTH = SAMPLING_RATE * SEGMENT_SECONDS  # 44100\n",
        "\n",
        "# dataset path\n",
        "DATASET_PATH_DIVIDED = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/proc_4_guit_5_eff_divided'\n",
        "\n",
        "# old paths\n",
        "#JSON_PATH = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5effects_div.json'\n",
        "#JSON_PATH_RED = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5effects_reduced.json'\n",
        "#PICKLE_PATH_ENTIRE = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5eff_entire.pickle'\n",
        "#PICKLE_PATH_ENTIRE_NAMES = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5eff_entire_names.pickle'\n",
        "\n",
        "# dataset with 4 guitars\n",
        "#PICKLE_PATH_ENTIRE_NAMES_SEGM = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5eff_entire_names_seg.pickle'  # only names\n",
        "PICKLE_PATH_ENTIRE_NAMES = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5eff_entire_names.pickle'\n",
        "PICKLE_PATH_40_PERCENT = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5eff_40_percent_names.pickle'\n",
        "\n",
        "# 3 guitars + 1 guitar divided (reduced 40%)\n",
        "PICKLE_PATH_NO_STRAT_RED = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/data_no_strat_red.pickle' \n",
        "PICKLE_PATH_STRAT_RED = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/data_strat_red.pickle'\n",
        "\n",
        "# 3 guitars + 1 guitar divided (entire)\n",
        "PICKLE_PATH_NO_STRAT_ENTIRE = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/data_no_strat_entire.pickle' \n",
        "PICKLE_PATH_STRAT_ENTIRE = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/data_strat_entire.pickle'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KtI3NNw6HmR"
      },
      "source": [
        "PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAEzMJpPOTES"
      },
      "outputs": [],
      "source": [
        "# verify dataset 5 folders each with 2560 audio files\n",
        "tele_count = 0\n",
        "strat_count = 0\n",
        "prs_count = 0\n",
        "les_count = 0\n",
        "\n",
        "\n",
        "for i, (path, folders, files) in enumerate(os.walk(DATASET_PATH_DIVIDED)):\n",
        "  \n",
        "  if path is not DATASET_PATH_DIVIDED:\n",
        "    print(i, end = \") \")\n",
        "    print(\"path:\", path)\n",
        "    # print(\"folders:\", folders)\n",
        "    print(\"len files:\", len(files), end=\"\\n\\n\")\n",
        "\n",
        "    for name in files:\n",
        "      if \"tele\" in name:\n",
        "        tele_count += 1\n",
        "      if \"strat\" in name:\n",
        "        strat_count += 1\n",
        "      if \"prs\" in name:\n",
        "        prs_count += 1\n",
        "      if \"les\" in name:\n",
        "        les_count += 1\n",
        "\n",
        "print(\"tele:\", tele_count)\n",
        "print(\"strato:\", strat_count)\n",
        "print(\"prs:\", prs_count)\n",
        "print(\"les:\", les_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D20aHbfYNQYf"
      },
      "outputs": [],
      "source": [
        "# functions for preprocessing\n",
        "def get_LIST_plugins(file_name):\n",
        "    \"\"\"returns the list of plugins associated to a specific audio file\n",
        "    ex: les_bridge_fing01__01101.wav returns [0, 1, 1, 0, 1]\"\"\"\n",
        "\n",
        "    # get only the string associated to plugin values es: '01101'\n",
        "    file_name_part = file_name[-9: -4]\n",
        "    list_plugins = []\n",
        "\n",
        "    # print(\"file_name:\", file_name)\n",
        "    \n",
        "    for number in file_name_part:\n",
        "        if number == '0':\n",
        "            list_plugins.append(0)\n",
        "        if number == '1':\n",
        "            list_plugins.append(1)\n",
        "\n",
        "    # print(\"list plugins:\", list_plugins)\n",
        "    return list_plugins\n",
        "\n",
        "    \n",
        "# save file in uniqe file\n",
        "# - json -> can be stored (24 GB) but not enough memory to be loaded later (for CNN)\n",
        "# - pickle -> can be stored (6 GB) and can be loaded \n",
        "\n",
        "def prepare_dataset(dataset_path, pickle_path):\n",
        "    \"\"\"saves mel-spectrogram and label for each audio file (segment)\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"names\":[],\n",
        "        \"spectrogram\": [],  # [ spec1, spec2, spec3, ...]\n",
        "        \"labels\": []        # [ [0,0,0,1,0], [0,1,0,1,1], [1,1,1,0,0], ...]\n",
        "    }\n",
        "\n",
        "    # data_strat = {\n",
        "    #     \"names\":[],\n",
        "    #     \"spectrogram\": [],  # [ spec1, spec2, spec3, ...]\n",
        "    #     \"labels\": []        # [ [0,0,0,1,0], [0,1,0,1,1], [1,1,1,0,0], ...]\n",
        "    # }\n",
        "    files_count = 0\n",
        "\n",
        "    count = 0\n",
        "    for i, (path, folders, files) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # path = G:\\tesi_4maggio_22\\dataset_michele\\multilabel\\processed_4guitars\n",
        "        # folders = []\n",
        "        # files = ['les_bridge_fing01__000.wav', ..., 'les_bridge_fing01__011.wav'], (tot: 3200)\n",
        "\n",
        "        condition = True\n",
        "        if path is not dataset_path:\n",
        "\n",
        "            print(\"path:\", path)\n",
        "            print(\"folders:\", folders)\n",
        "            print(\"len files:\", len(files))\n",
        "            print(\"file example:\", files[:3], end=\"\\n\\n\")\n",
        "\n",
        "            for file_name in files:\n",
        "                if condition:\n",
        "\n",
        "                    if count % 100 == 0:\n",
        "                        print(\"count:\", count)\n",
        "\n",
        "                    file_path = os.path.join(path, file_name)  # get the entire path\n",
        "                    audio_file, sr = librosa.load(file_path, sr=SAMPLING_RATE)  # load audio file                    \n",
        "                    y = get_LIST_plugins(file_name)  # get the current label\n",
        "      \n",
        "                    # divide the signal in segments and store\n",
        "                    for segment_index in range(NUMBER_OF_SEGMENTS):\n",
        "\n",
        "                        # divide signal into segments\n",
        "                        segment_start = segment_index * SEGMENT_LENGTH\n",
        "                        current_segment = audio_file[segment_start:segment_start + SEGMENT_LENGTH]\n",
        "\n",
        "                        # get the mel spectrogram\n",
        "                        mel_spectrogram = librosa.feature.melspectrogram(y=current_segment, sr=SAMPLING_RATE, n_fft=2048,\n",
        "                                                                         hop_length=512, n_mels=128)\n",
        "                        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
        "                        log_mel_spectrogram = log_mel_spectrogram.T\n",
        "\n",
        "                        # save data      \n",
        "                        current_name = file_name[:-4] + f'__segm{segment_index + 1}'             \n",
        "                        data[\"spectrogram\"].append(log_mel_spectrogram.tolist())\n",
        "                        data[\"labels\"].append(y)\n",
        "                        data[\"names\"].append(current_name)\n",
        "\n",
        "                    count +=1\n",
        "\n",
        "    with open(pickle_path, \"wb\") as fb:\n",
        "        pickle.dump(data, fb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3YOs1ybnmhc"
      },
      "outputs": [],
      "source": [
        "# perform preprocessing on 12800 files\n",
        "prepare_dataset(DATASET_PATH_DIVIDED, PICKLE_PATH_ENTIRE_NAMES_SEGM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGN_rcFom_SS"
      },
      "source": [
        "CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6dKltF6nB9E"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import librosa.display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCecjSq_2Bjb"
      },
      "outputs": [],
      "source": [
        "PICKLE_PATH_ENTIRE_NAMES = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5eff_entire_names.pickle'\n",
        "\n",
        "# functions for loading json files and pickle files\n",
        "def load_data(data_path):\n",
        "  with open(data_path, \"r\") as fp:\n",
        "      data = json.load(fp)\n",
        "  return data\n",
        "\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPHeRiYUBh-b"
      },
      "outputs": [],
      "source": [
        "data_complete = load_data_pickle(PICKLE_PATH_ENTIRE_NAMES)  # 2 GB -> 32 GB RAM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting 6 random mel spectrograms\n",
        "dataset_length = len(data_complete[\"labels\"])\n",
        "\n",
        "indeces = np.random.randint(dataset_length, size=6)  # ex. [ 9467 43814 58297  3831 29183 55152]\n",
        "print(\"indeces:\", indeces)\n",
        "\n",
        "spectrograms = []\n",
        "labels = []\n",
        "\n",
        "# save names and spectrograms (transposing them)\n",
        "for index in indeces:\n",
        "  spectrogram = np.array(data_complete[\"spectrogram\"][index]).T\n",
        "  spectrograms.append(spectrogram)\n",
        "\n",
        "  label = data_complete[\"names\"][index]\n",
        "  labels.append(label)\n",
        "\n",
        "# position of each spectrgram in the figure\n",
        "index_config = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)] \n",
        "\n",
        "# plot the spectrograms\n",
        "fig, ax = plt.subplots(2, 3, figsize=(18, 8))\n",
        "for i in range(6):\n",
        "  img = librosa.display.specshow(spectrograms[i], y_axis='mel', sr=22050, fmax=11050, ax=ax[index_config[i]])\n",
        "  #img = librosa.display.specshow(spectrograms[i] - np.max(spectrograms[i]), y_axis='mel', sr=22050, fmax=11050, ax=ax[index_config[i]]) max=0db\n",
        "  ax[index_config[i]].set(title=labels[i])\n",
        "\n",
        "ax[1, 0].set_xlabel(\"Time\")\n",
        "ax[1, 1].set_xlabel(\"Time\")\n",
        "ax[1, 2].set_xlabel(\"Time\")\n",
        "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "Sq_pWvi5juw8",
        "outputId": "6dac6956-06c1-4144-c000-57f7280af249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indeces: [59748 43783 12586 43455 45126  2798]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x576 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdIbh-mObNzO",
        "outputId": "d7a7f3b4-79bd-4e7e-ed35-1f2a9f07554f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000 16000 16000 16000\n",
            "les_bridge_pick24__11010__segm4\n",
            "les_neck_fing02__11011__segm1\n",
            "les_neck_fing18__11000__segm1\n",
            "les_bridge_pick24__11000__segm1\n",
            "les_bridge_fing03__11000__segm5\n"
          ]
        }
      ],
      "source": [
        "# verify some information about the dataset\n",
        "def verify_correct_loading(data):\n",
        "  st = 0\n",
        "  le = 0\n",
        "  te = 0\n",
        "  pr = 0\n",
        "\n",
        "  count = 0\n",
        "  for name in data['names']:\n",
        "    if name[:4] == 'stra':\n",
        "      st += 1\n",
        "    if name[:3] == 'les':\n",
        "      le += 1\n",
        "    if name[:4] == 'tele':\n",
        "      te += 1      \n",
        "    if name[:3] == 'prs':\n",
        "      pr += 1\n",
        "\n",
        "  print(st, le, te, pr)\n",
        "\n",
        "  # print some names\n",
        "  for i in (13, 500, 3045, 0, 10444):\n",
        "    print(data_complete['names'][i])\n",
        "\n",
        "\n",
        "verify_correct_loading(data_complete)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ebT10KVQSx",
        "outputId": "914668b6-2c64-4b36-fd58-ff05017600f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of data is: <class 'dict'>\n",
            "dictionary keys of dict are: dict_keys(['names', 'spectrogram', 'labels'])\n",
            "shape of data['spectrogram'] is: (64000, 87, 128)\n",
            "shape of data['labels'] is: (64000, 5)\n",
            "len of data['spectrogram'] is: 64000\n",
            "len of data['labels'] is: 64000\n",
            "type of data['spectrogram'] is: <class 'list'>\n",
            "type of data['labels'] is: <class 'list'>\n",
            "one element in data['names'] is: les_bridge_pick24__11010__segm3\n",
            "one element in data['spectrogram'] is: [[-4.280602931976318, -9.118806838989258, -9.27226448059082, -9.072574615478516, -8.627758979797363, -8.817724227905273, -2.351947784423828, 3.921657085418701, -5.533413887023926, -10.006413459777832, -8.371846199035645, -7.9540205001831055, -6.800868034362793, -5.733122825622559, 9.803675651550293, 12.129571914672852, 10.709514617919922, 5.979294776916504, -13.135383605957031, -5.435576915740967, 0.015465700067579746, 10.090171813964844, 13.958792686462402, 8.89465618133545, 6.815079689025879, 5.139479637145996, 0.03044469654560089, -5.957197189331055, -10.276540756225586, -1.1891037225723267, 0.32916978001594543, -4.265902042388916, -1.6152905225753784, -0.6179795265197754, 3.867910861968994, -0.2573009729385376, -2.3832364082336426, -0.3845070004463196, 0.06846533715724945, -1.959829330444336, 2.5766172409057617, 4.3515801429748535, 1.546139121055603, -9.864166259765625, -1.5950288772583008, -0.2736227512359619, -12.112876892089844, -18.6601619720459, -12.692863464355469, -14.283499717712402, -8.148541450500488, -9.925650596618652, -21.037843704223633, -15.053738594055176, -11.232810020446777, -11.977632522583008, -12.065549850463867, -25.64628791809082, -20.190885543823242, -14.360626220703125, -13.924093246459961, -19.53537368774414, -23.13058090209961, -14.912609100341797, -19.569868087768555, -30.469331741333008, -23.93956184387207, -11.612462043762207, -21.127784729003906, -22.895620346069336, -17.063955307006836, -16.243087768554688, -21.245697021484375, -26.984622955322266, -20.777164459228516, -26.39962387084961, -25.591392517089844, -32.35804748535156, -31.95317840576172, -28.578813552856445, -30.565683364868164, -33.266639709472656, -28.990249633789062, -30.968496322631836, -30.702877044677734, -26.608905792236328, -33.67634201049805, -31.169429779052734, -37.9654655456543, -32.358943939208984, -32.53583908081055, -37.35041427612305, -37.35309982299805, -41.642799377441406, -41.5764274597168, -37.11125564575195, -38.734275817871094, -38.459190368652344, -40.416664123535156, -40.75718307495117, -42.80268859863281, -42.522891998291016, -45.1234130859375, -46.301551818847656, -45.158443450927734, -45.41278076171875, -48.79184341430664, -49.06175994873047, -46.575347900390625, -49.099761962890625, -52.53665542602539, -49.51593780517578, -50.733028411865234, -53.33924102783203, -51.74909591674805, -51.52644348144531, -54.6077766418457, -53.21775817871094, -53.60057830810547, -55.16258239746094, -53.726844787597656, -55.080718994140625, -54.87974548339844, -54.99348068237305, -55.612770080566406, -55.28254699707031, -55.48784255981445, -55.532806396484375], [-7.935369491577148, -15.141444206237793, -15.28232192993164, -15.061240196228027, -14.659266471862793, -14.40422534942627, -4.403044700622559, 1.8467437028884888, -0.49287471175193787, -13.84311580657959, -14.198253631591797, -14.0614595413208, -12.710474967956543, -11.269564628601074, 5.93379020690918, 8.38461971282959, 10.65135383605957, 3.2962565422058105, -15.847803115844727, -11.115196228027344, -5.657346248626709, 6.151801109313965, 14.690885543823242, 8.614935874938965, 9.910280227661133, 8.595067024230957, -6.281955242156982, -11.967523574829102, -15.617527961730957, 1.2915903329849243, 5.486941337585449, -5.13779354095459, -0.08992654085159302, 2.586102247238159, 0.872342050075531, -6.349639415740967, -8.570955276489258, -5.616663932800293, -5.125985145568848, -7.937192440032959, -1.5342808961868286, 4.611498832702637, 0.24406327307224274, -12.851357460021973, -1.5561820268630981, -1.6525084972381592, -16.357044219970703, -15.45849895477295, -6.66935396194458, -11.412113189697266, -3.186056137084961, -6.695250988006592, -27.15320587158203, -17.37279510498047, -13.958858489990234, -15.673236846923828, -16.397796630859375, -31.295711517333984, -20.26714515686035, -16.060806274414062, -16.10357093811035, -25.153730392456055, -25.193527221679688, -15.50930404663086, -16.517101287841797, -33.83951187133789, -22.74247932434082, -12.022305488586426, -20.79503631591797, -28.82461166381836, -17.717182159423828, -15.943671226501465, -24.74653434753418, -26.998929977416992, -22.22018051147461, -28.32554817199707, -26.333932876586914, -29.78683853149414, -35.11264419555664, -30.364599227905273, -30.988140106201172, -35.28497314453125, -28.7253360748291, -29.955810546875, -32.00897979736328, -27.807415008544922, -33.63254165649414, -31.273996353149414, -37.315101623535156, -33.00181579589844, -35.334869384765625, -36.94342041015625, -39.7261848449707, -40.74294662475586, -40.87520980834961, -37.765010833740234, -40.23432922363281, -39.1871452331543, -41.42548370361328, -41.987037658691406, -43.628379821777344, -44.550086975097656, -45.813987731933594, -47.9435920715332, -48.22189712524414, -48.33061981201172, -49.7590217590332, -49.8063850402832, -49.696922302246094, -51.589256286621094, -54.367679595947266, -53.796504974365234, -54.94731903076172, -56.70794677734375, -55.82059860229492, -56.103878021240234, -58.79819869995117, -58.38041305541992, -58.94020080566406, -60.43779754638672, -59.28984069824219, -60.566307067871094, -60.562164306640625, -60.84846115112305, -61.54719924926758, -61.283233642578125, -61.50699996948242, -61.553375244140625], [-7.577343940734863, -24.481430053710938, -35.91952896118164, -30.730188369750977, -26.209239959716797, -22.34841537475586, -2.690206527709961, 6.402146339416504, 4.568727016448975, -18.555036544799805, -24.97005844116211, -22.609586715698242, -17.634098052978516, -8.555426597595215, -2.3928050994873047, 1.3144044876098633, 5.676288604736328, -1.6275674104690552, -22.8568115234375, -18.238109588623047, -13.361038208007812, 0.8444401025772095, 11.444121360778809, 6.7546844482421875, 9.448783874511719, 8.777017593383789, -12.506447792053223, -21.07818603515625, -19.57714080810547, 1.8629424571990967, 6.332212448120117, -2.2268617153167725, 2.868534564971924, 9.354799270629883, 1.5724563598632812, -28.82244300842285, -20.4766845703125, -10.414735794067383, -8.91253662109375, -17.091575622558594, -5.749668121337891, 1.2400550842285156, -2.6258766651153564, -10.766605377197266, -5.487431526184082, -7.167010307312012, -20.157291412353516, -14.600963592529297, -6.966178894042969, -9.193146705627441, -5.124283790588379, -8.293682098388672, -32.8212776184082, -18.511276245117188, -13.96084976196289, -18.093156814575195, -20.521621704101562, -32.26865768432617, -22.26027488708496, -18.327743530273438, -18.97096824645996, -30.120319366455078, -27.05168914794922, -15.24798583984375, -17.514955520629883, -35.8174934387207, -22.207155227661133, -12.548028945922852, -19.583284378051758, -47.989341735839844, -18.779943466186523, -15.16664981842041, -27.81485366821289, -28.920597076416016, -25.010385513305664, -31.05025291442871, -27.934532165527344, -28.90763282775879, -39.35940170288086, -33.51740264892578, -30.674110412597656, -39.12662887573242, -29.017839431762695, -29.501420974731445, -33.146968841552734, -29.38442611694336, -35.497596740722656, -31.76753044128418, -37.26641082763672, -33.947444915771484, -37.636932373046875, -37.267948150634766, -40.700416564941406, -39.962581634521484, -41.21071243286133, -39.246646881103516, -42.586387634277344, -40.7951774597168, -43.70569610595703, -43.927391052246094, -45.176639556884766, -46.97554016113281, -47.767799377441406, -49.868560791015625, -50.66649627685547, -50.59883499145508, -51.002403259277344, -51.64500427246094, -53.471370697021484, -54.87919235229492, -56.97002410888672, -59.060760498046875, -59.63702392578125, -59.94518280029297, -60.540809631347656, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-9.520130157470703, -25.237672805786133, -35.54989242553711, -28.620588302612305, -25.680599212646484, -18.31652069091797, -4.661581039428711, 9.812061309814453, 8.794649124145508, -14.288153648376465, -23.423961639404297, -21.46153450012207, -16.984119415283203, -10.086956024169922, -4.735284805297852, -1.0011757612228394, 3.795938014984131, -2.0959906578063965, -21.92755699157715, -15.8599853515625, -11.55656623840332, -8.428545951843262, 1.9069085121154785, 1.619337797164917, 2.4386463165283203, 5.583462238311768, -4.922418594360352, -21.196191787719727, -20.657264709472656, -4.6245245933532715, -0.6419218182563782, -4.203076362609863, 3.39674711227417, 10.45120620727539, 3.1997249126434326, -22.890283584594727, -23.62179946899414, -16.203365325927734, -13.259109497070312, -20.141897201538086, -6.304476737976074, 5.01887321472168, 0.20184186100959778, -12.178802490234375, -9.44106674194336, -13.677301406860352, -22.479373931884766, -15.48333740234375, -7.142375946044922, -9.774412155151367, -15.792835235595703, -16.658809661865234, -32.073699951171875, -21.202470779418945, -15.553421974182129, -19.54740333557129, -25.86751937866211, -29.162282943725586, -21.733623504638672, -17.089998245239258, -22.425399780273438, -29.854331970214844, -27.987468719482422, -14.473709106445312, -18.91409683227539, -37.158748626708984, -25.072717666625977, -12.446722984313965, -17.309446334838867, -45.12482452392578, -21.06454086303711, -16.446935653686523, -28.293132781982422, -35.64999771118164, -28.442428588867188, -33.479530334472656, -34.162357330322266, -32.106101989746094, -38.651607513427734, -34.485374450683594, -29.572420120239258, -39.540191650390625, -30.047317504882812, -30.537120819091797, -35.24750518798828, -30.330703735351562, -37.9677734375, -31.968271255493164, -37.17333221435547, -35.04757308959961, -38.62311553955078, -39.277217864990234, -41.766632080078125, -40.3846321105957, -42.82158660888672, -40.69652557373047, -44.30507278442383, -42.294891357421875, -45.00436782836914, -45.07041549682617, -46.395973205566406, -49.39048767089844, -49.6800537109375, -51.25215148925781, -51.829505920410156, -51.633262634277344, -52.31948471069336, -53.54823303222656, -55.84584045410156, -57.46480941772461, -59.404605865478516, -61.04893112182617, -61.24812698364258, -61.453582763671875, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-13.456798553466797, -33.005149841308594, -41.78392028808594, -34.50978088378906, -33.339508056640625, -26.052204132080078, -11.505561828613281, 10.570076942443848, 10.94331169128418, -11.229377746582031, -34.36918258666992, -32.7254638671875, -29.812278747558594, -23.931608200073242, -18.2308349609375, 3.087480306625366, 11.033711433410645, 2.9717159271240234, -30.232763290405273, -23.974533081054688, -21.546741485595703, -21.83906364440918, -18.476539611816406, -11.547163009643555, 3.4016706943511963, 3.8781344890594482, -9.092347145080566, -28.18239974975586, -30.653759002685547, -24.012269973754883, -24.349775314331055, -20.36353874206543, -0.46783193945884705, 5.651674270629883, 1.95609712600708, -23.966384887695312, -34.86747360229492, -25.728797912597656, -29.095691680908203, -39.51298522949219, -8.274608612060547, 3.954939365386963, 1.1863319873809814, -19.19957733154297, -24.186132431030273, -28.12262535095215, -34.4088134765625, -15.93099594116211, -6.63707160949707, -10.510787010192871, -26.20541000366211, -32.7161750793457, -39.76414489746094, -26.79712677001953, -18.606172561645508, -23.049962997436523, -40.50322723388672, -36.5048713684082, -20.993267059326172, -15.217231750488281, -24.842126846313477, -41.93302536010742, -30.104944229125977, -14.066509246826172, -17.496549606323242, -43.935150146484375, -28.910043716430664, -12.863876342773438, -17.199975967407227, -46.789649963378906, -23.471805572509766, -18.560611724853516, -30.649555206298828, -39.65994644165039, -29.896116256713867, -35.71512222290039, -45.05754470825195, -34.543277740478516, -38.85502243041992, -35.53628158569336, -29.36414337158203, -39.32181930541992, -30.890188217163086, -31.221763610839844, -37.13984680175781, -30.832530975341797, -39.69472122192383, -32.057762145996094, -37.28600311279297, -36.493377685546875, -39.438838958740234, -40.993621826171875, -43.21541213989258, -41.35943603515625, -44.204437255859375, -41.87535095214844, -45.56039810180664, -43.13913345336914, -46.068328857421875, -45.6883659362793, -47.55213928222656, -50.94289779663086, -51.08056640625, -52.12566375732422, -53.12383270263672, -52.77294158935547, -53.76837158203125, -55.321842193603516, -57.96115493774414, -59.86671829223633, -61.508323669433594, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-11.03397274017334, -28.667680740356445, -36.91348648071289, -35.30919647216797, -33.46531677246094, -37.955955505371094, -10.929153442382812, 11.43455982208252, 11.894685745239258, -10.19095230102539, -36.753807067871094, -36.119422912597656, -35.045692443847656, -35.343074798583984, -26.2288761138916, 5.676167011260986, 14.583456039428711, 6.3996148109436035, -27.907888412475586, -35.37421798706055, -32.108482360839844, -32.34066390991211, -33.217140197753906, -18.01131248474121, 8.6073637008667, 7.523636817932129, -13.067336082458496, -31.609989166259766, -29.861757278442383, -25.20913314819336, -28.25060272216797, -30.503402709960938, -0.87828528881073, 6.395669460296631, 0.48203542828559875, -27.708341598510742, -30.4914493560791, -25.25087547302246, -27.729671478271484, -27.39657974243164, -11.534652709960938, -0.16177180409431458, 0.2665270268917084, -22.444122314453125, -39.640933990478516, -37.58842468261719, -41.35600280761719, -17.01472282409668, -8.661322593688965, -11.931175231933594, -33.40655517578125, -41.62049865722656, -43.890262603759766, -34.479148864746094, -22.575206756591797, -26.51776885986328, -38.638431549072266, -41.977142333984375, -21.686813354492188, -15.864171981811523, -26.019804000854492, -44.69975280761719, -33.29731750488281, -13.752827644348145, -16.888343811035156, -48.27206039428711, -31.872589111328125, -13.105512619018555, -17.301237106323242, -48.14483642578125, -25.619831085205078, -19.903209686279297, -32.980003356933594, -41.54330825805664, -29.48349380493164, -35.146942138671875, -45.88825225830078, -33.50753402709961, -38.9057502746582, -36.72223663330078, -29.600008010864258, -40.114891052246094, -31.81334686279297, -31.881914138793945, -38.29499053955078, -30.900367736816406, -40.411712646484375, -32.44914245605469, -37.61989974975586, -37.67953109741211, -40.15095138549805, -42.110992431640625, -43.942100524902344, -42.60451889038086, -45.61288833618164, -43.011173248291016, -46.84595489501953, -43.55106735229492, -47.142486572265625, -46.630767822265625, -48.72734451293945, -52.35680389404297, -52.12353515625, -53.04587936401367, -54.477630615234375, -54.141868591308594, -55.19573211669922, -57.34362030029297, -59.919315338134766, -61.6127815246582, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-7.949340343475342, -24.13723373413086, -31.38796043395996, -33.58064651489258, -29.297080993652344, -24.414968490600586, -8.937492370605469, 11.353278160095215, 11.443052291870117, -7.332911968231201, -24.502151489257812, -33.000762939453125, -28.686416625976562, -24.503461837768555, -19.35946273803711, 7.071371078491211, 15.593503952026367, 6.945662498474121, -21.115800857543945, -27.58892250061035, -22.316287994384766, -20.189592361450195, -20.751131057739258, -13.888106346130371, 11.013345718383789, 10.850377082824707, -11.002350807189941, -21.59145736694336, -15.686845779418945, -12.235245704650879, -11.97085189819336, -15.186073303222656, 1.852881908416748, 9.850452423095703, 2.2033541202545166, -22.215465545654297, -15.915099143981934, -10.854964256286621, -11.663778305053711, -12.90788459777832, -10.192442893981934, 2.405435085296631, 0.23856204748153687, -23.862529754638672, -30.15108871459961, -32.72871398925781, -30.41815757751465, -18.46268081665039, -7.705531120300293, -16.813013076782227, -24.266551971435547, -29.720855712890625, -38.559295654296875, -32.13103485107422, -21.83000946044922, -21.816923141479492, -24.268014907836914, -28.435747146606445, -22.062379837036133, -16.724546432495117, -27.676265716552734, -29.573381423950195, -31.7763614654541, -13.064055442810059, -16.326536178588867, -45.00495147705078, -32.91263961791992, -14.789865493774414, -18.82508659362793, -45.554351806640625, -27.30626106262207, -21.574554443359375, -33.16515350341797, -38.34600830078125, -28.795625686645508, -33.97246170043945, -40.870567321777344, -29.8946590423584, -35.214073181152344, -36.83293151855469, -31.560882568359375, -42.86616897583008, -33.258358001708984, -33.63539505004883, -39.021141052246094, -31.612184524536133, -41.65496826171875, -33.704986572265625, -38.82554626464844, -38.56521224975586, -40.20553970336914, -42.63740158081055, -43.86021041870117, -43.964927673339844, -46.81700134277344, -44.02806091308594, -48.147701263427734, -44.659976959228516, -48.72299575805664, -48.10205078125, -49.79549026489258, -53.18695068359375, -52.584503173828125, -53.94734191894531, -55.89485549926758, -55.848907470703125, -56.9300651550293, -59.479976654052734, -61.559242248535156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-9.703048706054688, -20.5992488861084, -28.82876968383789, -36.59580993652344, -30.204050064086914, -23.65995216369629, -7.313506603240967, 9.496925354003906, 8.104393005371094, -9.758537292480469, -20.67066192626953, -30.34478759765625, -30.007892608642578, -22.459457397460938, -9.394021034240723, 8.482975959777832, 14.341845512390137, 4.58778190612793, -16.574737548828125, -26.110336303710938, -21.387672424316406, -18.687397003173828, -15.718639373779297, 0.08593413978815079, 11.973428726196289, 9.688214302062988, -12.35286808013916, -19.235124588012695, -15.13501262664795, -11.999980926513672, -10.427371978759766, -8.738812446594238, 3.7999887466430664, 8.595194816589355, 1.3831870555877686, -17.748613357543945, -14.208795547485352, -9.816933631896973, -11.444621086120605, -9.3873929977417, -4.079618453979492, 0.48367348313331604, -1.3011012077331543, -23.11720848083496, -25.609485626220703, -28.558656692504883, -19.971420288085938, -9.245109558105469, -6.4395551681518555, -19.659500122070312, -22.267732620239258, -28.589513778686523, -23.52904510498047, -16.29706573486328, -20.339872360229492, -23.783565521240234, -23.987903594970703, -27.304582595825195, -16.716007232666016, -14.76211166381836, -31.038219451904297, -28.63626480102539, -22.736431121826172, -12.26540756225586, -16.819541931152344, -38.766395568847656, -22.980030059814453, -15.767483711242676, -20.79857063293457, -33.59242248535156, -23.272747039794922, -23.059673309326172, -33.554752349853516, -27.68777847290039, -27.88295555114746, -34.429718017578125, -29.88955307006836, -27.55672264099121, -33.34064865112305, -30.929763793945312, -32.76778030395508, -38.412986755371094, -31.534326553344727, -36.01755142211914, -35.91368103027344, -33.50162887573242, -41.02946853637695, -36.241859436035156, -41.33559799194336, -39.744773864746094, -41.382720947265625, -42.34009552001953, -43.586483001708984, -43.64054870605469, -45.297813415527344, -44.621559143066406, -47.14739990234375, -46.962852478027344, -49.47688293457031, -50.50982666015625, -51.09501266479492, -53.39036560058594, -53.69211196899414, -54.80453109741211, -56.93203353881836, -57.87205123901367, -59.27783966064453, -61.049861907958984, -61.977481842041016, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-6.204834461212158, -9.639628410339355, -19.209394454956055, -30.73749542236328, -22.61221694946289, -21.344783782958984, -3.097538471221924, 7.157177448272705, 4.592130661010742, 1.4890141487121582, -8.100868225097656, -20.0651912689209, -22.337142944335938, -20.012462615966797, -2.9057421684265137, 7.53786039352417, 9.50059986114502, 2.2619636058807373, 2.8846073150634766, -1.3048230409622192, -14.879940032958984, -16.68443489074707, -11.494322776794434, 4.093136787414551, 9.552719116210938, 3.215575695037842, -12.70780086517334, -6.478582382202148, -8.816112518310547, -13.79940414428711, -10.292407035827637, -4.354612350463867, 1.267467737197876, -0.47765567898750305, -6.200024604797363, -17.757883071899414, -16.672786712646484, -19.338228225708008, -20.12008285522461, -9.33607006072998, -0.7833424806594849, -0.8332127332687378, -4.924668312072754, -15.333596229553223, -19.803035736083984, -15.490995407104492, -12.034326553344727, -7.593747138977051, -8.41499137878418, -20.13078498840332, -25.014812469482422, -25.73365020751953, -13.287549018859863, -11.310041427612305, -17.954137802124023, -29.672073364257812, -32.215904235839844, -26.11118507385254, -15.443278312683105, -17.393882751464844, -29.596912384033203, -36.07072448730469, -22.376508712768555, -18.61159896850586, -24.261295318603516, -35.1351203918457, -22.01504898071289, -20.080413818359375, -22.389928817749023, -29.217212677001953, -23.26787567138672, -21.971389770507812, -22.732288360595703, -25.921958923339844, -30.037025451660156, -30.8991641998291, -27.095308303833008, -28.996688842773438, -33.62736892700195, -29.566957473754883, -33.529296875, -33.965980529785156, -31.250747680664062, -41.310977935791016, -32.51249313354492, -34.8274040222168, -38.97590637207031, -34.21527099609375, -41.587486267089844, -42.66310119628906, -43.49834442138672, -36.68095016479492, -36.926578521728516, -39.868587493896484, -37.772193908691406, -45.371788024902344, -44.272117614746094, -46.62004470825195, -49.62623977661133, -49.11669921875, -49.53950500488281, -46.33237838745117, -48.45487976074219, -48.48600769042969, -54.01857376098633, -54.85740661621094, -47.93611526489258, -51.69879150390625, -52.437461853027344, -57.363067626953125, -59.76518630981445, -60.719024658203125, -59.89400863647461, -57.432090759277344, -61.74695587158203, -61.988258361816406, -61.80733108520508, -61.5990104675293, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-1.4829884767532349, -6.310703754425049, -13.696207046508789, -26.590923309326172, -17.72273826599121, -16.783212661743164, -4.051299571990967, 1.1027454137802124, 8.250256538391113, 10.516524314880371, -2.290241003036499, -12.575122833251953, -16.728565216064453, -14.074625968933105, -4.39146089553833, -1.4106121063232422, 0.7262791395187378, 6.131935119628906, 10.748473167419434, 9.176470756530762, -3.746955633163452, -11.472541809082031, -7.4413628578186035, -1.674338459968567, -1.1057534217834473, -8.66130256652832, -9.64346981048584, -0.19064036011695862, -1.8805077075958252, -7.848199844360352, -6.299201011657715, -3.1415653228759766, -4.220076084136963, -18.95985984802246, -14.86302375793457, -14.723196029663086, -13.538774490356445, -16.95589828491211, -16.273862838745117, -7.857790946960449, -5.358805179595947, -5.489711761474609, -7.6912384033203125, -11.835951805114746, -20.185338973999023, -11.682547569274902, -6.4300642013549805, -7.618588447570801, -8.062231063842773, -16.70956802368164, -25.788070678710938, -22.751771926879883, -8.524744033813477, -7.355363368988037, -9.784590721130371, -11.955717086791992, -25.35419464111328, -23.922832489013672, -12.593387603759766, -13.096480369567871, -13.770217895507812, -22.447336196899414, -30.638370513916016, -20.369741439819336, -21.644996643066406, -27.63922691345215, -27.294912338256836, -17.39263343811035, -15.79786491394043, -26.19696807861328, -27.999313354492188, -16.64198112487793, -15.775249481201172, -25.453277587890625, -23.769733428955078, -22.75730323791504, -27.012680053710938, -21.310808181762695, -24.278522491455078, -33.72770309448242, -27.17595863342285, -28.25498390197754, -29.59824562072754, -31.880435943603516, -27.998397827148438, -28.61163330078125, -32.75819778442383, -27.59658432006836, -35.30266571044922, -37.72836685180664, -36.95420837402344, -30.597278594970703, -29.97801971435547, -33.219974517822266, -30.10087776184082, -38.328712463378906, -35.74938201904297, -40.997093200683594, -41.60646438598633, -43.20305252075195, -42.202701568603516, -40.13896942138672, -40.65216064453125, -40.243797302246094, -44.14958953857422, -41.46277618408203, -40.672874450683594, -42.929588317871094, -44.68388366699219, -50.01557922363281, -53.296607971191406, -51.26893615722656, -50.42083740234375, -49.192813873291016, -50.49586486816406, -51.67428970336914, -53.64542007446289, -54.39329528808594, -56.21276092529297, -58.14462661743164, -58.576541900634766, -58.632057189941406, -59.7830924987793, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [4.211221218109131, -11.002745628356934, -12.684747695922852, -15.281643867492676, -15.43795394897461, -14.483447074890137, -2.2222790718078613, 1.2352147102355957, 5.668848991394043, 12.834917068481445, 5.641167640686035, -7.845062255859375, -9.197469711303711, -7.082283973693848, 3.9460835456848145, 2.8749749660491943, -4.59830379486084, 1.4240084886550903, 7.928637504577637, 10.831756591796875, 3.2127909660339355, -6.047165870666504, 1.624094843864441, 0.08956127613782883, -2.4852523803710938, -9.026708602905273, -12.116594314575195, -3.2064292430877686, -6.0373454093933105, -8.509057998657227, -1.8572320938110352, 0.4720586836338043, -6.186666965484619, -19.394227981567383, -13.810172080993652, -9.784255027770996, -10.113714218139648, -11.990907669067383, -14.532703399658203, -4.718692779541016, -4.973583221435547, -3.142979145050049, -8.119678497314453, -7.406396865844727, -8.977232933044434, -15.457597732543945, -10.06435489654541, -4.006862163543701, -2.0673987865448, -8.998847007751465, -16.670059204101562, -24.697078704833984, -12.966517448425293, -9.825294494628906, -4.353823184967041, -2.6540937423706055, -14.956777572631836, -23.03350830078125, -15.820027351379395, -12.437376976013184, -9.61495304107666, -16.704483032226562, -25.729896545410156, -22.06866455078125, -23.63702392578125, -23.081512451171875, -24.56794548034668, -19.402729034423828, -19.283451080322266, -25.278213500976562, -24.529861450195312, -17.02119255065918, -16.4160099029541, -18.40692138671875, -16.336355209350586, -18.773780822753906, -19.005577087402344, -16.745798110961914, -19.024078369140625, -27.18132972717285, -22.73526382446289, -22.914133071899414, -29.55988311767578, -26.708324432373047, -30.276065826416016, -29.698108673095703, -30.59229278564453, -28.741790771484375, -32.23047637939453, -33.3582763671875, -32.47521209716797, -28.851566314697266, -29.83523941040039, -29.493619918823242, -28.19247055053711, -31.755064010620117, -29.48530387878418, -36.22491455078125, -35.34550094604492, -39.63396072387695, -40.27131652832031, -40.75547790527344, -40.932228088378906, -37.797855377197266, -39.51908874511719, -35.95615005493164, -39.43183135986328, -40.56333541870117, -42.78240203857422, -47.25065612792969, -46.294921875, -46.7440185546875, -46.03441619873047, -45.897727966308594, -46.246421813964844, -46.932125091552734, -49.80915832519531, -49.99241256713867, -52.805328369140625, -53.457618713378906, -54.39703369140625, -54.41950988769531, -55.58515930175781, -58.72906494140625, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [6.960758209228516, -14.901719093322754, -16.588329315185547, -14.87260627746582, -17.71978759765625, -18.004425048828125, 2.9076499938964844, 5.228574275970459, -4.314396381378174, 10.247660636901855, 10.022335052490234, -4.3834686279296875, -11.135414123535156, -5.583358287811279, 9.835699081420898, 6.87143611907959, -6.930947780609131, -11.50750732421875, -2.0825753211975098, 3.407294988632202, 1.4388835430145264, -5.005139350891113, 5.526702404022217, -0.030974555760622025, -4.500602722167969, -10.483969688415527, -19.52256965637207, -14.02629280090332, -17.243549346923828, -12.883615493774414, 1.5945475101470947, 6.0939459800720215, 1.4499051570892334, -4.059498310089111, -12.365384101867676, -12.28563404083252, -12.214903831481934, -9.550365447998047, -16.378877639770508, -10.684686660766602, -5.47031307220459, 2.6884517669677734, -0.6621652245521545, -5.187572479248047, -2.3538641929626465, -13.518370628356934, -20.797447204589844, -10.09865951538086, -6.512750625610352, -9.418376922607422, -11.649953842163086, -20.091487884521484, -19.875425338745117, -22.71361541748047, -6.419081211090088, -1.615287184715271, -13.77896499633789, -18.874469757080078, -18.159420013427734, -12.634662628173828, -14.790637969970703, -20.725921630859375, -23.123519897460938, -21.182201385498047, -27.74527359008789, -27.503952026367188, -26.961469650268555, -14.113316535949707, -15.839107513427734, -27.563282012939453, -18.345792770385742, -14.8217191696167, -11.61634635925293, -15.081960678100586, -17.456478118896484, -17.292692184448242, -15.275970458984375, -20.160409927368164, -20.885345458984375, -22.419692993164062, -22.137022018432617, -24.24149513244629, -27.257278442382812, -24.550861358642578, -31.447650909423828, -29.613479614257812, -28.84552764892578, -31.702165603637695, -29.95831298828125, -31.867782592773438, -32.637962341308594, -27.3447208404541, -30.629119873046875, -25.81821632385254, -27.775123596191406, -28.29399871826172, -27.561100006103516, -34.38010025024414, -33.27448272705078, -37.650150299072266, -38.85620880126953, -39.6544303894043, -37.60222625732422, -36.69868850708008, -36.8754768371582, -36.2684211730957, -39.153743743896484, -41.92311096191406, -41.80400085449219, -42.513160705566406, -41.023338317871094, -43.88402557373047, -44.59291458129883, -45.85218048095703, -47.115150451660156, -47.14292526245117, -46.31618118286133, -45.96156311035156, -49.699974060058594, -51.52986526489258, -52.9327392578125, -53.19795227050781, -54.385040283203125, -56.664817810058594, -60.927085876464844, -61.988258361816406, -61.988258361816406, -61.988258361816406], [5.415809631347656, -16.412593841552734, -21.230873107910156, -21.705739974975586, -26.712549209594727, -25.283525466918945, 3.0362014770507812, 5.478267669677734, -11.33028793334961, 3.951565742492676, 9.754881858825684, 1.793565034866333, -21.12776756286621, -7.045154094696045, 10.348282814025879, 5.589276313781738, -18.745586395263672, -19.313697814941406, -15.736032485961914, -9.535029411315918, -3.9639854431152344, 4.512715816497803, 8.12518310546875, -5.480476379394531, -18.15719223022461, -23.714008331298828, -28.630311965942383, -23.99929428100586, -25.955629348754883, -7.504641532897949, -2.114758014678955, 4.545631408691406, 8.271876335144043, 7.3300275802612305, -5.732049942016602, -29.452531814575195, -29.000274658203125, -9.967717170715332, -14.904947280883789, -29.39162826538086, -12.280389785766602, 0.056696511805057526, 0.13887715339660645, -2.4727442264556885, -1.6683251857757568, -10.225614547729492, -32.83073043823242, -28.899919509887695, -25.303913116455078, -8.384660720825195, -2.9463860988616943, -9.305135726928711, -6.045194625854492, -18.796829223632812, -10.983743667602539, -4.227962970733643, -18.171485900878906, -18.184356689453125, -9.415668487548828, -8.769908905029297, -22.959030151367188, -38.553138732910156, -27.941753387451172, -24.050779342651367, -25.843788146972656, -33.469337463378906, -29.654787063598633, -14.608902931213379, -14.818395614624023, -17.05581283569336, -12.927545547485352, -18.2486572265625, -13.741473197937012, -13.605002403259277, -12.143037796020508, -22.484960556030273, -17.817110061645508, -18.02965545654297, -18.448787689208984, -23.934566497802734, -22.018596649169922, -23.669281005859375, -23.54969024658203, -27.62388038635254, -28.027830123901367, -25.96920394897461, -29.186017990112305, -29.79439926147461, -30.99321174621582, -32.505348205566406, -32.88410949707031, -27.414459228515625, -32.31724548339844, -24.98788833618164, -29.750585556030273, -28.76014518737793, -29.758159637451172, -32.91901779174805, -32.660770416259766, -35.06362533569336, -33.766014099121094, -37.52808380126953, -36.300968170166016, -38.51194763183594, -38.24473190307617, -39.923824310302734, -38.88417053222656, -40.426212310791016, -40.477622985839844, -39.94199752807617, -40.845306396484375, -42.006038665771484, -44.984493255615234, -47.565711975097656, -48.76043701171875, -48.82229232788086, -47.86207580566406, -48.37321853637695, -48.596858978271484, -49.70571517944336, -50.54125213623047, -52.717567443847656, -55.343109130859375, -58.66918182373047, -61.35834503173828, -61.988258361816406, -61.988258361816406, -61.988258361816406], [4.518918514251709, -20.673961639404297, -23.815933227539062, -23.586002349853516, -27.048933029174805, -31.509410858154297, 1.8872902393341064, 4.475022315979004, -17.62689781188965, -5.0199480056762695, 7.599416732788086, 3.1989738941192627, -24.673450469970703, -10.352387428283691, 8.231794357299805, 3.6560189723968506, -26.187532424926758, -27.788427352905273, -23.620391845703125, -18.653047561645508, -12.690793991088867, 9.581422805786133, 9.320487022399902, -7.790477275848389, -20.575477600097656, -23.994531631469727, -36.094154357910156, -32.881771087646484, -29.849266052246094, -3.083430767059326, -2.459308385848999, -7.626352310180664, 7.8411102294921875, 10.415536880493164, -4.878889560699463, -35.16142272949219, -27.92772102355957, -7.394582748413086, -11.017159461975098, -35.577659606933594, -22.224552154541016, -13.107658386230469, -9.192757606506348, -3.323566436767578, 1.0391038656234741, -7.065479278564453, -40.83079528808594, -35.37272262573242, -33.84965515136719, -8.226242065429688, -0.42687860131263733, -3.4278554916381836, 0.9519522190093994, -15.245655059814453, -17.612211227416992, -8.671339988708496, -21.404098510742188, -25.088581085205078, -8.838714599609375, -6.501440525054932, -25.14959716796875, -47.867042541503906, -39.62582015991211, -25.575862884521484, -21.8834285736084, -23.29007911682129, -24.734375, -15.734430313110352, -24.64963150024414, -10.865127563476562, -9.185708999633789, -20.36201286315918, -27.294937133789062, -12.40363597869873, -9.719137191772461, -24.250471115112305, -21.332210540771484, -21.325172424316406, -17.34276008605957, -27.243358612060547, -30.068872451782227, -20.686630249023438, -20.069843292236328, -30.912612915039062, -28.539222717285156, -24.781171798706055, -32.31775665283203, -30.751747131347656, -31.353023529052734, -36.673240661621094, -31.452789306640625, -30.165485382080078, -37.81195068359375, -27.223583221435547, -35.92995834350586, -30.695606231689453, -31.85590934753418, -34.55473327636719, -30.837024688720703, -38.57381057739258, -33.12018585205078, -41.78325653076172, -38.81568908691406, -44.49579620361328, -40.65869140625, -43.58692169189453, -40.314476013183594, -41.88014221191406, -42.90913391113281, -40.396331787109375, -43.96564483642578, -42.80368423461914, -46.977783203125, -50.09273147583008, -50.53718185424805, -52.79174041748047, -54.08967971801758, -53.768455505371094, -51.061763763427734, -51.70681381225586, -53.76142501831055, -56.195465087890625, -58.62969970703125, -61.80580139160156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [5.334930419921875, -33.36419677734375, -30.195674896240234, -22.912212371826172, -26.632770538330078, -32.07024383544922, 0.14660677313804626, 2.7166643142700195, -18.903257369995117, -8.291276931762695, 4.574923992156982, 0.6500940322875977, -24.455703735351562, -11.562660217285156, 4.718041896820068, 0.6273269057273865, -31.391254425048828, -36.607688903808594, -41.44432067871094, -38.367164611816406, -22.42496681213379, 12.436746597290039, 13.465548515319824, -2.8044703006744385, -23.88768768310547, -22.699905395507812, -46.62699890136719, -44.538761138916016, -25.49623680114746, 1.1759381294250488, 1.981444239616394, -18.99851417541504, 6.019296169281006, 9.371244430541992, -4.9705047607421875, -41.378196716308594, -23.08565902709961, -4.158614635467529, -7.3358917236328125, -36.09592056274414, -36.55534744262695, -33.8743896484375, -18.61341094970703, -1.4573101997375488, 1.237414836883545, -6.426072597503662, -47.16954803466797, -40.84640121459961, -40.641029357910156, -11.716546058654785, -3.2494053840637207, -1.1818214654922485, 3.4801580905914307, -12.911358833312988, -22.980300903320312, -14.649943351745605, -22.388572692871094, -46.48231887817383, -12.945796012878418, -7.3039140701293945, -14.38361930847168, -47.419960021972656, -43.25514221191406, -22.685443878173828, -13.206986427307129, -13.921157836914062, -22.935874938964844, -13.38084602355957, -26.199134826660156, -11.547423362731934, -10.018627166748047, -19.916685104370117, -39.75687026977539, -14.899118423461914, -11.931535720825195, -25.432767868041992, -29.227432250976562, -21.86105728149414, -13.870914459228516, -26.678077697753906, -43.667659759521484, -19.692079544067383, -20.4838924407959, -31.861862182617188, -27.887723922729492, -23.747739791870117, -33.72712326049805, -35.04889678955078, -33.77587890625, -38.835777282714844, -33.918148040771484, -32.88374328613281, -37.49201965332031, -29.14404296875, -39.65276336669922, -30.542009353637695, -31.07744598388672, -35.84980773925781, -30.614282608032227, -41.54384231567383, -33.36103057861328, -43.438507080078125, -40.12790298461914, -48.12668228149414, -45.83824920654297, -47.72850799560547, -44.52480697631836, -43.34669494628906, -44.035499572753906, -41.82638168334961, -45.91947937011719, -43.95543670654297, -48.28111267089844, -51.45050811767578, -52.684600830078125, -58.29246139526367, -57.294456481933594, -56.01218795776367, -53.84309768676758, -54.28453826904297, -56.17677307128906, -57.84056854248047, -60.40164566040039, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [5.049304485321045, -33.02888488769531, -33.38013458251953, -22.902687072753906, -26.375102996826172, -33.24010467529297, -2.331547260284424, 0.14069394767284393, -22.051532745361328, -11.693944931030273, -1.00459623336792, -4.130898952484131, -21.656558990478516, -11.934316635131836, -1.822932481765747, -4.6130805015563965, -29.881763458251953, -37.1226921081543, -42.326385498046875, -38.4168701171875, -20.369781494140625, 13.390129089355469, 16.499530792236328, 0.47292977571487427, -25.044998168945312, -23.81766128540039, -43.59951400756836, -47.26878356933594, -24.994638442993164, 4.183328628540039, 4.6302666664123535, -18.24480628967285, 2.0257885456085205, 4.96951961517334, -5.240039825439453, -36.403751373291016, -18.239471435546875, -3.2478699684143066, -6.967893600463867, -37.60064697265625, -41.92890167236328, -35.35321807861328, -19.267404556274414, 3.471842050552368, 1.732276201248169, -8.897194862365723, -38.76959228515625, -44.331764221191406, -40.987998962402344, -10.384571075439453, -4.848406791687012, -3.1197104454040527, 1.195252537727356, -11.521406173706055, -17.06476402282715, -8.869823455810547, -19.221054077148438, -48.61427688598633, -13.899754524230957, -6.913853168487549, -12.154953002929688, -50.14679718017578, -35.011497497558594, -21.09880828857422, -11.608320236206055, -12.292509078979492, -20.343294143676758, -14.379894256591797, -24.984603881835938, -14.607772827148438, -12.381284713745117, -20.503318786621094, -35.915592193603516, -17.34170913696289, -11.626319885253906, -23.67995834350586, -30.052818298339844, -23.863250732421875, -15.935585021972656, -29.44430160522461, -45.60188674926758, -20.46333122253418, -21.602876663208008, -33.00042724609375, -29.10647201538086, -25.66283416748047, -34.27238082885742, -35.64661407470703, -34.60282897949219, -36.030555725097656, -31.67626190185547, -30.876829147338867, -36.778778076171875, -27.713943481445312, -35.84030532836914, -31.0823917388916, -30.7053279876709, -37.287105560302734, -31.75286102294922, -42.31129455566406, -36.28244400024414, -44.00184631347656, -43.68740463256836, -49.558143615722656, -44.391231536865234, -46.15278244018555, -42.43705368041992, -43.804893493652344, -43.72254180908203, -43.07392120361328, -46.779296875, -45.83583450317383, -50.613868713378906, -52.85661315917969, -52.78908157348633, -53.819000244140625, -54.20124053955078, -53.95753479003906, -54.04524230957031, -55.62456512451172, -57.72050476074219, -59.17186737060547, -61.01160430908203, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [3.7600505352020264, -34.65544891357422, -32.40303421020508, -25.200576782226562, -27.22650146484375, -35.07947540283203, -5.00068473815918, -2.813652753829956, -23.57699203491211, -11.883880615234375, -2.585113048553467, -5.146604061126709, -20.38029670715332, -9.792104721069336, 1.8852473497390747, -2.0460100173950195, -28.108694076538086, -35.53273010253906, -41.11540985107422, -37.08306884765625, -19.293245315551758, 10.04088020324707, 14.342510223388672, 2.649625539779663, -29.090396881103516, -26.416397094726562, -35.564300537109375, -40.30706787109375, -25.38364028930664, 4.195034027099609, 4.301740646362305, -17.583213806152344, 0.6026206016540527, 3.1841981410980225, -4.685186386108398, -36.10398864746094, -16.140541076660156, -7.509037017822266, -10.549654960632324, -43.379905700683594, -43.56037902832031, -33.6883430480957, -19.0725040435791, 4.896798133850098, 3.8289709091186523, -9.13125991821289, -38.33367156982422, -48.39389419555664, -45.256134033203125, -6.986778259277344, -0.5120869874954224, -4.549792289733887, -0.6173486709594727, -10.94637680053711, -14.208307266235352, -7.646628379821777, -17.516611099243164, -45.497093200683594, -13.544408798217773, -9.47640609741211, -15.29753303527832, -51.96234893798828, -30.388805389404297, -14.813993453979492, -11.223634719848633, -12.420917510986328, -18.49767303466797, -12.837608337402344, -26.5035343170166, -14.239540100097656, -13.639509201049805, -21.347862243652344, -34.376834869384766, -19.2712345123291, -15.78408432006836, -27.444791793823242, -32.30644607543945, -24.83466148376465, -17.05991554260254, -28.333932876586914, -45.119041442871094, -22.158727645874023, -22.885494232177734, -31.3710880279541, -32.219871520996094, -28.53736114501953, -35.95269012451172, -34.481075286865234, -30.42416000366211, -34.467872619628906, -29.277080535888672, -28.385393142700195, -37.805477142333984, -28.07906150817871, -34.843780517578125, -32.931060791015625, -32.394004821777344, -40.70079040527344, -35.08464050292969, -42.996681213378906, -40.54779815673828, -45.30397033691406, -43.707916259765625, -46.61528778076172, -41.48386001586914, -44.45780944824219, -41.51770782470703, -44.61815643310547, -44.24681854248047, -45.672698974609375, -48.48850631713867, -48.33656692504883, -50.551734924316406, -51.66874313354492, -51.210723876953125, -52.564598083496094, -54.08156967163086, -54.61921310424805, -55.968910217285156, -57.67421340942383, -59.145729064941406, -59.83820343017578, -60.891910552978516, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [1.9762731790542603, -30.767284393310547, -35.793128967285156, -31.925046920776367, -30.149433135986328, -35.09761047363281, -7.682339668273926, -5.55894136428833, -26.727991104125977, -7.3068389892578125, 5.057613849639893, 1.3335233926773071, -21.77535057067871, -8.713772773742676, 8.274322509765625, 3.922957181930542, -26.48619842529297, -34.078792572021484, -38.804222106933594, -37.80229949951172, -13.653326034545898, 7.718925952911377, 12.477374076843262, 3.3925178050994873, -31.01703453063965, -30.45901870727539, -33.910640716552734, -38.90228271484375, -20.6668643951416, 0.452668696641922, 0.43123695254325867, -15.700868606567383, 5.952800750732422, 9.28704833984375, -3.3719170093536377, -37.367637634277344, -15.387167930603027, -5.8730268478393555, -10.131068229675293, -43.189048767089844, -39.098854064941406, -31.863353729248047, -12.802591323852539, 2.486477851867676, 5.266374588012695, -5.308997631072998, -38.44745635986328, -51.491119384765625, -45.999027252197266, -8.42019271850586, -2.825932025909424, -2.830564498901367, 1.9154382944107056, -10.689493179321289, -11.981200218200684, -6.127583980560303, -15.558870315551758, -41.99062728881836, -9.82613754272461, -7.744265556335449, -17.413591384887695, -52.61802291870117, -28.40515899658203, -13.967683792114258, -10.685976028442383, -12.60435676574707, -19.701702117919922, -14.232873916625977, -26.20355987548828, -14.603018760681152, -14.192306518554688, -23.743297576904297, -36.58162307739258, -21.7369384765625, -17.981843948364258, -29.247533798217773, -30.89566993713379, -23.562307357788086, -17.723386764526367, -29.095029830932617, -39.801551818847656, -22.327903747558594, -23.798112869262695, -29.302913665771484, -31.37142562866211, -27.245500564575195, -35.42561721801758, -31.182859420776367, -28.6135196685791, -34.891483306884766, -28.460113525390625, -28.36612319946289, -36.80097961425781, -28.527509689331055, -35.886444091796875, -34.93294906616211, -34.65218734741211, -44.35309600830078, -39.631065368652344, -43.688236236572266, -41.900169372558594, -44.90486526489258, -40.973182678222656, -44.21229553222656, -40.33210372924805, -43.939979553222656, -41.41017532348633, -44.71974182128906, -45.2946891784668, -47.94904708862305, -51.06574249267578, -50.64959716796875, -50.93321228027344, -52.662010192871094, -51.82062530517578, -53.686553955078125, -55.9108772277832, -57.186317443847656, -58.19149398803711, -59.16658401489258, -59.78428268432617, -61.04267120361328, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-0.2050003707408905, -35.2473258972168, -40.95674133300781, -37.65726852416992, -33.398651123046875, -35.21913146972656, -11.313182830810547, -9.395410537719727, -28.186622619628906, -3.426302909851074, 9.566844940185547, 5.492129325866699, -22.698101043701172, -6.801607608795166, 11.844062805175781, 7.604511260986328, -24.404361724853516, -35.00224304199219, -34.61725616455078, -38.33531188964844, -10.435606002807617, 10.149679183959961, 14.395360946655273, 2.9764857292175293, -28.35679817199707, -29.94106101989746, -36.19545364379883, -45.70085525512695, -19.619199752807617, -1.4641892910003662, -1.1309621334075928, -13.91950511932373, 7.327266216278076, 10.26756763458252, -3.1362404823303223, -37.128597259521484, -15.136752128601074, -2.6108803749084473, -7.961310386657715, -39.58118438720703, -41.16558837890625, -35.4610481262207, -10.047769546508789, 5.460977554321289, 5.422847747802734, -6.250654220581055, -39.59013748168945, -54.300575256347656, -48.68775177001953, -8.996702194213867, -2.82468318939209, -4.2549028396606445, -1.2142819166183472, -11.45571231842041, -10.754451751708984, -4.362161636352539, -14.257843017578125, -40.884254455566406, -7.629886150360107, -5.37703275680542, -18.693153381347656, -46.79880142211914, -27.760948181152344, -13.23034381866455, -12.1482572555542, -16.4706974029541, -20.774761199951172, -15.004878044128418, -25.846731185913086, -15.824804306030273, -15.296097755432129, -25.712852478027344, -40.08211135864258, -19.78627586364746, -16.324052810668945, -27.73944091796875, -29.230247497558594, -22.58833122253418, -17.71371841430664, -27.615219116210938, -36.3902587890625, -22.5144100189209, -25.173816680908203, -28.67066192626953, -29.38062286376953, -27.2703857421875, -36.13181686401367, -29.626501083374023, -27.47675895690918, -35.967079162597656, -28.782978057861328, -30.080425262451172, -38.48720932006836, -30.761150360107422, -37.58552551269531, -38.302772521972656, -38.0637321472168, -48.25902557373047, -47.41498565673828, -44.36359786987305, -42.10609817504883, -45.20811080932617, -41.48683547973633, -43.305030822753906, -40.25039291381836, -45.58130645751953, -43.55126953125, -47.037025451660156, -48.69419479370117, -49.53019714355469, -52.442298889160156, -51.42816162109375, -52.553009033203125, -54.75632095336914, -54.96503448486328, -57.2449951171875, -58.75749588012695, -59.49641418457031, -59.5879020690918, -61.00374221801758, -61.8050537109375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-2.5371787548065186, -36.59298324584961, -42.27375411987305, -35.5972900390625, -36.411964416503906, -38.582611083984375, -17.140466690063477, -15.496871948242188, -28.392154693603516, -1.057869791984558, 12.276329040527344, 8.232462882995605, -26.21036148071289, -8.673870086669922, 13.3465576171875, 9.996758460998535, -20.027589797973633, -36.85643768310547, -33.14994430541992, -33.61682891845703, -9.560426712036133, 5.899658203125, 10.962879180908203, 2.045849084854126, -23.351024627685547, -33.236236572265625, -39.2880744934082, -49.416297912597656, -22.494619369506836, 2.4205899238586426, 4.48220157623291, -10.756053924560547, 4.066025257110596, 5.971477031707764, -2.9282948970794678, -36.846763610839844, -17.428241729736328, -5.6287641525268555, -10.369719505310059, -31.243389129638672, -36.682437896728516, -41.420082092285156, -9.714180946350098, 5.625338554382324, 5.268237590789795, -3.5806262493133545, -29.435081481933594, -47.20814514160156, -41.2644157409668, -9.463249206542969, -2.052377462387085, -3.6525959968566895, -0.20151248574256897, -11.414073944091797, -13.793289184570312, -6.4434380531311035, -11.985898971557617, -40.17955017089844, -8.092217445373535, -6.62961483001709, -20.55355453491211, -38.74998474121094, -31.70699119567871, -14.701414108276367, -11.986808776855469, -16.333219528198242, -23.948823928833008, -17.05095100402832, -26.29767417907715, -18.349308013916016, -19.276369094848633, -26.674776077270508, -45.386234283447266, -19.917171478271484, -14.998291015625, -25.10907745361328, -28.229246139526367, -22.82119369506836, -17.870351791381836, -25.77733039855957, -36.529945373535156, -24.340362548828125, -27.338756561279297, -30.21135139465332, -29.343984603881836, -29.568538665771484, -39.05803298950195, -28.559980392456055, -27.203845977783203, -38.099700927734375, -29.574325561523438, -30.51626968383789, -41.3716926574707, -35.38348388671875, -40.54811477661133, -41.91548156738281, -40.9150505065918, -45.726051330566406, -47.79756164550781, -46.00113296508789, -41.362247467041016, -44.25074768066406, -40.60653305053711, -43.66169738769531, -41.164329528808594, -47.694091796875, -48.07408142089844, -51.67583084106445, -51.967132568359375, -51.29201889038086, -53.18996047973633, -52.0702018737793, -53.82003402709961, -56.39860153198242, -57.249122619628906, -59.149757385253906, -60.63032531738281, -60.638458251953125, -60.960296630859375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-4.9466400146484375, -38.51389694213867, -44.586158752441406, -34.46249771118164, -36.89005661010742, -39.8464241027832, -18.753089904785156, -16.10879898071289, -25.5341739654541, 0.3979698121547699, 13.760842323303223, 9.639483451843262, -30.53378677368164, -13.700757026672363, 13.24576473236084, 11.126575469970703, -24.508712768554688, -41.0030403137207, -35.632164001464844, -30.558298110961914, -9.392654418945312, 10.447348594665527, 10.333403587341309, 2.1509528160095215, -23.695850372314453, -35.87498474121094, -42.34302520751953, -46.06140899658203, -27.274799346923828, 2.0264856815338135, 5.71887731552124, -7.598259449005127, 4.687923431396484, 6.867430210113525, -2.899354934692383, -34.894386291503906, -24.525634765625, -10.279593467712402, -10.500118255615234, -22.9622859954834, -32.49504852294922, -41.717041015625, -8.955471992492676, 2.5718746185302734, 1.491227149963379, -2.0626678466796875, -22.9262638092041, -42.296871185302734, -37.96232604980469, -13.372225761413574, -4.3334431648254395, -3.769942283630371, -2.2116920948028564, -11.756961822509766, -18.811840057373047, -5.796360969543457, -10.720623016357422, -39.747581481933594, -9.347875595092773, -7.13067102432251, -15.240409851074219, -31.750015258789062, -42.74964141845703, -16.22188377380371, -13.433792114257812, -15.395865440368652, -29.14208221435547, -21.07782554626465, -26.932573318481445, -18.582067489624023, -18.673154830932617, -24.77400779724121, -51.336647033691406, -19.84468650817871, -15.571837425231934, -25.765897750854492, -27.01511001586914, -24.1859073638916, -20.165847778320312, -26.012773513793945, -37.90184783935547, -28.550710678100586, -29.51136016845703, -34.140167236328125, -29.993494033813477, -29.119979858398438, -37.45917510986328, -28.396692276000977, -26.822786331176758, -41.16156768798828, -30.987648010253906, -32.47804641723633, -42.014068603515625, -38.145545959472656, -42.93558120727539, -43.501609802246094, -43.24441909790039, -43.72321319580078, -42.772254943847656, -45.51021194458008, -40.852264404296875, -44.51767349243164, -41.25495529174805, -46.29312515258789, -45.34223175048828, -51.35186767578125, -51.79576110839844, -52.247955322265625, -52.883487701416016, -52.03449249267578, -55.351924896240234, -55.04764938354492, -56.22190475463867, -59.01294708251953, -60.71807861328125, -60.74705123901367, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-8.270777702331543, -35.676971435546875, -46.353336334228516, -36.97357940673828, -35.47675323486328, -35.18086242675781, -11.89196491241455, -8.699713706970215, -25.369304656982422, 0.9278731346130371, 14.225178718566895, 10.055782318115234, -29.263874053955078, -16.147672653198242, 11.774934768676758, 10.244222640991211, -23.855722427368164, -35.93281936645508, -39.637210845947266, -32.152381896972656, -10.049906730651855, 14.256705284118652, 17.434839248657227, 7.481259822845459, -32.68218231201172, -39.0432014465332, -41.08184051513672, -41.178855895996094, -30.317203521728516, -1.4189146757125854, 1.6766632795333862, -6.489996433258057, 7.296161651611328, 10.142080307006836, -2.359677314758301, -31.82080078125, -30.084217071533203, -7.010298728942871, -5.960434913635254, -20.77578353881836, -34.85134506225586, -40.29652404785156, -9.08798599243164, 5.5356764793396, 4.855827331542969, -3.21834135055542, -20.09616470336914, -40.139007568359375, -34.71207046508789, -15.248830795288086, -2.4770655632019043, -2.480858325958252, -1.2872586250305176, -11.843137741088867, -23.554149627685547, -10.405421257019043, -13.012566566467285, -39.66786575317383, -12.671585083007812, -10.848758697509766, -14.132128715515137, -29.05013656616211, -48.83155059814453, -18.180992126464844, -12.091971397399902, -15.097257614135742, -34.20915985107422, -23.493501663208008, -27.925378799438477, -17.88701820373535, -17.77928924560547, -23.28490447998047, -47.55220413208008, -19.712696075439453, -15.519989967346191, -25.563720703125, -26.508468627929688, -25.481246948242188, -22.82808494567871, -27.28997230529785, -37.0563850402832, -29.985551834106445, -32.174888610839844, -40.91706085205078, -30.700984954833984, -28.609216690063477, -36.09527587890625, -31.724712371826172, -30.63707160949707, -45.09048080444336, -33.41468811035156, -35.99900817871094, -42.92659378051758, -39.107879638671875, -43.85149383544922, -44.55626678466797, -44.372230529785156, -44.163597106933594, -41.828006744384766, -45.479515075683594, -41.34259033203125, -46.343467712402344, -44.72793960571289, -49.87461471557617, -49.29631042480469, -53.86558532714844, -52.50883483886719, -53.87251281738281, -55.48872375488281, -53.81614685058594, -57.51321792602539, -58.37030792236328, -59.878318786621094, -61.61489486694336, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-13.072815895080566, -35.51549530029297, -45.70749282836914, -39.32764434814453, -35.87748718261719, -33.443504333496094, -7.053244590759277, -3.7639427185058594, -22.60512351989746, -0.5818742513656616, 13.547526359558105, 10.026239395141602, -26.886234283447266, -14.670160293579102, 8.256771087646484, 6.8664069175720215, -19.54607391357422, -35.87226486206055, -40.095909118652344, -33.792659759521484, -10.76529598236084, 11.741242408752441, 18.011743545532227, 9.525531768798828, -34.98827362060547, -42.00077819824219, -40.962738037109375, -38.743751525878906, -30.289073944091797, -1.064918875694275, 2.117804527282715, -5.827662944793701, 4.505973815917969, 6.84576940536499, -1.0770223140716553, -29.084613800048828, -29.411972045898438, -8.667054176330566, -7.806495666503906, -19.725833892822266, -32.654754638671875, -37.39208984375, -12.34576416015625, 2.762040138244629, 4.723703384399414, -0.8417955040931702, -20.04458999633789, -41.938533782958984, -34.54525375366211, -14.737655639648438, -4.097518444061279, -3.9887118339538574, -2.317512273788452, -8.782313346862793, -30.170316696166992, -13.030552864074707, -15.008052825927734, -40.2586555480957, -18.254104614257812, -15.680174827575684, -15.72232723236084, -29.801576614379883, -51.75154113769531, -19.262775421142578, -11.811600685119629, -15.396596908569336, -32.20775604248047, -22.805660247802734, -27.281835556030273, -17.234302520751953, -16.039169311523438, -23.88343048095703, -47.04093933105469, -22.268362045288086, -18.136775970458984, -25.331348419189453, -26.275115966796875, -27.267942428588867, -25.781118392944336, -29.62005615234375, -38.62251663208008, -30.934032440185547, -31.8809871673584, -42.80772399902344, -32.15957260131836, -28.75236701965332, -34.998355865478516, -37.247291564941406, -34.715728759765625, -44.09258270263672, -39.33576965332031, -39.42879104614258, -45.45375442504883, -40.47742462158203, -46.70874786376953, -45.1766242980957, -43.1329345703125, -45.74430847167969, -41.5775146484375, -45.91499710083008, -43.4188117980957, -48.66875076293945, -48.76958465576172, -53.137290954589844, -52.50994873046875, -55.12879943847656, -53.60897445678711, -56.67927169799805, -56.851749420166016, -57.198463439941406, -60.27757263183594, -61.421592712402344, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-13.53231430053711, -26.837669372558594, -46.89269256591797, -36.52250289916992, -31.491893768310547, -30.08770179748535, -3.8024520874023438, -0.22461837530136108, -18.742568969726562, -3.4908223152160645, 11.742399215698242, 8.887212753295898, -20.729961395263672, -10.660619735717773, 1.2509602308273315, 0.01649630442261696, -17.17713737487793, -26.851491928100586, -30.48659896850586, -23.928455352783203, -14.11341667175293, 4.425816059112549, 13.355504035949707, 7.333643436431885, -11.942176818847656, -21.796606063842773, -25.887880325317383, -25.46333122253418, -23.850833892822266, 2.285475254058838, 6.724799156188965, -3.9641880989074707, 2.125074625015259, 7.311163902282715, 0.9956651926040649, -34.4752082824707, -24.121475219726562, -10.35745620727539, -9.908075332641602, -18.349384307861328, -31.04712677001953, -33.56438446044922, -19.736230850219727, 2.1338536739349365, 3.8883156776428223, -4.043648719787598, -20.71965980529785, -41.41309356689453, -28.697301864624023, -14.148980140686035, -2.9843268394470215, -4.866751670837402, -1.780095100402832, -8.031895637512207, -31.23312759399414, -18.13959503173828, -19.68057632446289, -37.72419357299805, -21.608413696289062, -16.874828338623047, -18.037843704223633, -32.50688934326172, -44.95606231689453, -21.5135555267334, -15.768819808959961, -16.885284423828125, -30.704933166503906, -22.3720703125, -26.940040588378906, -17.4393310546875, -13.780388832092285, -24.720096588134766, -44.68395233154297, -27.519596099853516, -21.202468872070312, -26.176137924194336, -27.212247848510742, -29.197509765625, -26.80415916442871, -30.535320281982422, -43.06883239746094, -31.128135681152344, -29.011632919311523, -39.604827880859375, -33.20241165161133, -28.338871002197266, -34.24636459350586, -40.15012741088867, -34.7661247253418, -43.09318542480469, -44.55324172973633, -42.13597106933594, -48.789554595947266, -41.37425994873047, -46.83697509765625, -44.984336853027344, -41.692012786865234, -48.90476989746094, -42.09540939331055, -46.937904357910156, -46.80736541748047, -52.149322509765625, -52.04366683959961, -55.683876037597656, -52.92266082763672, -55.99003219604492, -54.589046478271484, -58.71371841430664, -58.15425491333008, -61.76610565185547, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-8.668079376220703, -22.254749298095703, -40.92561721801758, -34.40552520751953, -25.811725616455078, -19.72918128967285, -3.528392791748047, 1.9123529195785522, -5.644211769104004, -5.818688869476318, 8.925701141357422, 6.14301872253418, -15.616157531738281, -7.63707160949707, -3.1318578720092773, -5.474348068237305, -18.097312927246094, -20.430299758911133, -21.551006317138672, -15.85081672668457, -10.821054458618164, 8.16820240020752, 9.390389442443848, 3.9997971057891846, -0.8353476524353027, -2.6081583499908447, -9.319480895996094, -20.579492568969727, -18.950410842895508, -0.04015037417411804, 4.257491111755371, -1.8559659719467163, 5.588111400604248, 11.503294944763184, 2.2545387744903564, -22.8638858795166, -23.066692352294922, -11.483522415161133, -9.625130653381348, -17.537189483642578, -27.852745056152344, -20.080116271972656, -17.5399227142334, -1.1325621604919434, 0.6004974842071533, -7.99974250793457, -20.70433807373047, -33.60361099243164, -17.857173919677734, -10.749483108520508, -9.215266227722168, -7.447077751159668, -3.42167592048645, -10.505399703979492, -23.98605728149414, -19.13372230529785, -21.90575408935547, -29.12057876586914, -16.29517364501953, -12.227737426757812, -20.674001693725586, -28.662385940551758, -36.30119323730469, -27.796003341674805, -17.901836395263672, -18.049928665161133, -31.976112365722656, -27.456317901611328, -31.06661033630371, -16.141494750976562, -14.149637222290039, -28.456850051879883, -39.02299880981445, -28.403539657592773, -22.597597122192383, -30.141223907470703, -30.688941955566406, -31.002117156982422, -27.572330474853516, -33.07273483276367, -48.649539947509766, -29.692798614501953, -28.174028396606445, -41.0384407043457, -33.05638885498047, -28.145679473876953, -37.680938720703125, -41.782691955566406, -36.36235046386719, -46.72288513183594, -47.5917854309082, -46.592247009277344, -53.35645294189453, -42.543426513671875, -46.503936767578125, -43.819278717041016, -40.88982391357422, -49.988521575927734, -43.294822692871094, -50.527679443359375, -51.67652130126953, -56.64189147949219, -53.733524322509766, -57.61913299560547, -52.637794494628906, -56.829833984375, -55.0792121887207, -60.610103607177734, -60.720863342285156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-9.539619445800781, -26.636037826538086, -42.671363830566406, -40.735809326171875, -29.85334014892578, -20.54193115234375, -10.09325122833252, 1.1315206289291382, 0.7219141125679016, -7.5437188148498535, 4.160452842712402, 1.016096591949463, -18.862123489379883, -13.690410614013672, -8.696986198425293, -9.827776908874512, -16.38955307006836, -16.466869354248047, -23.52246856689453, -18.349000930786133, -12.110193252563477, 11.383237838745117, 12.348003387451172, -2.753847599029541, -0.6159992814064026, 2.3408360481262207, -6.310520172119141, -23.93601417541504, -24.3850040435791, -11.699810981750488, -8.129528999328613, -8.834824562072754, 5.154635906219482, 10.230701446533203, 2.202061891555786, -21.711959838867188, -31.691740036010742, -21.914331436157227, -19.459165573120117, -25.81084442138672, -32.995201110839844, -11.742205619812012, -8.594499588012695, 0.7538629174232483, 0.3050990104675293, -15.46713924407959, -26.651321411132812, -33.37821578979492, -15.900992393493652, -11.965537071228027, -20.391042709350586, -8.42961597442627, -2.1090080738067627, -12.375530242919922, -23.3775691986084, -22.451148986816406, -31.766664505004883, -31.168306350708008, -14.954385757446289, -11.797771453857422, -23.37383460998535, -32.894100189208984, -38.18231964111328, -38.796966552734375, -18.379531860351562, -19.444286346435547, -41.12834930419922, -39.959651947021484, -39.31362533569336, -15.10297679901123, -14.463868141174316, -37.64914321899414, -41.73068618774414, -33.04599380493164, -26.89244842529297, -36.085853576660156, -40.69329071044922, -34.54651641845703, -29.171241760253906, -37.5107421875, -51.511619567871094, -28.631908416748047, -28.260704040527344, -49.43239212036133, -33.32991409301758, -28.663604736328125, -42.53773498535156, -43.62544250488281, -38.73688507080078, -53.144554138183594, -51.54952621459961, -52.000816345214844, -57.11986541748047, -45.00291442871094, -50.61272048950195, -43.081634521484375, -41.2061653137207, -50.92583084106445, -45.390777587890625, -55.41530990600586, -55.326595306396484, -61.12005615234375, -57.444923400878906, -60.297462463378906, -54.6259651184082, -59.5435905456543, -57.23931884765625, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-12.406558990478516, -32.29548645019531, -43.44692611694336, -45.668373107910156, -41.59791946411133, -36.40361404418945, -23.524559020996094, 1.349837303161621, 2.7608084678649902, -10.501059532165527, -3.3604073524475098, -5.731858253479004, -24.59406280517578, -34.95735549926758, -30.5545597076416, -14.55674934387207, -5.1786322593688965, -9.73596477508545, -32.90107727050781, -31.95117950439453, -21.0050106048584, 12.675182342529297, 13.743120193481445, -15.492363929748535, -5.889580726623535, -1.5467867851257324, -9.981165885925293, -33.188594818115234, -39.98441696166992, -31.685115814208984, -36.56362533569336, -23.645000457763672, 0.4611400067806244, 4.521505355834961, -0.1834978312253952, -23.32086944580078, -36.67871856689453, -39.25393295288086, -39.28280258178711, -47.08417510986328, -34.56707763671875, -8.620311737060547, -5.652779579162598, 3.4256324768066406, 3.2824368476867676, -17.028743743896484, -43.771053314208984, -43.443511962890625, -13.10494613647461, -12.562766075134277, -30.100374221801758, -11.215490341186523, -6.357154846191406, -14.844311714172363, -25.18751335144043, -26.941022872924805, -49.37782669067383, -47.736778259277344, -13.660649299621582, -9.860106468200684, -24.84311294555664, -53.03632736206055, -50.61652755737305, -44.66728591918945, -19.825061798095703, -20.575334548950195, -49.68894577026367, -49.136817932128906, -43.33311080932617, -15.0936279296875, -14.244400024414062, -40.960060119628906, -47.49574279785156, -38.588706970214844, -32.043792724609375, -41.55242919921875, -58.59276580810547, -38.16532516479492, -31.845699310302734, -41.519126892089844, -54.51057815551758, -30.23223114013672, -30.42226791381836, -54.688167572021484, -34.91508865356445, -30.37886619567871, -46.25885772705078, -42.511993408203125, -37.56256866455078, -53.493797302246094, -53.34856033325195, -52.019012451171875, -61.988258361816406, -50.78369140625, -57.37749481201172, -44.64543151855469, -43.076805114746094, -54.11225128173828, -48.72148513793945, -59.508766174316406, -57.07676315307617, -61.988258361816406, -61.988258361816406, -61.988258361816406, -58.734683990478516, -61.988258361816406, -60.4766845703125, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-10.271149635314941, -27.396745681762695, -32.64519500732422, -38.709537506103516, -36.89936828613281, -30.166908264160156, -17.2287540435791, 2.1266708374023438, 3.312192916870117, -8.801729202270508, 2.65108060836792, 0.6796348094940186, -17.205617904663086, -25.707406997680664, -24.315391540527344, -10.366510391235352, -0.6998262405395508, -6.130415916442871, -25.910350799560547, -30.91407012939453, -14.844037055969238, 11.326285362243652, 12.565561294555664, -11.420124053955078, -7.585097312927246, -7.440395355224609, -13.869077682495117, -25.671796798706055, -20.80946922302246, -16.53013038635254, -17.545106887817383, -19.795406341552734, 2.5086281299591064, 8.965824127197266, 2.4435057640075684, -15.43057918548584, -22.25996208190918, -17.437971115112305, -16.930526733398438, -18.052745819091797, -21.748577117919922, -10.93644905090332, -8.76635456085205, 0.4313030540943146, 0.046687688678503036, -10.901927947998047, -28.77405548095703, -38.9636116027832, -12.341509819030762, -12.494253158569336, -28.926076889038086, -12.193038940429688, -5.081357002258301, -14.139505386352539, -22.373619079589844, -24.618492126464844, -29.212053298950195, -33.69599533081055, -17.007545471191406, -13.356210708618164, -23.938785552978516, -34.81336975097656, -39.435611724853516, -44.43532943725586, -19.189817428588867, -19.09568977355957, -29.74842071533203, -48.652565002441406, -45.401458740234375, -17.385555267333984, -15.677260398864746, -29.705068588256836, -50.84956359863281, -39.76826095581055, -32.51015853881836, -36.32679748535156, -49.598506927490234, -42.892059326171875, -36.286006927490234, -43.898948669433594, -45.9958610534668, -33.685089111328125, -34.430118560791016, -52.900882720947266, -38.21367263793945, -34.036590576171875, -47.614227294921875, -42.65989303588867, -37.18619918823242, -46.95646286010742, -50.93862533569336, -48.22523498535156, -59.37714385986328, -58.23843002319336, -59.54943084716797, -48.41558074951172, -47.48005676269531, -58.53038024902344, -53.452720642089844, -61.988258361816406, -59.6575927734375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-10.938977241516113, -21.302581787109375, -30.804115295410156, -37.148963928222656, -31.867942810058594, -24.088848114013672, -13.53055191040039, -0.9208097457885742, 0.24254480004310608, -7.069374084472656, 7.49472188949585, 7.506335258483887, -9.807209014892578, -21.682769775390625, -19.593217849731445, -9.204278945922852, -2.987401247024536, -6.7729926109313965, -19.974987030029297, -27.858985900878906, -12.553824424743652, 5.80984354019165, 7.959794998168945, -2.2520997524261475, -7.599809169769287, -8.679314613342285, -16.061866760253906, -20.327945709228516, -13.922510147094727, -10.537368774414062, -9.995307922363281, -12.4653902053833, -0.34850361943244934, 9.649770736694336, 8.072896003723145, -7.085439682006836, -14.7379732131958, -10.372834205627441, -10.260017395019531, -11.154958724975586, -14.396284103393555, -17.91713523864746, -16.630126953125, -6.978206634521484, 0.07981709390878677, -1.613020896911621, -22.079513549804688, -32.63945007324219, -18.678611755371094, -17.22282600402832, -22.617237091064453, -16.800304412841797, -8.428304672241211, -11.111464500427246, -19.71428680419922, -22.796009063720703, -22.932584762573242, -27.23280143737793, -24.29048728942871, -16.51934051513672, -20.84678840637207, -27.882692337036133, -32.36185836791992, -42.072940826416016, -24.160184860229492, -18.31525993347168, -20.96024513244629, -44.50065612792969, -45.53827667236328, -21.296489715576172, -16.432706832885742, -19.755043029785156, -46.777706146240234, -44.306392669677734, -33.49052810668945, -29.85154914855957, -38.92241668701172, -42.63128662109375, -41.94435119628906, -40.07411193847656, -38.3810920715332, -41.41794204711914, -39.11381912231445, -44.022377014160156, -44.432682037353516, -39.20720672607422, -43.14339065551758, -47.60532760620117, -39.135459899902344, -39.98975372314453, -53.195186614990234, -47.882266998291016, -50.75479507446289, -59.77668762207031, -54.34263610839844, -55.13219451904297, -54.394954681396484, -61.988258361816406, -59.42066192626953, -60.21947479248047, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-10.826580047607422, -15.975229263305664, -24.848369598388672, -31.04892349243164, -28.257123947143555, -25.052837371826172, -15.502327919006348, -11.105437278747559, -8.085664749145508, -7.667341709136963, 9.31009578704834, 10.357752799987793, -7.377772331237793, -24.75426483154297, -22.260391235351562, -15.16168212890625, -11.11417007446289, -8.60666561126709, -8.104838371276855, -12.030488014221191, -17.33820915222168, -5.022985935211182, -0.41532933712005615, -2.90531063079834, -16.62204933166504, -19.285396575927734, -19.35663414001465, -15.040533065795898, -15.098104476928711, -14.307184219360352, -12.562517166137695, -13.184962272644043, -8.814153671264648, 4.531395435333252, 7.373598098754883, -6.836489677429199, -17.85272216796875, -14.741870880126953, -15.447415351867676, -15.98480224609375, -17.45195770263672, -19.10177993774414, -19.194860458374023, -15.826032638549805, 1.3606196641921997, 0.9519097805023193, -20.0089168548584, -28.27834701538086, -31.60186004638672, -26.883440017700195, -27.109968185424805, -28.158281326293945, -14.480997085571289, -7.234201908111572, -18.165515899658203, -29.898290634155273, -28.313697814941406, -31.24386215209961, -30.84529685974121, -20.52948760986328, -21.001989364624023, -32.19175720214844, -36.04243469238281, -36.356876373291016, -33.13448715209961, -21.352783203125, -22.04047966003418, -32.58277893066406, -34.27031326293945, -33.84762191772461, -18.61568832397461, -17.88431167602539, -33.698204040527344, -43.30086135864258, -33.20602798461914, -25.016674041748047, -35.329620361328125, -40.15745162963867, -40.70710754394531, -34.37813949584961, -39.610260009765625, -43.9336051940918, -40.36878967285156, -42.261390686035156, -44.25562286376953, -42.34052276611328, -42.594486236572266, -45.265316009521484, -41.525718688964844, -37.232601165771484, -53.80439376831055, -43.23798751831055, -43.81218719482422, -50.87333679199219, -46.695098876953125, -54.285675048828125, -55.38488006591797, -55.74485397338867, -59.67485046386719, -55.02937698364258, -59.19023895263672, -54.11328887939453, -58.35326385498047, -58.06117248535156, -61.988258361816406, -61.988258361816406, -58.83464050292969, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.945629358291626, -6.716721534729004, -15.12671947479248, -28.28738021850586, -20.52483367919922, -15.91112995147705, -10.677644729614258, -2.870159387588501, 5.788173675537109, 6.895952224731445, 10.68997859954834, 10.089588165283203, -10.818105697631836, -22.590505599975586, -16.749225616455078, -9.73451042175293, -3.631591558456421, 4.50960111618042, 8.292110443115234, 4.762291431427002, -11.00821304321289, -9.59001636505127, 0.07216819375753403, -4.001252174377441, -13.253107070922852, -17.27947425842285, -11.21722412109375, -2.2616803646087646, -3.90057110786438, -11.081551551818848, -6.3394904136657715, -5.204253196716309, -2.363694429397583, 5.875150680541992, 4.018350601196289, -11.998733520507812, -18.71968650817871, -26.712871551513672, -21.132877349853516, -14.430582046508789, -14.436338424682617, -8.464948654174805, -8.405206680297852, -4.208504676818848, 1.965339183807373, -2.2808942794799805, -8.668119430541992, -14.353693962097168, -17.084558486938477, -20.887737274169922, -28.62201690673828, -23.105274200439453, -10.478326797485352, -6.260281562805176, -18.17742347717285, -22.183425903320312, -31.944730758666992, -26.767501831054688, -15.182029724121094, -13.556629180908203, -17.693466186523438, -30.68263816833496, -35.12519454956055, -22.332576751708984, -22.954139709472656, -24.47443199157715, -28.19011688232422, -19.209001541137695, -18.153472900390625, -27.361658096313477, -20.506298065185547, -17.38912582397461, -18.121641159057617, -31.61625099182129, -25.709440231323242, -22.541112899780273, -29.43588638305664, -27.897930145263672, -29.060359954833984, -32.156578063964844, -31.90547752380371, -33.29231643676758, -31.478294372558594, -37.0839958190918, -30.167259216308594, -30.362356185913086, -36.375667572021484, -29.981386184692383, -35.14714050292969, -37.874298095703125, -40.909542083740234, -32.39751434326172, -32.32212829589844, -36.203819274902344, -33.148277282714844, -42.732566833496094, -40.42444610595703, -44.632774353027344, -47.14685821533203, -46.196205139160156, -45.73937225341797, -42.23473358154297, -43.67503356933594, -43.712310791015625, -48.770538330078125, -48.13367462158203, -43.51737594604492, -46.6500244140625, -47.489158630371094, -53.13035583496094, -56.21559143066406, -55.521095275878906, -54.796775817871094, -52.64152526855469, -55.37208938598633, -57.415443420410156, -56.96839904785156, -56.983909606933594, -59.431453704833984, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [4.328541278839111, -7.2671027183532715, -13.579582214355469, -28.060205459594727, -22.913339614868164, -17.373178482055664, -14.779937744140625, -2.7998595237731934, 8.19373893737793, 12.371206283569336, 12.146575927734375, 9.053863525390625, -18.45682716369629, -22.84500503540039, -19.540164947509766, -11.133866310119629, -6.361588478088379, 5.077792167663574, 10.710429191589355, 10.953903198242188, 0.18839788436889648, -4.916110515594482, -3.5654449462890625, -9.905998229980469, -11.907207489013672, -16.94078254699707, -8.839007377624512, -0.8554362058639526, -2.204177141189575, -8.105525016784668, -6.796506881713867, -5.346869468688965, -1.1015411615371704, 7.316375732421875, 0.30714812874794006, -15.462152481079102, -18.494678497314453, -28.983871459960938, -18.36809730529785, -6.519804954528809, -7.866364002227783, -7.603708267211914, -9.468489646911621, -1.377238154411316, 1.6718814373016357, -10.452007293701172, -6.931250095367432, -5.5995612144470215, -4.347168922424316, -14.226879119873047, -19.649866104125977, -19.857938766479492, -9.020663261413574, -7.296884536743164, -6.955833435058594, -8.012944221496582, -20.323307037353516, -24.691524505615234, -13.062507629394531, -10.579833984375, -10.464911460876465, -18.016658782958984, -32.09123229980469, -20.997093200683594, -20.990219116210938, -23.327144622802734, -30.134925842285156, -18.712364196777344, -16.324193954467773, -22.708328247070312, -20.72455406188965, -17.129676818847656, -16.059917449951172, -22.96393394470215, -15.839066505432129, -20.216468811035156, -26.747264862060547, -17.575531005859375, -20.672588348388672, -32.55470657348633, -24.46990203857422, -24.13581085205078, -29.460975646972656, -29.58704376220703, -28.34756088256836, -28.118022918701172, -31.109130859375, -27.66533088684082, -32.67094421386719, -34.95331954956055, -34.953529357910156, -29.68937110900879, -29.51669692993164, -31.943208694458008, -28.89169692993164, -35.84844970703125, -32.294891357421875, -38.981056213378906, -37.60842514038086, -41.67015075683594, -41.1839485168457, -40.084564208984375, -39.86931610107422, -38.586883544921875, -41.393131256103516, -37.7585334777832, -39.80084991455078, -40.8037109375, -43.25237274169922, -48.36528396606445, -50.28140640258789, -49.22107696533203, -48.1053466796875, -47.45262145996094, -47.87555694580078, -48.56074523925781, -51.75066375732422, -53.2236328125, -54.6137809753418, -55.6431770324707, -55.83462142944336, -56.06983184814453, -57.32389831542969, -61.468170166015625, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [4.840516090393066, -18.501344680786133, -20.917484283447266, -27.32347869873047, -28.43663787841797, -22.252904891967773, -18.01663589477539, -11.915672302246094, 1.4209996461868286, 12.261351585388184, 13.106391906738281, 8.267155647277832, -23.007598876953125, -25.964839935302734, -22.47209358215332, -17.112377166748047, -13.287214279174805, -4.520015239715576, 3.6804018020629883, 8.90647029876709, 3.971334457397461, -3.0823822021484375, -2.3374531269073486, -14.034912109375, -13.065624237060547, -15.24041748046875, -12.959345817565918, -9.489678382873535, -10.41201114654541, -10.640869140625, -1.5557668209075928, 2.221752166748047, 0.6426450610160828, 7.087721824645996, -2.157430410385132, -22.86862564086914, -24.671794891357422, -32.59833526611328, -21.268482208251953, -7.697301864624023, -4.721806049346924, 0.09550964832305908, -4.661286354064941, -3.3403074741363525, -0.15109670162200928, -18.175434112548828, -16.36333656311035, -6.43693208694458, -2.8926496505737305, -5.641183376312256, -5.795302867889404, -17.247440338134766, -7.778456211090088, -12.373747825622559, -7.049874782562256, -6.130672454833984, -12.945398330688477, -20.036415100097656, -18.98963165283203, -12.0381498336792, -11.185402870178223, -16.873859405517578, -25.050853729248047, -23.257062911987305, -23.915218353271484, -21.87584686279297, -29.109420776367188, -17.11728286743164, -19.785432815551758, -26.11833953857422, -21.33919906616211, -16.40896987915039, -14.274497032165527, -22.021120071411133, -13.25016975402832, -17.581523895263672, -21.246793746948242, -17.001720428466797, -19.962627410888672, -26.57364845275879, -22.957212448120117, -22.802494049072266, -27.704509735107422, -24.494068145751953, -33.458351135253906, -30.646076202392578, -30.44805908203125, -32.5338134765625, -28.79288673400879, -32.37179183959961, -33.491111755371094, -30.59859275817871, -31.39240074157715, -29.772871017456055, -29.03846549987793, -31.702529907226562, -28.839218139648438, -35.8621711730957, -33.493988037109375, -39.92837905883789, -41.445411682128906, -42.00901794433594, -40.99114227294922, -37.865234375, -38.044029235839844, -35.45977783203125, -39.15608596801758, -40.06648635864258, -42.7479133605957, -44.922523498535156, -43.00949478149414, -45.934329986572266, -45.80742263793945, -47.03514099121094, -47.73632049560547, -47.02396011352539, -47.675472259521484, -47.20794677734375, -50.59120178222656, -53.47614669799805, -54.45109558105469, -54.307029724121094, -54.81241226196289, -57.247867584228516, -61.674346923828125, -61.988258361816406, -61.988258361816406, -61.988258361816406], [4.360371112823486, -19.654247283935547, -25.110750198364258, -29.098081588745117, -31.167810440063477, -26.913333892822266, -23.163410186767578, -16.86794662475586, -10.580910682678223, 7.178738594055176, 11.258870124816895, 8.512535095214844, -20.216665267944336, -26.426921844482422, -24.426639556884766, -23.162418365478516, -19.34444808959961, -14.102777481079102, -7.606983661651611, -3.002803325653076, -0.6058593988418579, 0.03466137498617172, -0.634904146194458, -9.611587524414062, -17.79117202758789, -21.184417724609375, -21.870088577270508, -18.413394927978516, -18.998302459716797, -15.65136432647705, -0.5688263773918152, 6.241816997528076, 6.864569187164307, 6.404011249542236, -4.666377067565918, -26.783740997314453, -31.409435272216797, -36.29429244995117, -30.140270233154297, -18.827011108398438, -8.136615753173828, 2.383413553237915, 0.5702880620956421, -1.6699395179748535, 0.1375592052936554, -20.72310447692871, -30.55997657775879, -18.28607940673828, -12.341946601867676, -5.635251998901367, -2.874070644378662, -11.086404800415039, -4.924670219421387, -16.182092666625977, -19.131757736206055, -15.366151809692383, -15.282096862792969, -17.678783416748047, -12.756719589233398, -12.314295768737793, -21.376121520996094, -26.71785545349121, -24.440601348876953, -22.933971405029297, -19.770715713500977, -18.693199157714844, -32.729827880859375, -13.55119800567627, -14.161293029785156, -23.554061889648438, -22.574235916137695, -16.119674682617188, -11.523759841918945, -20.271303176879883, -15.599929809570312, -20.248104095458984, -20.23577117919922, -19.300405502319336, -20.88494300842285, -23.554887771606445, -21.848392486572266, -25.75446891784668, -26.066600799560547, -24.462238311767578, -30.614181518554688, -27.075313568115234, -28.631275177001953, -35.764060974121094, -29.790422439575195, -33.357025146484375, -35.53266143798828, -31.413137435913086, -33.758460998535156, -27.694416046142578, -29.851337432861328, -29.707618713378906, -28.650636672973633, -33.73656463623047, -33.1318244934082, -37.09086227416992, -37.15896224975586, -40.766502380371094, -39.20698928833008, -38.91952133178711, -37.565223693847656, -37.97676467895508, -39.341373443603516, -41.19682312011719, -41.236759185791016, -41.28934860229492, -40.45375442504883, -43.04719924926758, -44.9007453918457, -48.045230865478516, -49.77418518066406, -48.05096435546875, -46.255157470703125, -46.221527099609375, -49.1127815246582, -51.19599914550781, -51.60951614379883, -53.05949401855469, -54.64905548095703, -57.5334587097168, -60.87948226928711, -61.988258361816406, -61.988258361816406, -61.988258361816406], [2.090158462524414, -18.442378997802734, -23.546585083007812, -33.19775390625, -38.1053466796875, -35.05189514160156, -28.987138748168945, -22.37514877319336, -13.981067657470703, 1.5265896320343018, 13.948284149169922, 10.499116897583008, -19.132753372192383, -23.616470336914062, -23.77659797668457, -32.12661361694336, -28.217201232910156, -23.140445709228516, -18.155445098876953, -12.153266906738281, -6.956984996795654, 7.076567649841309, 5.853280067443848, -13.174345016479492, -20.854660034179688, -29.106367111206055, -32.74201202392578, -27.969398498535156, -27.73149299621582, -25.514057159423828, -7.43364143371582, 0.5669947862625122, 6.761871337890625, 5.259619235992432, -2.530416250228882, -24.588430404663086, -38.010990142822266, -39.24113845825195, -35.429588317871094, -33.30113983154297, -15.93075180053711, -4.421744346618652, -2.5480916500091553, 1.643923044204712, 2.1774230003356934, -16.70343017578125, -36.171566009521484, -30.603015899658203, -29.74227523803711, -14.407025337219238, -9.34650993347168, -5.980954170227051, -1.1067683696746826, -16.658790588378906, -35.667015075683594, -33.35792922973633, -24.903562545776367, -20.106037139892578, -8.253461837768555, -6.507911682128906, -26.633207321166992, -43.929019927978516, -33.44176483154297, -29.198867797851562, -17.993648529052734, -14.388141632080078, -36.382266998291016, -19.42978286743164, -17.942256927490234, -13.29226303100586, -13.338968276977539, -24.54818344116211, -18.35673713684082, -16.83592987060547, -10.802309036254883, -25.323665618896484, -25.566041946411133, -18.712900161743164, -18.072513580322266, -28.117046356201172, -24.143386840820312, -22.255098342895508, -21.531085968017578, -32.32080078125, -28.698928833007812, -24.951053619384766, -32.81509780883789, -35.5103759765625, -34.303611755371094, -38.13938522338867, -31.884807586669922, -30.35567855834961, -35.392181396484375, -26.22661590576172, -32.90726089477539, -30.44597625732422, -31.620168685913086, -33.266422271728516, -31.505535125732422, -37.38915252685547, -33.51747131347656, -42.12198257446289, -38.92353820800781, -43.62579345703125, -40.00445556640625, -42.14155578613281, -39.185081481933594, -41.215118408203125, -41.608802795410156, -40.19071578979492, -42.05284118652344, -42.06473922729492, -45.39252853393555, -48.73921203613281, -50.154518127441406, -50.14963150024414, -50.08512496948242, -50.85558319091797, -49.45192337036133, -50.1756591796875, -51.572166442871094, -54.35396194458008, -56.989768981933594, -60.454078674316406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [2.5469348430633545, -29.19131088256836, -29.861366271972656, -36.175140380859375, -41.44532012939453, -46.06889343261719, -34.35527801513672, -32.0019416809082, -32.28343200683594, -1.5504621267318726, 13.677410125732422, 10.85309886932373, -18.958614349365234, -23.693323135375977, -26.833656311035156, -37.50304412841797, -31.360368728637695, -34.8441276550293, -33.3082389831543, -30.896055221557617, -20.08335304260254, 11.23501205444336, 11.217055320739746, -9.251798629760742, -24.59211540222168, -25.785770416259766, -42.409950256347656, -35.734310150146484, -31.342510223388672, -31.649324417114258, -26.954185485839844, -21.876317977905273, 7.479714393615723, 13.058161735534668, 4.928533554077148, -25.349437713623047, -44.195335388183594, -40.066524505615234, -42.6948127746582, -42.236690521240234, -31.37700653076172, -25.547800064086914, -17.551197052001953, -1.4281880855560303, 1.541405439376831, -14.319196701049805, -45.839351654052734, -44.46686553955078, -43.51237869262695, -36.42649841308594, -31.16170883178711, -2.531860113143921, 1.9555771350860596, -14.562915802001953, -43.64948272705078, -48.08070755004883, -42.789642333984375, -34.357486724853516, -10.150310516357422, -6.415028095245361, -25.493858337402344, -52.013248443603516, -46.306182861328125, -41.77858352661133, -14.79449462890625, -12.064743995666504, -32.02632522583008, -42.678245544433594, -38.96226119995117, -10.415839195251465, -11.283435821533203, -43.03884506225586, -40.68681716918945, -19.710739135742188, -11.947296142578125, -25.193613052368164, -41.08738327026367, -22.835647583007812, -15.862943649291992, -30.212230682373047, -40.281959533691406, -19.989110946655273, -19.484567642211914, -46.07293701171875, -29.58493423461914, -24.58646583557129, -40.7303466796875, -36.08457946777344, -31.602209091186523, -47.79661178588867, -33.03444290161133, -33.0825309753418, -41.36534881591797, -28.766578674316406, -38.52314758300781, -30.94482421875, -31.492294311523438, -35.5520133972168, -30.579652786254883, -42.613502502441406, -33.37810516357422, -45.473628997802734, -38.07143020629883, -47.72068786621094, -42.86003112792969, -46.417076110839844, -42.958030700683594, -43.039466857910156, -44.041385650634766, -41.041748046875, -45.3794059753418, -43.533416748046875, -47.238502502441406, -50.2452278137207, -51.665992736816406, -55.519805908203125, -56.22095489501953, -55.69890594482422, -53.04616928100586, -53.63426208496094, -55.637672424316406, -57.408470153808594, -59.6348762512207, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [2.901365280151367, -36.59880065917969, -35.78078842163086, -35.886131286621094, -39.578067779541016, -45.895076751708984, -41.64982604980469, -32.387535095214844, -31.738985061645508, -3.785315990447998, 11.577322006225586, 9.310103416442871, -15.833550453186035, -24.22234344482422, -28.322202682495117, -38.38414001464844, -31.16263198852539, -36.872623443603516, -40.454017639160156, -44.29358673095703, -24.142650604248047, 14.05153751373291, 15.740818977355957, -5.196832656860352, -27.522197723388672, -27.8842830657959, -50.323585510253906, -41.80780792236328, -33.710914611816406, -37.103668212890625, -39.91301345825195, -23.775531768798828, 7.159894943237305, 14.852977752685547, 8.126413345336914, -26.89582061767578, -45.37604522705078, -40.24863815307617, -41.34717559814453, -47.27169418334961, -42.51026153564453, -34.92010498046875, -18.180723190307617, 2.5494251251220703, 1.956687569618225, -16.832963943481445, -44.741249084472656, -52.98554992675781, -52.15528106689453, -52.13180923461914, -43.535133361816406, -2.013413429260254, 2.6022372245788574, -12.851815223693848, -44.42100524902344, -51.64730453491211, -47.9975700378418, -47.09115982055664, -14.228103637695312, -8.785079002380371, -22.777732849121094, -55.44976043701172, -49.365638732910156, -45.73600769042969, -12.31195068359375, -12.653383255004883, -28.152423858642578, -59.06559753417969, -50.75092697143555, -13.586264610290527, -14.39465618133545, -39.366233825683594, -49.03193664550781, -20.508281707763672, -11.75851058959961, -22.224510192871094, -56.28594970703125, -22.343238830566406, -14.388051986694336, -28.577993392944336, -59.550933837890625, -21.089418411254883, -21.448213577270508, -44.7687873840332, -28.323856353759766, -24.31829261779785, -43.549957275390625, -39.663509368896484, -34.40693664550781, -51.038002014160156, -34.31239318847656, -34.28662872314453, -40.9812126159668, -28.92278289794922, -37.232757568359375, -30.897836685180664, -30.903114318847656, -36.52296447753906, -30.977645874023438, -43.19346618652344, -34.416141510009766, -45.74653244018555, -41.21261215209961, -50.23509216308594, -47.49333190917969, -47.53268814086914, -43.580467224121094, -43.47393798828125, -43.90591049194336, -42.25262451171875, -46.408546447753906, -44.72455596923828, -49.13433837890625, -52.122520446777344, -53.482521057128906, -56.37672424316406, -55.918846130371094, -55.0279426574707, -53.88390350341797, -54.980377197265625, -56.8337287902832, -58.47976303100586, -60.81427001953125, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [2.1016018390655518, -33.436161041259766, -42.728050231933594, -34.218650817871094, -37.49533462524414, -47.90420150756836, -40.503238677978516, -32.12744140625, -33.105712890625, -7.246074199676514, 6.556856155395508, 5.363665580749512, -14.475802421569824, -24.48751449584961, -30.151254653930664, -39.883277893066406, -30.626840591430664, -36.924842834472656, -40.322303771972656, -41.50951385498047, -21.619909286499023, 14.407838821411133, 17.052324295043945, -2.353309154510498, -32.716209411621094, -33.18828201293945, -47.63340759277344, -46.115360260009766, -38.032676696777344, -33.81864929199219, -36.52412796020508, -21.612239837646484, 1.3474204540252686, 11.60976791381836, 7.024726390838623, -25.132434844970703, -39.808780670166016, -42.71550750732422, -45.162391662597656, -53.201847076416016, -46.646026611328125, -37.63944625854492, -20.456958770751953, 5.351909637451172, 4.607929706573486, -13.803251266479492, -41.901145935058594, -51.00178527832031, -52.132843017578125, -49.11347198486328, -39.94521713256836, -5.296384811401367, -0.35751837491989136, -8.55453872680664, -44.63237762451172, -51.439857482910156, -50.34467315673828, -46.3222541809082, -12.102916717529297, -6.53831672668457, -23.218273162841797, -53.502445220947266, -54.21461486816406, -46.18732452392578, -13.07988166809082, -14.40687370300293, -26.878273010253906, -55.936607360839844, -49.204498291015625, -13.322110176086426, -12.497116088867188, -37.63945770263672, -52.965850830078125, -21.117687225341797, -13.75794506072998, -25.1676025390625, -56.767127990722656, -25.033897399902344, -15.813995361328125, -25.93671417236328, -58.11103057861328, -21.90853500366211, -22.792261123657227, -44.275455474853516, -31.606101989746094, -26.702787399291992, -42.980384826660156, -38.30372619628906, -32.03628158569336, -48.78816604614258, -31.01763916015625, -30.06856918334961, -40.7099494934082, -28.106918334960938, -35.044189453125, -31.866493225097656, -31.22894287109375, -39.20039749145508, -33.220306396484375, -45.154056549072266, -38.84251022338867, -47.992332458496094, -43.84571838378906, -48.3079948425293, -43.042945861816406, -46.141963958740234, -41.7568244934082, -44.14229965209961, -43.799476623535156, -44.11012268066406, -48.179542541503906, -47.21887969970703, -51.472312927246094, -53.035945892333984, -51.95207977294922, -52.81287384033203, -53.855308532714844, -53.74799728393555, -54.81679916381836, -56.67831039428711, -58.757240295410156, -59.853111267089844, -60.914310455322266, -61.60990905761719, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [1.0664317607879639, -32.30576705932617, -46.61883544921875, -33.88490295410156, -37.1945686340332, -47.777549743652344, -42.02679443359375, -37.45392608642578, -35.67364501953125, -9.961009979248047, 0.9725480675697327, 1.9553886651992798, -14.958391189575195, -26.40047264099121, -31.005136489868164, -37.444366455078125, -30.704944610595703, -36.427162170410156, -38.93328857421875, -35.54437255859375, -15.818527221679688, 10.86265754699707, 14.216758728027344, 0.34084320068359375, -34.88649368286133, -35.205528259277344, -44.225685119628906, -45.339317321777344, -35.2557258605957, -32.396751403808594, -38.802734375, -20.761701583862305, 4.8939642906188965, 10.269166946411133, 2.1847376823425293, -18.263671875, -38.28728485107422, -43.928550720214844, -48.1383171081543, -46.17656326293945, -41.60426712036133, -32.63226318359375, -15.959199905395508, 3.0916085243225098, 2.6228785514831543, -12.583975791931152, -43.6115837097168, -50.7349853515625, -50.20349884033203, -47.506690979003906, -41.98638153076172, -4.137905120849609, 2.0125033855438232, -7.321764945983887, -45.690460205078125, -52.27708435058594, -46.965755462646484, -44.65072250366211, -12.211692810058594, -6.497759819030762, -17.454410552978516, -50.95293426513672, -53.064544677734375, -42.15280532836914, -11.787803649902344, -13.195745468139648, -25.931190490722656, -56.85869216918945, -45.39219665527344, -14.05288314819336, -13.756340980529785, -35.75992202758789, -53.550697326660156, -23.82052230834961, -18.074989318847656, -27.445819854736328, -58.243412017822266, -24.359283447265625, -17.1671199798584, -27.99239158630371, -58.7285270690918, -22.897470474243164, -23.36676025390625, -43.907257080078125, -34.45677947998047, -28.721050262451172, -41.66311264038086, -32.85479736328125, -28.640573501586914, -47.67498779296875, -29.239151000976562, -28.63370704650879, -39.73614501953125, -28.535442352294922, -35.56843566894531, -33.995845794677734, -33.2946891784668, -43.26259994506836, -37.394248962402344, -48.4163703918457, -42.814212799072266, -48.322452545166016, -42.47433090209961, -46.31380081176758, -41.082069396972656, -45.369873046875, -41.53114318847656, -45.34999465942383, -45.025115966796875, -46.70087814331055, -50.4317626953125, -49.46586608886719, -51.041343688964844, -52.383689880371094, -51.46034240722656, -52.984928131103516, -55.07084274291992, -55.76614761352539, -57.23626708984375, -58.34397888183594, -59.602142333984375, -60.383148193359375, -61.46430969238281, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.17176270484924316, -32.367820739746094, -46.53595733642578, -34.318931579589844, -33.851959228515625, -37.39781951904297, -42.99090576171875, -41.2138786315918, -38.41386413574219, -7.635560989379883, 6.444293022155762, 4.684813976287842, -15.661739349365234, -26.96242904663086, -31.49900245666504, -37.36320114135742, -34.53364562988281, -38.58855056762695, -41.72199249267578, -34.14902114868164, -10.992897033691406, 5.041780471801758, 8.976081848144531, 0.346459299325943, -29.104007720947266, -32.228981018066406, -40.27083969116211, -46.44607162475586, -36.065040588378906, -36.136634826660156, -41.951988220214844, -20.54608917236328, 8.375460624694824, 13.225994110107422, 4.680147171020508, -17.356752395629883, -41.79420471191406, -44.02706527709961, -45.190223693847656, -43.83039474487305, -39.81608581542969, -32.91815185546875, -10.979297637939453, 1.3417612314224243, -2.1779420375823975, -15.025924682617188, -46.26383972167969, -51.76388168334961, -54.24137496948242, -51.33294677734375, -44.136573791503906, -3.8855443000793457, 1.6115952730178833, -8.80998706817627, -46.51292419433594, -53.851348876953125, -49.72135543823242, -41.70951461791992, -7.681432247161865, -4.456462383270264, -18.507341384887695, -51.081512451171875, -50.96216583251953, -34.0557746887207, -12.697361946105957, -13.581735610961914, -25.535385131835938, -55.3807487487793, -38.890865325927734, -15.310453414916992, -16.88412857055664, -33.11572265625, -55.96167755126953, -22.7767276763916, -17.260578155517578, -26.838056564331055, -57.60682678222656, -23.0530948638916, -18.23052978515625, -30.626632690429688, -57.637725830078125, -23.74654769897461, -24.324913024902344, -46.36220932006836, -32.62343978881836, -29.458908081054688, -44.408409118652344, -30.876644134521484, -27.979280471801758, -50.40026092529297, -28.962467193603516, -29.86640739440918, -38.75029754638672, -29.913312911987305, -37.31251525878906, -36.549686431884766, -36.69102478027344, -46.865394592285156, -42.51530456542969, -49.80638122558594, -44.00264358520508, -47.41819763183594, -41.72652816772461, -45.48055648803711, -40.821041107177734, -45.42408752441406, -42.76585006713867, -46.920738220214844, -47.38378143310547, -49.21009826660156, -52.46470642089844, -51.26014709472656, -51.88534164428711, -53.88306427001953, -53.359588623046875, -55.33155822753906, -57.53185272216797, -58.41504669189453, -58.96516418457031, -59.97230911254883, -60.98278045654297, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-0.6113427877426147, -34.06438446044922, -45.456146240234375, -37.22868347167969, -35.835697174072266, -36.85698318481445, -43.32522964477539, -41.483848571777344, -39.05709457397461, -6.29940128326416, 7.3944621086120605, 4.591677665710449, -18.00778579711914, -30.213951110839844, -33.622032165527344, -38.386558532714844, -39.753475189208984, -41.35602569580078, -39.67914962768555, -35.2990837097168, -9.476663589477539, 6.75349235534668, 7.5787506103515625, -0.7757915258407593, -30.177936553955078, -32.783504486083984, -38.451438903808594, -49.283653259277344, -40.215965270996094, -39.58869552612305, -41.144378662109375, -18.118741989135742, 5.990469932556152, 12.16732120513916, 6.81888484954834, -18.947141647338867, -48.49063491821289, -39.25917434692383, -42.370853424072266, -44.6468505859375, -42.390235900878906, -39.02025604248047, -9.816170692443848, 5.276980400085449, 2.292881727218628, -16.01952362060547, -45.24406814575195, -52.20878982543945, -56.13733673095703, -56.83576583862305, -44.598609924316406, -4.975608825683594, -0.2329709827899933, -9.616666793823242, -43.446266174316406, -54.278053283691406, -51.380062103271484, -41.08157730102539, -7.793362140655518, -5.186992645263672, -19.249126434326172, -51.16655349731445, -54.714088439941406, -31.17142105102539, -12.829957008361816, -13.14627742767334, -26.428539276123047, -53.80735397338867, -37.201568603515625, -18.208106994628906, -21.62472152709961, -32.59170150756836, -57.893795013427734, -21.009933471679688, -15.693655967712402, -25.75162124633789, -59.29114532470703, -22.638628005981445, -18.205583572387695, -28.950172424316406, -57.0698127746582, -25.54935646057129, -25.974246978759766, -45.99933624267578, -31.40346336364746, -29.952392578125, -48.39447021484375, -30.53907012939453, -27.572019577026367, -49.603416442871094, -29.660717010498047, -31.121604919433594, -40.166595458984375, -32.718482971191406, -39.830589294433594, -41.2238655090332, -42.47613525390625, -49.609779357910156, -44.94776916503906, -47.92150115966797, -42.23772048950195, -45.43443298339844, -40.26258087158203, -44.677154541015625, -41.57817840576172, -47.35353469848633, -46.001495361328125, -50.880340576171875, -51.86811828613281, -51.43937683105469, -53.576881408691406, -52.10607147216797, -53.68295669555664, -56.15493392944336, -56.55092239379883, -59.37424087524414, -60.24468231201172, -60.4891242980957, -60.318965911865234, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-1.0952850580215454, -42.49106979370117, -47.36249923706055, -38.650146484375, -38.72310256958008, -44.80517578125, -44.440608978271484, -41.8961296081543, -38.246124267578125, -6.182703495025635, 4.133399486541748, -0.2966071367263794, -18.614269256591797, -35.276180267333984, -37.03628921508789, -38.97142791748047, -32.45787048339844, -40.34619140625, -39.79922103881836, -39.43204879760742, -10.588525772094727, 10.037633895874023, 10.490264892578125, -1.6398611068725586, -36.229713439941406, -36.94499588012695, -42.94026184082031, -47.92786407470703, -39.412017822265625, -39.45023727416992, -41.77793884277344, -17.023479461669922, 3.779895782470703, 7.342680931091309, 2.002636194229126, -19.432172775268555, -39.73280334472656, -41.92218780517578, -43.63465118408203, -47.00851821899414, -48.24824905395508, -47.5438232421875, -9.375859260559082, 3.321378469467163, -0.07256035506725311, -17.846261978149414, -51.471500396728516, -53.898399353027344, -54.32090377807617, -54.29825210571289, -45.89686965942383, -5.2112812995910645, -0.21765059232711792, -9.795927047729492, -45.75397491455078, -55.58930206298828, -52.287567138671875, -40.745361328125, -7.7865447998046875, -5.43569278717041, -22.067962646484375, -54.64975357055664, -56.20681381225586, -31.799318313598633, -12.516731262207031, -12.779911041259766, -29.105634689331055, -55.92103958129883, -38.3869514465332, -19.215200424194336, -22.250185012817383, -34.193939208984375, -58.010562896728516, -20.11336326599121, -15.083952903747559, -24.78388214111328, -61.988258361816406, -23.988313674926758, -19.18625831604004, -30.16283416748047, -58.36962127685547, -28.508167266845703, -29.499475479125977, -49.61357498168945, -32.04355239868164, -30.387537002563477, -48.936466217041016, -30.513080596923828, -27.33448028564453, -47.549560546875, -30.668338775634766, -31.786113739013672, -43.025238037109375, -35.66584777832031, -42.359825134277344, -45.677032470703125, -46.34531021118164, -48.9747428894043, -43.99871063232422, -46.389747619628906, -40.86647033691406, -44.69493103027344, -40.27130889892578, -45.582889556884766, -43.991580963134766, -50.48433303833008, -49.75895690917969, -53.526206970214844, -53.63417053222656, -52.21236801147461, -54.263301849365234, -53.35816192626953, -55.65412521362305, -58.47425079345703, -59.098121643066406, -60.95041275024414, -61.12506866455078, -61.434417724609375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-1.9456474781036377, -42.987178802490234, -48.46471405029297, -37.51249694824219, -37.33095169067383, -43.979698181152344, -45.367156982421875, -43.60589599609375, -36.49623489379883, -3.9585580825805664, 6.8280863761901855, 3.0725934505462646, -14.897809982299805, -34.097450256347656, -37.04024887084961, -34.749210357666016, -27.017799377441406, -33.359676361083984, -39.636688232421875, -37.056541442871094, -8.859557151794434, 13.004841804504395, 14.47847843170166, -2.0056540966033936, -33.773834228515625, -38.17754364013672, -42.28941345214844, -41.667205810546875, -40.28559875488281, -36.49020767211914, -41.74293518066406, -18.08903694152832, 8.271167755126953, 11.679351806640625, 2.5824759006500244, -18.971830368041992, -40.99056625366211, -41.44385528564453, -39.28984451293945, -45.97871780395508, -45.016666412353516, -41.24251937866211, -8.759308815002441, 4.089550495147705, 1.8048220872879028, -14.377509117126465, -40.73754119873047, -47.620643615722656, -47.54201889038086, -47.261165618896484, -44.28113555908203, -5.646951198577881, -1.145784616470337, -10.630273818969727, -40.710601806640625, -55.02986526489258, -56.20476531982422, -40.848201751708984, -11.047844886779785, -8.523355484008789, -22.30925750732422, -50.640281677246094, -48.1143913269043, -30.694124221801758, -12.579392433166504, -13.300483703613281, -30.862995147705078, -57.65998840332031, -36.83646011352539, -19.106517791748047, -22.032482147216797, -34.230979919433594, -60.479339599609375, -20.208805084228516, -14.85297966003418, -24.26682472229004, -59.712337493896484, -26.06647491455078, -22.000381469726562, -31.931072235107422, -52.932987213134766, -31.32044792175293, -33.557010650634766, -55.69642639160156, -31.4754638671875, -29.353988647460938, -50.621559143066406, -31.16021156311035, -28.57903289794922, -49.52726364135742, -33.109031677246094, -34.9418830871582, -46.265647888183594, -39.10931396484375, -45.56034851074219, -46.86307907104492, -47.2686767578125, -47.22224807739258, -42.84613037109375, -46.100772857666016, -40.99201202392578, -46.074851989746094, -42.797237396240234, -49.10602951049805, -48.538230895996094, -54.36083221435547, -52.807960510253906, -54.38261413574219, -54.77606201171875, -54.472084045410156, -57.15299606323242, -56.79774856567383, -59.812313079833984, -61.988258361816406, -61.947265625, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.282799243927002, -42.30827713012695, -50.751121520996094, -37.8297119140625, -38.852439880371094, -42.00315475463867, -51.15947723388672, -47.75890350341797, -38.91069030761719, -1.2610211372375488, 13.312091827392578, 11.126251220703125, -10.340534210205078, -33.55384063720703, -35.908668518066406, -35.488162994384766, -27.735490798950195, -33.755889892578125, -43.05360794067383, -38.192928314208984, -8.847200393676758, 10.453429222106934, 11.409287452697754, 1.3992946147918701, -33.616790771484375, -41.272499084472656, -40.88216781616211, -40.98508834838867, -40.226139068603516, -39.67853927612305, -41.34956741333008, -17.62745475769043, 7.282008171081543, 12.258563995361328, 7.255558967590332, -14.111495018005371, -47.6963005065918, -41.98141098022461, -40.41400909423828, -46.61692810058594, -43.11735534667969, -40.47338104248047, -9.896385192871094, 4.3039445877075195, 1.2313549518585205, -13.195271492004395, -36.95632553100586, -44.63127899169922, -46.33789825439453, -48.54106903076172, -40.35676956176758, -5.694975852966309, -1.3444998264312744, -8.880500793457031, -35.37177658081055, -53.72932434082031, -54.96867752075195, -40.65208053588867, -14.192648887634277, -12.622880935668945, -24.640731811523438, -46.59717559814453, -48.84235763549805, -31.28757095336914, -13.322924613952637, -13.199270248413086, -26.2667293548584, -55.03313064575195, -36.72745132446289, -17.679006576538086, -17.646482467651367, -30.04690170288086, -58.05973434448242, -21.175020217895508, -16.1594295501709, -24.4132080078125, -53.10154342651367, -28.854263305664062, -24.796266555786133, -33.67668533325195, -52.07801818847656, -33.26334762573242, -33.794403076171875, -57.13738250732422, -31.52733039855957, -29.074077606201172, -43.49943542480469, -33.414161682128906, -30.795120239257812, -44.8265495300293, -36.83171081542969, -38.66270065307617, -48.6552848815918, -41.12337112426758, -46.113792419433594, -45.728702545166016, -44.81977462768555, -46.273468017578125, -41.89474105834961, -46.28538513183594, -42.500877380371094, -48.35283660888672, -47.25310516357422, -53.10730743408203, -51.849945068359375, -55.59882354736328, -53.768714904785156, -55.671669006347656, -56.07149124145508, -57.19633483886719, -59.91852569580078, -60.3565559387207, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-4.428867816925049, -40.547691345214844, -49.10448455810547, -39.715030670166016, -39.19203186035156, -40.071128845214844, -52.956138610839844, -48.580631256103516, -42.14834213256836, -0.8756997585296631, 16.18048095703125, 14.681977272033691, -8.588690757751465, -32.362548828125, -33.63597106933594, -40.85981369018555, -35.244632720947266, -39.074161529541016, -42.744895935058594, -35.3800048828125, -12.980491638183594, 6.848630428314209, 8.83242130279541, 1.8828035593032837, -30.250782012939453, -34.076011657714844, -40.35823440551758, -43.5477294921875, -40.35911560058594, -44.908966064453125, -40.72837829589844, -19.937192916870117, 2.497046947479248, 7.5562028884887695, 5.356723785400391, -11.134160995483398, -45.445831298828125, -46.08782958984375, -48.444976806640625, -49.31655502319336, -46.144020080566406, -42.128822326660156, -16.108243942260742, 1.6059050559997559, 2.2386221885681152, -7.221785545349121, -37.93456268310547, -49.93566131591797, -47.579246520996094, -49.030601501464844, -40.93059158325195, -8.630784034729004, -1.6344057321548462, -7.672393798828125, -29.99828338623047, -55.303627014160156, -55.95884323120117, -45.14503479003906, -22.09226417541504, -19.712921142578125, -23.38702964782715, -45.71168518066406, -51.06870651245117, -37.50517272949219, -16.481605529785156, -13.624561309814453, -24.816884994506836, -55.63858413696289, -42.34440612792969, -17.23941993713379, -14.267784118652344, -26.987571716308594, -59.30682373046875, -25.510986328125, -19.55549430847168, -26.138004302978516, -48.33625411987305, -32.83312225341797, -26.24861717224121, -32.15740966796875, -55.63500213623047, -32.793251037597656, -30.113204956054688, -49.296112060546875, -33.472496032714844, -29.114810943603516, -38.24507141113281, -37.09394836425781, -33.05881118774414, -42.143802642822266, -42.425750732421875, -41.40857696533203, -53.0380859375, -42.09800720214844, -45.619808197021484, -45.91626739501953, -42.548301696777344, -47.36908721923828, -41.84577178955078, -47.28484344482422, -45.77104187011719, -51.03643798828125, -51.797874450683594, -55.513526916503906, -53.03208923339844, -56.09739685058594, -54.41433334350586, -57.62281799316406, -57.25309371948242, -60.48081970214844, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-4.594429016113281, -39.07242202758789, -47.151588439941406, -39.30884552001953, -40.42095184326172, -43.66291809082031, -51.058135986328125, -45.83633804321289, -39.32857131958008, -1.5239702463150024, 16.29737663269043, 14.916280746459961, -8.927034378051758, -30.405214309692383, -34.10980987548828, -41.37175750732422, -37.96685028076172, -43.68016815185547, -43.42490768432617, -35.99861145019531, -22.358665466308594, 6.53413724899292, 7.552502155303955, 1.152042269706726, -29.066116333007812, -34.044029235839844, -45.0001220703125, -41.18274688720703, -39.547725677490234, -39.469749450683594, -44.57185363769531, -27.077171325683594, 4.509573459625244, 11.056108474731445, 3.7201857566833496, -12.281837463378906, -42.35478973388672, -42.16732406616211, -42.40650177001953, -46.92794418334961, -49.72344970703125, -43.90635681152344, -29.143070220947266, 2.713696002960205, 4.283082485198975, -9.080812454223633, -40.42319869995117, -51.97269058227539, -49.526214599609375, -54.73577880859375, -41.88604736328125, -9.773561477661133, -3.380275011062622, -8.720881462097168, -30.71913719177246, -51.90248489379883, -53.68170928955078, -51.327117919921875, -19.21122169494629, -14.780704498291016, -23.94239616394043, -46.89339065551758, -51.43789291381836, -47.52833938598633, -18.57668113708496, -14.928829193115234, -25.969812393188477, -55.03104782104492, -47.56672286987305, -17.17038345336914, -13.518553733825684, -27.81256675720215, -59.4643440246582, -30.350732803344727, -22.186243057250977, -28.648719787597656, -50.09086608886719, -36.20475769042969, -27.221851348876953, -33.00695037841797, -60.69580841064453, -30.65040397644043, -27.838214874267578, -48.07416915893555, -34.3533935546875, -28.597610473632812, -37.83305358886719, -40.987060546875, -35.956600189208984, -45.035316467285156, -47.0162353515625, -43.193939208984375, -56.50157165527344, -42.567501068115234, -45.7573356628418, -45.04341506958008, -41.0450325012207, -49.12774658203125, -42.68238830566406, -49.55625534057617, -49.5381965637207, -54.70392608642578, -53.106101989746094, -56.50233459472656, -52.968528747558594, -56.69061279296875, -54.9766960144043, -59.92432403564453, -59.17165756225586, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-4.1228837966918945, -39.44468307495117, -46.741363525390625, -38.05467224121094, -41.14142608642578, -46.19325256347656, -46.80088806152344, -43.50338363647461, -38.678672790527344, -2.118452787399292, 14.262809753417969, 12.476755142211914, -11.440494537353516, -30.269428253173828, -32.484458923339844, -39.341514587402344, -37.1229362487793, -41.688209533691406, -39.627140045166016, -40.16112518310547, -17.600574493408203, 10.103611946105957, 12.023069381713867, -0.620238184928894, -32.125614166259766, -38.89599609375, -44.73835372924805, -39.81161117553711, -35.37270736694336, -36.611045837402344, -43.49674987792969, -24.33588218688965, 4.717998504638672, 12.146710395812988, 6.181016445159912, -18.125818252563477, -44.696964263916016, -39.71907043457031, -42.21992492675781, -48.002845764160156, -51.8183708190918, -45.088111877441406, -20.554780960083008, -0.07357992976903915, 0.573166012763977, -12.076643943786621, -39.162784576416016, -54.27436447143555, -54.96974182128906, -54.88435745239258, -45.346527099609375, -8.469229698181152, -2.1943678855895996, -11.566205978393555, -36.15074920654297, -47.59027862548828, -49.296688079833984, -48.4449348449707, -16.304075241088867, -11.750175476074219, -21.449581146240234, -51.68121337890625, -50.239044189453125, -47.081241607666016, -18.38087272644043, -15.98574447631836, -30.226869583129883, -51.94546127319336, -46.629364013671875, -15.165546417236328, -13.791984558105469, -33.09016799926758, -59.4912109375, -32.90784454345703, -25.762331008911133, -33.082374572753906, -57.16204071044922, -36.55218505859375, -29.025287628173828, -36.199337005615234, -60.43437194824219, -28.237293243408203, -27.318029403686523, -51.84522247314453, -33.44334411621094, -28.460599899291992, -40.770973205566406, -43.517154693603516, -39.26992416381836, -51.40552520751953, -49.62260437011719, -47.803260803222656, -57.31499099731445, -43.585819244384766, -48.305564880371094, -43.28657150268555, -40.9814453125, -50.08693313598633, -44.12706756591797, -53.375885009765625, -53.483585357666016, -59.50151824951172, -55.24811553955078, -58.6394157409668, -53.60023880004883, -58.246742248535156, -55.905967712402344, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.852285861968994, -47.71196746826172, -46.93038558959961, -38.79014587402344, -43.00581359863281, -48.677486419677734, -48.031883239746094, -44.08084487915039, -36.53215789794922, -4.909673690795898, 9.440340042114258, 7.705037593841553, -14.447420120239258, -32.54566955566406, -34.36277770996094, -35.83302688598633, -30.761701583862305, -38.894596099853516, -39.81410217285156, -42.57411575317383, -19.660070419311523, 12.331354141235352, 15.004251480102539, -3.1007888317108154, -36.937095642089844, -45.875640869140625, -45.09242248535156, -40.09025573730469, -36.823143005371094, -39.30851364135742, -40.50927734375, -23.25586700439453, 0.18639859557151794, 7.405930519104004, 3.3991169929504395, -24.628578186035156, -44.13917922973633, -43.58378601074219, -47.01606369018555, -49.05835723876953, -54.78321075439453, -45.231712341308594, -20.248905181884766, 1.6239867210388184, 2.3349742889404297, -11.287240982055664, -48.95998001098633, -53.12839889526367, -52.61376190185547, -55.72574996948242, -49.13417434692383, -10.121391296386719, -3.3016860485076904, -10.175765991210938, -49.13700866699219, -48.41997528076172, -51.12643814086914, -51.356754302978516, -13.56885814666748, -9.76047134399414, -23.753080368041992, -54.556678771972656, -50.264503479003906, -50.012428283691406, -17.850954055786133, -16.922588348388672, -33.80116271972656, -53.0203971862793, -48.34083938598633, -15.28207778930664, -14.872774124145508, -37.648284912109375, -61.988258361816406, -36.36917495727539, -30.30156707763672, -38.59593200683594, -61.988258361816406, -37.49354553222656, -31.213851928710938, -39.932472229003906, -61.988258361816406, -29.000490188598633, -28.95770835876465, -55.78691482543945, -33.84300994873047, -29.606781005859375, -43.8298225402832, -43.1980094909668, -37.9343147277832, -51.88658142089844, -53.28645324707031, -52.12567138671875, -59.36825180053711, -47.569725036621094, -53.924034118652344, -43.50141525268555, -41.80523681640625, -52.051883697509766, -46.56103515625, -56.97394561767578, -56.009193420410156, -61.988258361816406, -60.12880325317383, -61.988258361816406, -56.408782958984375, -61.19602966308594, -58.431243896484375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.989809036254883, -49.16206741333008, -48.43459701538086, -39.09070587158203, -40.917945861816406, -46.02794647216797, -50.52135467529297, -42.90650177001953, -36.99174880981445, -9.678372383117676, 1.2505812644958496, 1.9510746002197266, -16.772663116455078, -34.64828109741211, -38.515220642089844, -32.8536262512207, -25.893735885620117, -34.47272872924805, -39.35333251953125, -36.32038497924805, -15.787771224975586, 10.128565788269043, 12.730552673339844, -4.873190879821777, -30.617216110229492, -40.07023620605469, -48.72714614868164, -42.54600524902344, -39.34848403930664, -39.40890121459961, -41.76377868652344, -24.765708923339844, 2.720658302307129, 7.81909704208374, -1.1595847606658936, -19.26861572265625, -40.8660888671875, -45.14064025878906, -44.83039474487305, -50.645660400390625, -57.530235290527344, -47.03921890258789, -21.77657699584961, 1.732579231262207, 0.7259278893470764, -15.17746353149414, -37.13220977783203, -51.740516662597656, -50.328453063964844, -55.7243537902832, -48.47335433959961, -11.462646484375, -4.35093879699707, -12.574629783630371, -44.10358810424805, -50.91118621826172, -51.215721130371094, -54.191131591796875, -14.111352920532227, -9.990235328674316, -25.354156494140625, -54.82787322998047, -53.969390869140625, -51.40531921386719, -18.37234878540039, -16.778579711914062, -36.47341537475586, -58.1846809387207, -49.905643463134766, -16.205751419067383, -15.37575626373291, -38.53242492675781, -61.988258361816406, -39.40966033935547, -32.7241096496582, -41.1268196105957, -61.988258361816406, -41.13462448120117, -34.573814392089844, -44.18838119506836, -61.988258361816406, -31.814193725585938, -32.544456481933594, -54.48183059692383, -36.285789489746094, -31.666072845458984, -46.85497283935547, -41.966712951660156, -36.59053421020508, -51.42207336425781, -51.72420120239258, -49.58465576171875, -61.988258361816406, -55.023555755615234, -60.40643310546875, -46.00104522705078, -44.6007194519043, -56.01230239868164, -50.70328140258789, -61.709190368652344, -58.034610748291016, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.59784698486328, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-4.720171928405762, -46.44017028808594, -42.845008850097656, -39.3184700012207, -41.99361801147461, -44.72807312011719, -55.043121337890625, -46.73410415649414, -44.837249755859375, -10.201313018798828, 6.06643009185791, 5.976388454437256, -12.033738136291504, -33.704673767089844, -37.92460632324219, -32.5147705078125, -24.406818389892578, -32.735694885253906, -41.92726516723633, -37.60223388671875, -12.890138626098633, 2.7094318866729736, 7.370705604553223, -5.683953762054443, -28.00885009765625, -36.92073059082031, -46.461997985839844, -45.11518096923828, -42.367584228515625, -42.446258544921875, -46.32871627807617, -26.02130126953125, 3.738405704498291, 10.497159004211426, 4.719719409942627, -11.48951530456543, -41.51898193359375, -41.94940185546875, -42.58711242675781, -52.78588104248047, -51.307064056396484, -40.28434371948242, -20.254169464111328, -1.9979994297027588, -1.1330019235610962, -6.254114151000977, -24.76646614074707, -51.49994659423828, -46.602195739746094, -53.812400817871094, -54.634517669677734, -12.541585922241211, -4.4495391845703125, -13.536323547363281, -25.59349250793457, -51.91441345214844, -49.4454231262207, -52.534542083740234, -20.69106674194336, -13.468578338623047, -20.365449905395508, -46.37751007080078, -53.941627502441406, -46.14875793457031, -18.841541290283203, -16.509910583496094, -23.90148162841797, -50.99064636230469, -50.37214660644531, -18.976238250732422, -16.65752601623535, -24.23321533203125, -51.492942810058594, -41.2236328125, -32.525657653808594, -33.94020462036133, -46.3101806640625, -47.4478759765625, -40.677391052246094, -45.25294876098633, -56.86267852783203, -36.76862335205078, -36.322052001953125, -47.56060028076172, -40.507930755615234, -35.672428131103516, -44.55157470703125, -44.25284957885742, -37.55093765258789, -43.71227264404297, -51.438297271728516, -47.43008041381836, -54.79056930541992, -58.784385681152344, -55.837955474853516, -51.26205062866211, -50.449337005615234, -60.636497497558594, -56.12548065185547, -61.988258361816406, -61.070308685302734, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-5.223016738891602, -37.2206916809082, -37.989688873291016, -40.03225326538086, -40.6009521484375, -43.62690734863281, -52.58549499511719, -48.084930419921875, -38.999603271484375, -10.578044891357422, 10.883870124816895, 11.349164009094238, -6.840057373046875, -35.79414749145508, -36.66497039794922, -33.39359664916992, -25.511859893798828, -34.01588821411133, -45.91596984863281, -40.3385124206543, -18.825031280517578, 2.2318010330200195, 9.03237247467041, 0.1989423632621765, -24.44969367980957, -34.58206558227539, -47.069190979003906, -43.89650344848633, -41.52772521972656, -36.3339958190918, -41.3570442199707, -25.96571159362793, -0.7461747527122498, 7.720552444458008, 6.257867813110352, -7.373817443847656, -38.50825500488281, -40.72767639160156, -43.424678802490234, -53.92662811279297, -51.01108932495117, -40.40035629272461, -26.725658416748047, -7.564663887023926, 2.651505708694458, 0.6912451386451721, -20.87871742248535, -46.534400939941406, -48.26130294799805, -54.622413635253906, -52.616127014160156, -21.80759620666504, -8.271230697631836, -7.6620635986328125, -18.52178955078125, -51.7357063293457, -48.846595764160156, -50.90523147583008, -27.552310943603516, -16.88722801208496, -20.566303253173828, -40.53707504272461, -56.19010925292969, -50.166812896728516, -25.49015998840332, -15.945842742919922, -19.998014450073242, -46.93990707397461, -54.441864013671875, -25.864543914794922, -17.528507232666016, -18.039316177368164, -47.26150894165039, -50.40415954589844, -34.7903938293457, -27.394775390625, -37.44003677368164, -58.7434196472168, -44.82232666015625, -38.18111038208008, -47.36965560913086, -46.2440185546875, -39.64339065551758, -42.79945755004883, -51.303287506103516, -42.20640182495117, -42.245147705078125, -52.23931884765625, -40.81493377685547, -38.18645095825195, -55.04888916015625, -47.9185791015625, -47.77039337158203, -61.1793098449707, -52.21384048461914, -57.24250411987305, -59.97443389892578, -61.988258361816406, -61.988258361816406, -57.24786376953125, -61.988258361816406, -60.146095275878906, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-5.583715915679932, -35.98986053466797, -39.29438018798828, -37.46752166748047, -39.62747573852539, -43.761905670166016, -45.4136962890625, -36.736671447753906, -31.726160049438477, -6.8000359535217285, 13.581219673156738, 13.376192092895508, -7.05854606628418, -36.675228118896484, -37.36813735961914, -33.95064926147461, -27.01593780517578, -35.40979766845703, -41.2568359375, -36.52609634399414, -22.606281280517578, 2.1027374267578125, 8.122644424438477, -2.4674973487854004, -23.338333129882812, -33.797943115234375, -43.95117950439453, -44.416709899902344, -37.0687370300293, -31.69139862060547, -33.79326248168945, -25.764869689941406, -2.1474101543426514, 7.152815341949463, 5.181591033935547, -9.964485168457031, -34.76047897338867, -40.780303955078125, -44.76150894165039, -42.37748718261719, -39.60987854003906, -37.26246643066406, -32.297630310058594, -10.240781784057617, 2.1049156188964844, 0.20992401242256165, -22.278453826904297, -41.6220817565918, -43.74618911743164, -45.882564544677734, -47.33168029785156, -32.696659088134766, -11.616287231445312, -7.628152370452881, -19.349061965942383, -51.19545364379883, -50.31415939331055, -54.843605041503906, -35.946510314941406, -18.100543975830078, -20.076953887939453, -39.65762710571289, -51.53091049194336, -53.04069519042969, -31.98926544189453, -22.415266036987305, -26.057527542114258, -46.768829345703125, -55.18480682373047, -36.957275390625, -19.064233779907227, -19.801830291748047, -48.89342498779297, -55.245609283447266, -29.66702651977539, -24.499509811401367, -38.14704513549805, -61.988258361816406, -38.17205047607422, -33.70256042480469, -47.2611083984375, -54.17344665527344, -41.215553283691406, -43.33808135986328, -60.63154602050781, -43.537349700927734, -44.66027069091797, -60.343055725097656, -39.865333557128906, -37.70853042602539, -58.02067565917969, -45.01685333251953, -45.70000457763672, -61.988258361816406, -49.51854705810547, -56.9709587097168, -59.107051849365234, -61.988258361816406, -58.559932708740234, -56.850059509277344, -61.988258361816406, -57.47538757324219, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-5.633662223815918, -24.30881118774414, -39.10213851928711, -37.23850631713867, -40.526023864746094, -46.92478561401367, -37.09752655029297, -30.686227798461914, -15.490778923034668, 0.5105568766593933, 15.148449897766113, 12.98155689239502, -12.846195220947266, -34.86832046508789, -30.081581115722656, -32.38969421386719, -29.395973205566406, -31.446664810180664, -22.814062118530273, -19.18735694885254, -18.103620529174805, -0.7132962942123413, 3.5131187438964844, -6.8742170333862305, -16.90837287902832, -26.07003402709961, -32.46918487548828, -34.92580795288086, -37.15766906738281, -28.84832000732422, -21.378490447998047, -12.48602294921875, 3.1282382011413574, 10.678333282470703, 4.813640117645264, -14.77618408203125, -22.04413414001465, -33.56793975830078, -33.860538482666016, -26.12137222290039, -21.774364471435547, -20.67145347595215, -17.71674919128418, -3.671403408050537, 2.419781446456909, -6.420324325561523, -27.22344398498535, -26.963619232177734, -27.454092025756836, -29.284135818481445, -30.985414505004883, -25.22967529296875, -9.186238288879395, -12.118605613708496, -25.41079330444336, -32.53041076660156, -38.420326232910156, -47.23944854736328, -30.634326934814453, -16.724206924438477, -23.29745864868164, -44.400291442871094, -45.76725387573242, -37.61650466918945, -25.78144073486328, -22.102014541625977, -36.225013732910156, -43.90522384643555, -43.98102569580078, -27.93285369873047, -20.059518814086914, -28.40218734741211, -48.91153335571289, -47.04719161987305, -24.073352813720703, -26.84902000427246, -47.68648147583008, -48.10828399658203, -33.0196418762207, -35.929168701171875, -54.697959899902344, -48.6344108581543, -42.47470474243164, -49.245418548583984, -51.82378387451172, -38.097007751464844, -48.32394027709961, -51.670562744140625, -35.902286529541016, -42.40918731689453, -52.01328659057617, -43.99773025512695, -51.548500061035156, -59.203041076660156, -53.33739471435547, -58.466548919677734, -53.10039520263672, -61.988258361816406, -52.488609313964844, -59.12612533569336, -57.51852035522461, -59.33284378051758, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-7.202305793762207, -23.095050811767578, -34.0860595703125, -34.87678146362305, -37.63633346557617, -35.78042984008789, -24.042034149169922, -17.653249740600586, -7.091958522796631, 3.5546226501464844, 14.278536796569824, 11.296730041503906, -19.684598922729492, -33.72175598144531, -23.789215087890625, -22.78437042236328, -21.933368682861328, -20.12617301940918, -16.66904067993164, -16.93640899658203, -15.713334083557129, -5.37076473236084, -1.434938669204712, -7.186312675476074, -16.443538665771484, -23.4720516204834, -26.176071166992188, -26.508119583129883, -30.94253921508789, -30.58863067626953, -19.237903594970703, -9.615103721618652, 2.5774776935577393, 8.946844100952148, -0.3015066981315613, -14.776418685913086, -17.120141983032227, -26.634063720703125, -27.79206085205078, -22.752714157104492, -19.491565704345703, -18.8203067779541, -15.481606483459473, -2.455544948577881, 0.8947107195854187, -16.38299560546875, -30.052927017211914, -22.037979125976562, -23.440357208251953, -25.48307228088379, -28.54986000061035, -23.853742599487305, -8.212231636047363, -15.285958290100098, -26.70874786376953, -28.341358184814453, -34.110267639160156, -46.297935485839844, -23.047805786132812, -13.922858238220215, -25.162294387817383, -40.1841926574707, -43.36688232421875, -34.19065475463867, -25.6929931640625, -23.771678924560547, -43.918548583984375, -43.86327362060547, -43.31880569458008, -27.473899841308594, -23.022720336914062, -41.668113708496094, -48.615684509277344, -47.21175765991211, -22.534011840820312, -29.139331817626953, -54.51179885864258, -43.94558334350586, -28.841083526611328, -37.105201721191406, -53.90127182006836, -47.3037109375, -44.611061096191406, -57.72230529785156, -51.16464614868164, -38.768611907958984, -55.075679779052734, -49.76592254638672, -36.070091247558594, -51.103057861328125, -47.59563446044922, -42.474552154541016, -61.988258361816406, -53.32240676879883, -55.52238464355469, -60.809635162353516, -55.41046905517578, -61.988258361816406, -52.95077896118164, -61.988258361816406, -54.902130126953125, -60.405155181884766, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-10.952448844909668, -22.62836265563965, -29.8476619720459, -35.58525848388672, -29.752384185791016, -22.300703048706055, -18.28545570373535, -12.023916244506836, -6.22041654586792, -0.0435970276594162, 11.94627571105957, 9.328356742858887, -21.227054595947266, -32.71582794189453, -22.63481903076172, -20.215248107910156, -14.96218490600586, -11.259765625, -9.493399620056152, -8.796465873718262, -11.725265502929688, -5.122308731079102, -3.2210171222686768, -13.978260040283203, -16.272851943969727, -17.65253257751465, -21.115264892578125, -26.382972717285156, -28.651123046875, -17.86279296875, -14.046028137207031, -11.277533531188965, -0.9981269836425781, 7.106637477874756, -1.4962561130523682, -17.862586975097656, -18.192392349243164, -25.89124298095703, -21.119413375854492, -16.67607879638672, -15.960627555847168, -24.79914093017578, -19.178524017333984, -2.625680446624756, -0.2108711302280426, -20.478029251098633, -23.688344955444336, -16.431583404541016, -15.18755054473877, -19.08325958251953, -29.903308868408203, -21.13614273071289, -7.450700283050537, -15.279284477233887, -23.94550323486328, -23.999109268188477, -31.405479431152344, -46.50166320800781, -22.691699981689453, -14.432331085205078, -26.69989776611328, -35.52294158935547, -38.93727493286133, -34.441009521484375, -23.700523376464844, -22.50554656982422, -42.95977020263672, -43.63977813720703, -42.176856994628906, -31.580612182617188, -25.531034469604492, -32.395729064941406, -44.361690521240234, -37.626068115234375, -22.397628784179688, -28.891603469848633, -46.43798065185547, -42.32160186767578, -29.018291473388672, -37.08291244506836, -40.782325744628906, -41.00926971435547, -43.35619354248047, -49.35182571411133, -44.20234680175781, -38.624691009521484, -50.43878936767578, -44.22850036621094, -38.41838073730469, -52.168853759765625, -47.11937713623047, -41.477848052978516, -46.5143928527832, -51.83517074584961, -50.166595458984375, -55.35285186767578, -54.8460578918457, -57.07304000854492, -54.47589111328125, -61.09951400756836, -51.12751770019531, -57.71623992919922, -57.02122116088867, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.01591110229492, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-4.022040367126465, -15.774893760681152, -23.582670211791992, -31.631256103515625, -24.223081588745117, -16.608707427978516, -12.392936706542969, -6.813385486602783, 0.5483736991882324, 6.715036392211914, 11.416244506835938, 8.12234115600586, -21.02642250061035, -32.80650329589844, -20.642074584960938, -14.606365203857422, -9.03774642944336, -4.848409652709961, -0.5673426389694214, 3.2105751037597656, -2.2627217769622803, -7.82843017578125, -6.236915588378906, -9.074308395385742, -9.331826210021973, -11.306821823120117, -15.60812759399414, -23.44253158569336, -22.666614532470703, -4.841409683227539, -2.2662153244018555, -5.994792938232422, 0.15948042273521423, 7.6068267822265625, -1.2928496599197388, -12.31523323059082, -14.694451332092285, -23.5574893951416, -14.84345817565918, -3.3212218284606934, -4.724113464355469, -21.065702438354492, -21.090091705322266, -2.6032865047454834, -0.7196224927902222, -20.908994674682617, -17.60297966003418, -5.576394081115723, -0.729249119758606, -9.499137878417969, -27.019216537475586, -19.75172233581543, -7.7687554359436035, -16.195758819580078, -13.199557304382324, -11.521716117858887, -23.917863845825195, -41.40973663330078, -28.6285400390625, -20.897319793701172, -26.763391494750977, -29.299732208251953, -32.70050048828125, -30.984447479248047, -19.184051513671875, -16.762420654296875, -30.05296516418457, -37.21147155761719, -35.29644012451172, -24.812576293945312, -13.511077880859375, -22.32213592529297, -37.64155578613281, -27.690284729003906, -18.41738510131836, -25.83678436279297, -39.978118896484375, -34.97531509399414, -34.09465408325195, -38.63361740112305, -32.28469467163086, -32.2557373046875, -37.23500442504883, -36.80051040649414, -31.052942276000977, -35.76537322998047, -35.09854507446289, -32.48432540893555, -41.80377197265625, -42.793792724609375, -46.89148712158203, -35.93171691894531, -34.917877197265625, -45.94207763671875, -40.635929107666016, -48.73551940917969, -47.92790222167969, -49.08028030395508, -44.90604019165039, -50.350433349609375, -40.536964416503906, -49.34036636352539, -46.36915588378906, -61.5062370300293, -61.988258361816406, -51.570587158203125, -53.37766647338867, -48.03081512451172, -56.223846435546875, -57.35449981689453, -61.988258361816406, -59.203216552734375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.451364278793335, -18.501293182373047, -27.19743537902832, -31.347217559814453, -27.41600799560547, -22.057735443115234, -16.807891845703125, -11.374167442321777, -0.6485514640808105, 10.649620056152344, 11.169632911682129, 8.127521514892578, -19.968467712402344, -33.471153259277344, -26.56308937072754, -18.784931182861328, -13.453874588012695, -9.579034805297852, -3.252703905105591, 4.015664577484131, -0.6690363883972168, -6.9169206619262695, -3.0553388595581055, -10.842510223388672, -13.751678466796875, -16.165573120117188, -20.187938690185547, -27.236173629760742, -17.669466018676758, 2.4749526977539062, 1.409138560295105, -11.494293212890625, 0.2531590461730957, 9.5020751953125, 2.907181978225708, -16.171615600585938, -19.463159561157227, -25.328353881835938, -20.45948028564453, 1.3895833492279053, 0.39528441429138184, -21.185165405273438, -25.19017219543457, -5.2426042556762695, -1.1269316673278809, -16.35194206237793, -21.733901977539062, -4.349724769592285, 2.9359796047210693, -9.058721542358398, -31.26430892944336, -23.187862396240234, -10.111040115356445, -16.563796997070312, -13.060514450073242, -10.123400688171387, -25.311832427978516, -45.546226501464844, -34.50590133666992, -22.453153610229492, -20.906795501708984, -22.10031509399414, -36.85745620727539, -35.40348434448242, -19.332534790039062, -13.452339172363281, -20.448434829711914, -41.64918899536133, -40.013572692871094, -20.97787094116211, -8.980222702026367, -21.160785675048828, -42.350013732910156, -25.93728256225586, -16.253419876098633, -27.421287536621094, -44.397987365722656, -37.24241638183594, -34.020137786865234, -38.48880386352539, -31.816211700439453, -27.20840072631836, -36.4267578125, -30.86154556274414, -25.230283737182617, -39.18094253540039, -31.670433044433594, -30.278465270996094, -47.81429672241211, -40.886756896972656, -46.044288635253906, -34.59955596923828, -33.258392333984375, -42.28422546386719, -34.67061996459961, -49.79310607910156, -45.08845520019531, -51.6463508605957, -42.07326889038086, -48.49557876586914, -39.57432556152344, -48.3983039855957, -44.86254119873047, -61.988258361816406, -61.988258361816406, -47.860267639160156, -50.43644714355469, -46.62384033203125, -56.74862289428711, -58.214324951171875, -61.707183837890625, -56.81656265258789, -58.773685455322266, -59.37572479248047, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.435718059539795, -37.29620361328125, -41.12815856933594, -36.340858459472656, -40.13625717163086, -45.484352111816406, -36.624000549316406, -33.5676155090332, -4.023507118225098, 10.294281005859375, 10.222414016723633, 7.619677543640137, -18.01328468322754, -37.67609405517578, -45.760284423828125, -34.180274963378906, -26.447338104248047, -33.1479606628418, -7.835395812988281, 0.4658271372318268, -2.0982096195220947, -0.07249559462070465, 5.083183288574219, -8.5814847946167, -31.531084060668945, -34.808109283447266, -43.52268600463867, -34.990509033203125, -14.511499404907227, 6.572055339813232, 3.9883527755737305, -32.48173904418945, -1.4331353902816772, 10.742931365966797, 5.867574214935303, -27.129032135009766, -45.67600631713867, -41.50377655029297, -38.99665451049805, 1.8230750560760498, 1.1165244579315186, -25.105968475341797, -40.81426239013672, -9.40163516998291, -3.304298162460327, -15.1451416015625, -41.880409240722656, -7.413540840148926, 0.08558744192123413, -11.806221961975098, -48.9998779296875, -28.096355438232422, -14.648395538330078, -17.98670768737793, -20.257457733154297, -17.49365997314453, -31.599119186401367, -54.1547737121582, -31.36224365234375, -18.467790603637695, -14.521416664123535, -15.550865173339844, -51.31916046142578, -50.26573944091797, -21.5078125, -11.951626777648926, -16.00942039489746, -51.1045036315918, -58.968666076660156, -21.35955047607422, -11.43881607055664, -23.363922119140625, -61.528892517089844, -27.623577117919922, -18.66243553161621, -27.350778579711914, -61.988258361816406, -34.842018127441406, -29.82282829284668, -35.295597076416016, -31.307971954345703, -25.537748336791992, -39.26294708251953, -31.9847469329834, -27.143709182739258, -48.66178512573242, -34.52584457397461, -34.09526443481445, -47.849586486816406, -38.7027702331543, -44.74861145019531, -34.24583053588867, -33.09735107421875, -43.025325775146484, -35.21830749511719, -53.18183517456055, -49.636253356933594, -56.19743728637695, -43.98927307128906, -50.22252655029297, -43.060279846191406, -50.87049102783203, -47.04124069213867, -61.69207763671875, -60.862422943115234, -50.16685485839844, -53.69953918457031, -52.012062072753906, -61.988258361816406, -61.988258361816406, -61.988258361816406, -59.868492126464844, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-1.114941954612732, -34.953392028808594, -40.59391403198242, -35.89833450317383, -39.78936767578125, -41.288089752197266, -38.70049285888672, -39.997657775878906, -4.875505447387695, 8.366585731506348, 7.894155979156494, 5.381426811218262, -17.472461700439453, -42.39879608154297, -45.895164489746094, -34.16392517089844, -25.621646881103516, -31.988210678100586, -4.25497579574585, 8.63914966583252, 3.6478304862976074, 4.842561721801758, 10.298254013061523, -4.471407413482666, -33.15679931640625, -34.81385040283203, -46.69799041748047, -41.154869079589844, -10.60927963256836, 8.798504829406738, 5.345404148101807, -32.08331298828125, -2.011836051940918, 10.539972305297852, 6.286711692810059, -26.062042236328125, -46.7747917175293, -42.66295623779297, -29.12303924560547, -0.5540200471878052, -1.418163776397705, -23.7496280670166, -45.245574951171875, -14.835362434387207, -9.071029663085938, -16.718822479248047, -41.23775863647461, -8.198999404907227, -3.940415382385254, -13.776185989379883, -48.14379119873047, -29.329418182373047, -10.125955581665039, -12.813817024230957, -24.585098266601562, -20.67096519470215, -34.7901611328125, -55.855812072753906, -30.55561065673828, -19.150951385498047, -14.355819702148438, -15.957846641540527, -50.564300537109375, -54.50542068481445, -24.261207580566406, -13.516975402832031, -16.296123504638672, -53.94670486450195, -56.748653411865234, -20.434146881103516, -13.881916046142578, -27.26690101623535, -61.807193756103516, -26.579381942749023, -18.293535232543945, -26.725383758544922, -61.988258361816406, -33.97517395019531, -29.510940551757812, -35.023197174072266, -35.487152099609375, -31.458837509155273, -41.03688049316406, -34.58589172363281, -31.645009994506836, -48.88450622558594, -35.20120620727539, -35.71766662597656, -45.55016326904297, -37.2069206237793, -44.62910079956055, -35.45172882080078, -35.32935333251953, -47.10917663574219, -41.02804183959961, -56.670265197753906, -52.59905242919922, -56.52522277832031, -46.62725067138672, -52.38316345214844, -46.58971405029297, -54.06229019165039, -51.13975524902344, -58.62783432006836, -58.58701705932617, -53.723670959472656, -58.4983024597168, -59.06965637207031, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.4726530611515045, -40.98145294189453, -41.918426513671875, -34.5294189453125, -38.97404479980469, -40.05488967895508, -37.907894134521484, -37.719234466552734, -6.527404308319092, 5.255622863769531, 3.124058246612549, 0.806431233882904, -18.750879287719727, -42.002960205078125, -41.12922286987305, -35.80064392089844, -26.493000030517578, -30.510814666748047, 0.2036759853363037, 13.811042785644531, 7.570194244384766, 7.229499340057373, 13.164257049560547, -1.4722230434417725, -35.898433685302734, -37.84180450439453, -46.730037689208984, -45.37294006347656, -7.270349502563477, 8.91888427734375, 4.475135326385498, -28.161540985107422, -3.711696147918701, 7.39396333694458, 3.5517237186431885, -21.376239776611328, -43.04572296142578, -40.99931335449219, -19.319522857666016, -5.630471706390381, -7.422478199005127, -26.189306259155273, -44.90761184692383, -15.877315521240234, -8.567900657653809, -15.979818344116211, -35.86913299560547, -2.378887176513672, 1.459721326828003, -15.266714096069336, -48.47626495361328, -29.743223190307617, -9.293891906738281, -11.762466430664062, -21.08951187133789, -18.520055770874023, -35.701297760009766, -57.011207580566406, -31.340274810791016, -20.23845863342285, -19.003602981567383, -23.19902801513672, -50.32771682739258, -55.944671630859375, -24.81121253967285, -12.800110816955566, -14.706182479858398, -52.493927001953125, -57.941795349121094, -19.48602867126465, -13.457884788513184, -30.423643112182617, -61.988258361816406, -28.260517120361328, -23.432104110717773, -29.324249267578125, -60.625858306884766, -34.28434753417969, -30.7890625, -34.62527084350586, -39.18537521362305, -37.57621383666992, -39.060142517089844, -34.83833694458008, -33.535247802734375, -44.81672668457031, -35.45573043823242, -37.821189880371094, -42.32805252075195, -35.56951904296875, -44.44285583496094, -37.16951370239258, -38.12027359008789, -51.55852508544922, -46.69111251831055, -57.375343322753906, -51.3516845703125, -56.03294372558594, -49.356903076171875, -53.34797668457031, -48.46446990966797, -55.314476013183594, -53.34452819824219, -57.10400390625, -58.27434158325195, -57.50939178466797, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [1.1180179119110107, -45.83191680908203, -48.284297943115234, -36.02064895629883, -39.00395965576172, -44.27939987182617, -39.334510803222656, -37.543148040771484, -9.218324661254883, 0.14160054922103882, -2.520763874053955, -3.906337022781372, -17.891136169433594, -40.536861419677734, -39.23225784301758, -38.48036575317383, -29.310821533203125, -31.885557174682617, 3.5175065994262695, 16.558595657348633, 9.436063766479492, 7.342336177825928, 13.999075889587402, 0.6294727325439453, -40.580413818359375, -40.99940872192383, -42.33954620361328, -39.640296936035156, -5.581487655639648, 5.749530792236328, 1.1510803699493408, -29.29713249206543, -6.168615341186523, 1.6241586208343506, 0.15374353528022766, -17.530439376831055, -40.97821807861328, -47.556453704833984, -14.166328430175781, -0.9501141309738159, -5.5855302810668945, -35.010597229003906, -50.265907287597656, -15.099249839782715, -6.043256759643555, -13.874125480651855, -31.707637786865234, -1.5948827266693115, 1.2443931102752686, -17.31049346923828, -51.21543884277344, -34.354766845703125, -14.651884078979492, -15.674958229064941, -12.319021224975586, -12.819472312927246, -36.952728271484375, -57.44630813598633, -31.647323608398438, -16.52436065673828, -15.978523254394531, -23.33880615234375, -53.90474319458008, -57.925697326660156, -22.627866744995117, -11.52591323852539, -15.653266906738281, -55.10573959350586, -61.11797332763672, -18.080339431762695, -13.876233100891113, -30.178319931030273, -61.988258361816406, -30.417888641357422, -25.476032257080078, -29.707141876220703, -55.556339263916016, -36.02721405029297, -32.91861343383789, -34.839210510253906, -40.45979309082031, -39.95176696777344, -38.459922790527344, -34.48179626464844, -35.11893081665039, -43.48418426513672, -34.921897888183594, -38.89879608154297, -41.636268615722656, -35.4996452331543, -45.631919860839844, -37.95252990722656, -40.86593246459961, -53.983551025390625, -50.54896545410156, -56.27299880981445, -50.942955017089844, -53.76510238647461, -49.024234771728516, -52.962059020996094, -49.347267150878906, -55.6696891784668, -54.932533264160156, -56.9212646484375, -59.09469223022461, -58.363609313964844, -61.750831604003906, -61.85462951660156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.5780728459358215, -41.92744445800781, -46.6385612487793, -36.86601257324219, -40.882476806640625, -47.305198669433594, -42.89704895019531, -36.709835052490234, -10.68300724029541, -5.251505374908447, 3.9150331020355225, 2.661040782928467, -16.556072235107422, -38.6308708190918, -43.60076141357422, -44.20825958251953, -35.59217834472656, -38.57436752319336, 4.793442726135254, 17.345869064331055, 9.942170143127441, 5.854100227355957, 12.400728225708008, 0.4267944097518921, -37.25267028808594, -44.19716262817383, -41.327091217041016, -35.946632385253906, -4.97845458984375, 0.548672080039978, -2.2095961570739746, -30.195913314819336, -5.038595199584961, 6.994184494018555, 4.401264190673828, -17.356021881103516, -45.667457580566406, -43.0931510925293, -11.95335578918457, 1.3914754390716553, -3.7118263244628906, -39.636016845703125, -48.98707580566406, -16.73708152770996, -9.817503929138184, -15.62829875946045, -35.017860412597656, -3.4538867473602295, -1.9592546224594116, -18.741085052490234, -49.386260986328125, -36.919063568115234, -15.379140853881836, -15.508687973022461, -8.550636291503906, -9.537104606628418, -36.070068359375, -59.659271240234375, -30.778467178344727, -18.041818618774414, -14.63366413116455, -20.182716369628906, -55.489803314208984, -61.481285095214844, -20.904537200927734, -9.328739166259766, -14.795394897460938, -58.57819366455078, -61.988258361816406, -20.01285743713379, -17.016803741455078, -32.53725814819336, -61.988258361816406, -35.32843017578125, -29.971046447753906, -30.825119018554688, -50.579071044921875, -34.44987106323242, -33.67085647583008, -36.225955963134766, -34.10512924194336, -34.04017639160156, -39.62685012817383, -33.2932243347168, -34.17605972290039, -43.253623962402344, -34.53148651123047, -39.16004943847656, -43.05072784423828, -37.172183990478516, -47.06708526611328, -40.25634765625, -44.01897048950195, -49.0660400390625, -47.17155456542969, -51.98185348510742, -46.979522705078125, -51.60602569580078, -47.06600570678711, -53.2744140625, -50.764915466308594, -56.381858825683594, -56.51028060913086, -56.448646545410156, -58.927833557128906, -57.71361541748047, -61.09044647216797, -61.47749328613281, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-0.5342494249343872, -38.87710952758789, -45.80516815185547, -36.682037353515625, -41.127525329589844, -48.79818344116211, -39.788673400878906, -35.293113708496094, -7.153005599975586, 2.8679347038269043, 9.199252128601074, 7.378086566925049, -16.310047149658203, -37.3333854675293, -45.956172943115234, -45.14786148071289, -38.122833251953125, -32.506961822509766, 4.083914279937744, 15.844026565551758, 8.676839828491211, 2.257817268371582, 6.7869181632995605, -1.7502856254577637, -36.46733474731445, -39.31173324584961, -45.419761657714844, -36.08295822143555, -3.625080108642578, 6.691092491149902, 0.831577718257904, -33.28669357299805, -3.045257568359375, 8.373286247253418, 4.966599464416504, -19.101837158203125, -46.02079772949219, -42.069183349609375, -9.78515338897705, -2.2710165977478027, -5.512403964996338, -39.130157470703125, -44.79404067993164, -14.765846252441406, -9.304980278015137, -16.93256378173828, -31.00623321533203, -1.1353927850723267, 0.20500265061855316, -19.00480079650879, -49.6248779296875, -33.008968353271484, -17.227781295776367, -17.84671401977539, -8.442339897155762, -9.797002792358398, -35.689605712890625, -61.988258361816406, -29.39794921875, -18.37308120727539, -13.454718589782715, -18.111160278320312, -54.84996032714844, -58.926673889160156, -24.16731834411621, -14.483986854553223, -18.335975646972656, -60.35503005981445, -61.988258361816406, -22.895153045654297, -21.116952896118164, -32.6805534362793, -61.988258361816406, -34.33036422729492, -30.07377815246582, -32.299354553222656, -44.05558776855469, -30.988445281982422, -32.95307922363281, -38.88558578491211, -30.02079963684082, -30.445432662963867, -41.83207702636719, -32.50205612182617, -33.4385986328125, -43.589073181152344, -34.73973083496094, -39.364898681640625, -44.21906280517578, -38.543060302734375, -47.72447204589844, -41.327667236328125, -45.53153610229492, -46.82439422607422, -47.22229766845703, -49.15119934082031, -44.99342346191406, -51.155731201171875, -47.38551330566406, -54.88298797607422, -52.568607330322266, -56.4300537109375, -56.29195785522461, -55.8109245300293, -58.375431060791016, -57.993770599365234, -61.18579864501953, -61.84187316894531, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-1.8196523189544678, -39.19295883178711, -46.502769470214844, -38.05084228515625, -41.27122497558594, -44.2430534362793, -41.55086898803711, -35.364627838134766, -3.443438768386841, 7.672978401184082, 11.8599853515625, 9.87231159210205, -16.746246337890625, -37.807220458984375, -38.79244613647461, -41.59577178955078, -36.183677673339844, -27.4843807220459, 2.095506191253662, 10.729158401489258, 5.0977044105529785, 2.4133901596069336, 5.903463363647461, -3.4840502738952637, -34.48847579956055, -36.880916595458984, -45.38169479370117, -36.97932434082031, -2.9119973182678223, 8.075804710388184, 1.6558396816253662, -35.46833419799805, -3.6922833919525146, 3.529416084289551, 0.8420836329460144, -20.972332000732422, -41.689422607421875, -39.691261291503906, -8.743524551391602, 1.0080475807189941, -3.6812095642089844, -36.9359016418457, -41.709434509277344, -13.81010913848877, -8.705406188964844, -17.335010528564453, -30.42226791381836, -3.147017002105713, -2.0675487518310547, -19.072402954101562, -48.4502067565918, -30.53340721130371, -16.53612518310547, -18.860395431518555, -7.209463119506836, -8.842323303222656, -35.38507843017578, -56.569576263427734, -28.664169311523438, -18.169878005981445, -11.992788314819336, -17.16432762145996, -54.375, -55.576175689697266, -22.609785079956055, -14.550156593322754, -21.03416633605957, -59.996070861816406, -59.58150863647461, -25.977954864501953, -23.600500106811523, -34.72682571411133, -61.988258361816406, -30.59499740600586, -25.72553253173828, -32.96200180053711, -39.22990417480469, -27.682571411132812, -31.083354949951172, -41.74381637573242, -28.371421813964844, -29.224348068237305, -45.09134292602539, -33.31517791748047, -34.69711685180664, -44.627166748046875, -35.77007293701172, -40.32838821411133, -43.66413116455078, -39.459983825683594, -48.814483642578125, -43.10736083984375, -47.61308288574219, -45.499229431152344, -46.443260192871094, -48.22596740722656, -44.970848083496094, -52.42321014404297, -49.031654357910156, -56.36579132080078, -54.31846237182617, -55.403133392333984, -55.25060272216797, -55.48509979248047, -58.790279388427734, -59.443965911865234, -61.95475769042969, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.7060041427612305, -41.37921142578125, -49.59308624267578, -39.38679504394531, -43.264854431152344, -46.16566467285156, -45.710609436035156, -36.131187438964844, -0.9108372926712036, 10.687051773071289, 12.970915794372559, 11.406610488891602, -13.017770767211914, -37.82402420043945, -36.020912170410156, -38.49955749511719, -31.436796188354492, -26.64455795288086, 1.769995927810669, 7.966599464416504, 3.762272596359253, 5.101416110992432, 11.503791809082031, -0.17149506509304047, -30.158161163330078, -38.10354232788086, -43.762184143066406, -33.584964752197266, -3.984023094177246, 3.7667036056518555, -1.252213716506958, -29.37767791748047, -6.5404863357543945, 4.079184532165527, 2.791003704071045, -15.888461112976074, -47.556175231933594, -39.31800079345703, -8.31688404083252, 2.254645347595215, -2.856658935546875, -34.906288146972656, -40.161590576171875, -17.017581939697266, -10.649009704589844, -15.294289588928223, -27.60917854309082, -1.6431282758712769, -0.5737966895103455, -19.208866119384766, -44.151206970214844, -34.043792724609375, -18.952823638916016, -19.145763397216797, -8.660446166992188, -10.657407760620117, -36.44432067871094, -55.39459228515625, -31.488445281982422, -18.426326751708984, -11.514595031738281, -16.66379737854004, -56.46268844604492, -55.32231140136719, -22.224790573120117, -14.09727668762207, -21.026058197021484, -58.591102600097656, -60.163543701171875, -28.60055923461914, -23.035518646240234, -33.69279861450195, -61.988258361816406, -28.589035034179688, -24.600811004638672, -33.30036926269531, -36.48187255859375, -25.912944793701172, -30.192302703857422, -43.77117919921875, -28.832197189331055, -30.269298553466797, -49.326393127441406, -35.768585205078125, -37.729000091552734, -46.07347106933594, -37.17839813232422, -41.86236572265625, -43.41407012939453, -40.64504623413086, -50.922760009765625, -44.657752990722656, -48.88096237182617, -45.10148620605469, -45.58071517944336, -50.06683349609375, -47.36553192138672, -55.41669845581055, -51.99821472167969, -56.77383804321289, -54.34049606323242, -55.563323974609375, -56.02265930175781, -57.65989685058594, -61.48516082763672, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-5.306849956512451, -39.341434478759766, -50.08779525756836, -39.56060791015625, -43.678367614746094, -48.046146392822266, -46.87980270385742, -39.1910285949707, 0.6272444725036621, 12.281782150268555, 12.890848159790039, 12.273941040039062, -9.550580024719238, -38.75389862060547, -41.13376235961914, -37.68654251098633, -28.072093963623047, -28.63948631286621, 4.1239190101623535, 14.814413070678711, 7.682290554046631, 4.03898811340332, 13.082231521606445, 3.5921268463134766, -36.48329162597656, -44.82036209106445, -43.607460021972656, -34.14266586303711, -4.566987037658691, 1.8721808195114136, -2.409970760345459, -31.037670135498047, -11.600008010864258, 6.228174686431885, 6.1785101890563965, -11.559557914733887, -49.729801177978516, -40.831214904785156, -7.927264213562012, -1.5410553216934204, -4.554937362670898, -39.5144157409668, -47.368377685546875, -19.572826385498047, -7.294146537780762, -11.217737197875977, -28.547016143798828, -3.1437530517578125, -2.1372475624084473, -19.485858917236328, -49.544185638427734, -43.541412353515625, -18.854982376098633, -15.900248527526855, -9.768235206604004, -12.147828102111816, -37.93838119506836, -58.99802780151367, -39.619422912597656, -17.0869083404541, -10.29269027709961, -16.455760955810547, -55.582557678222656, -56.6655387878418, -26.924007415771484, -17.285053253173828, -22.336206436157227, -59.03459930419922, -61.988258361816406, -29.460058212280273, -22.57061767578125, -29.8184871673584, -61.988258361816406, -27.33823013305664, -25.209379196166992, -33.39668655395508, -35.731346130371094, -25.76096534729004, -30.63980484008789, -44.936439514160156, -31.457473754882812, -33.63222885131836, -53.45147705078125, -38.64325714111328, -40.65929412841797, -49.07905578613281, -39.55181884765625, -43.6953010559082, -46.642433166503906, -43.21954345703125, -53.42456817626953, -44.81201171875, -48.59389877319336, -46.66224670410156, -46.85390853881836, -54.44890594482422, -52.54954528808594, -57.979759216308594, -54.34135818481445, -57.11817169189453, -55.08393096923828, -58.028263092041016, -59.37334060668945, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-6.271677017211914, -41.61759948730469, -49.42619323730469, -40.28232955932617, -42.96257781982422, -42.694007873535156, -49.990848541259766, -42.76298522949219, 1.380711555480957, 13.123075485229492, 12.452613830566406, 11.963443756103516, -8.929778099060059, -39.9670295715332, -43.02988052368164, -38.427268981933594, -28.58346939086914, -33.72539520263672, 5.490359306335449, 17.34625816345215, 9.71179485321045, 1.9895763397216797, 11.376327514648438, 3.2398440837860107, -32.2765007019043, -36.84679412841797, -45.51668167114258, -39.24359130859375, -3.661665916442871, 6.882641792297363, 0.3117523193359375, -34.98837661743164, -11.656960487365723, 3.137981414794922, 3.8892972469329834, -10.973052978515625, -47.304786682128906, -40.463172912597656, -8.351572036743164, 2.8023040294647217, -2.3729188442230225, -36.759342193603516, -45.956119537353516, -19.152809143066406, -9.996748924255371, -12.777009963989258, -27.873422622680664, -1.7066588401794434, -0.6855821013450623, -19.723983764648438, -52.313743591308594, -45.13239288330078, -19.07436752319336, -16.87049674987793, -15.268911361694336, -18.012842178344727, -40.176143646240234, -61.60991287231445, -43.48808670043945, -18.243331909179688, -10.886178970336914, -16.780569076538086, -58.5007438659668, -59.04353332519531, -29.220561981201172, -18.505823135375977, -22.520132064819336, -59.30242919921875, -61.51934051513672, -29.318603515625, -21.99430274963379, -29.491607666015625, -61.988258361816406, -26.591930389404297, -24.755760192871094, -34.22813415527344, -36.927181243896484, -27.12874984741211, -32.436824798583984, -46.912086486816406, -36.17421340942383, -39.228485107421875, -52.01809310913086, -40.07759475708008, -41.56622314453125, -50.5057373046875, -41.272789001464844, -45.681270599365234, -48.67447280883789, -45.90402603149414, -56.189273834228516, -45.78034210205078, -50.46870422363281, -50.65083312988281, -51.06348419189453, -60.52363967895508, -57.883399963378906, -58.82484436035156, -55.06682586669922, -59.530784606933594, -58.382728576660156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-6.168323040008545, -39.6068115234375, -49.95102310180664, -42.955379486083984, -43.860443115234375, -41.900936126708984, -46.45861053466797, -38.15421676635742, 1.3657441139221191, 13.208340644836426, 11.53053092956543, 10.204352378845215, -11.168905258178711, -36.292423248291016, -40.591400146484375, -41.4084587097168, -33.02955627441406, -34.315216064453125, 4.9974565505981445, 16.951030731201172, 9.44845962524414, -0.27587297558784485, 5.225932598114014, -0.42495012283325195, -28.42690658569336, -34.83553695678711, -48.40022277832031, -38.83498001098633, -4.242768287658691, 6.24691915512085, -0.058471690863370895, -34.219749450683594, -6.722389221191406, 2.465919017791748, 0.326297402381897, -13.919774055480957, -43.79798126220703, -42.8701171875, -8.678694725036621, 1.43660569190979, -3.255023956298828, -37.331573486328125, -52.15129470825195, -14.744248390197754, -7.373727798461914, -13.699769973754883, -29.95693588256836, -2.9407825469970703, -1.9331365823745728, -19.98936653137207, -54.951637268066406, -34.62734603881836, -16.517784118652344, -15.93462085723877, -19.800556182861328, -21.145519256591797, -42.057044982910156, -60.076927185058594, -33.926177978515625, -20.051469802856445, -12.992835998535156, -18.113706588745117, -60.40850067138672, -61.988258361816406, -27.260141372680664, -17.82054901123047, -22.740440368652344, -59.011756896972656, -61.988258361816406, -28.37425422668457, -22.2545166015625, -31.20092010498047, -61.988258361816406, -26.56673812866211, -24.937664031982422, -36.47227478027344, -40.36434555053711, -30.301820755004883, -36.113468170166016, -49.07313537597656, -39.55863571166992, -41.12969970703125, -48.83027648925781, -41.17369079589844, -42.08967208862305, -48.47757339477539, -42.45058059692383, -48.636802673339844, -48.234745025634766, -45.051109313964844, -56.376529693603516, -47.46931076049805, -53.337345123291016, -58.16123580932617, -59.41410827636719, -61.988258361816406, -58.76115417480469, -60.03974151611328, -56.52901077270508, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-5.933940410614014, -42.2404670715332, -51.24026870727539, -43.34465026855469, -44.433815002441406, -44.292625427246094, -45.838016510009766, -36.04242706298828, 0.621123194694519, 12.521940231323242, 9.475639343261719, 6.906646728515625, -15.568092346191406, -35.06462478637695, -38.382408142089844, -43.959815979003906, -40.19614791870117, -30.514610290527344, 2.6042537689208984, 13.689364433288574, 6.818265914916992, 2.080095052719116, 5.741186141967773, -4.033168792724609, -32.41826629638672, -38.003414154052734, -49.39167785644531, -36.42304229736328, -6.128837585449219, 0.1262504607439041, -3.281248092651367, -30.6248836517334, -4.066384315490723, 6.825937747955322, 2.5548946857452393, -22.122425079345703, -46.76171112060547, -45.54786682128906, -9.313241004943848, -1.0899927616119385, -4.408744812011719, -40.07804870605469, -50.2001953125, -13.871601104736328, -7.57615852355957, -15.336045265197754, -32.58961868286133, -3.051743984222412, -1.5516364574432373, -20.26595115661621, -55.52472686767578, -29.281064987182617, -15.8689546585083, -17.97220230102539, -16.93172264099121, -16.832807540893555, -41.203208923339844, -60.69650650024414, -30.494251251220703, -19.595050811767578, -14.019111633300781, -19.48723030090332, -57.67190933227539, -61.988258361816406, -26.011829376220703, -17.039113998413086, -23.5614013671875, -61.988258361816406, -61.988258361816406, -28.535263061523438, -24.310413360595703, -34.56639862060547, -61.988258361816406, -27.459238052368164, -24.960227966308594, -38.60713577270508, -46.342567443847656, -36.10982131958008, -41.8051872253418, -50.273414611816406, -37.78759765625, -38.082000732421875, -46.411888122558594, -42.90228271484375, -42.81519317626953, -47.829402923583984, -47.18701934814453, -53.584716796875, -47.48125076293945, -44.051971435546875, -55.59343719482422, -53.10527801513672, -58.951332092285156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -58.408973693847656, -61.988258361816406, -59.13470458984375, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-6.137375354766846, -43.15789794921875, -56.8892707824707, -44.29520034790039, -43.8902587890625, -44.28783416748047, -47.519474029541016, -35.57980728149414, -0.7642907500267029, 11.251240730285645, 6.266139030456543, 2.075658082962036, -18.86566734313965, -39.04954528808594, -38.752689361572266, -43.24119186401367, -38.607147216796875, -30.601137161254883, -0.5543647408485413, 6.290034770965576, 2.0595614910125732, 6.0405402183532715, 10.730706214904785, -4.877781391143799, -41.18965530395508, -43.77838897705078, -47.89802169799805, -38.597721099853516, -6.448733329772949, 3.5796375274658203, -0.964021623134613, -31.458654403686523, -4.802572727203369, 5.668839931488037, 1.0160737037658691, -28.312110900878906, -49.22478485107422, -48.04730987548828, -11.039294242858887, 3.3936080932617188, -1.409203290939331, -38.395267486572266, -45.97052001953125, -14.335808753967285, -10.11529541015625, -18.142934799194336, -37.98700714111328, -2.7138259410858154, -0.9716858863830566, -20.941850662231445, -56.60148239135742, -28.550487518310547, -13.045177459716797, -16.870868682861328, -15.17331600189209, -15.126550674438477, -39.264530181884766, -61.988258361816406, -31.455913543701172, -21.29972267150879, -16.978227615356445, -22.81326675415039, -60.4494514465332, -61.988258361816406, -29.399639129638672, -21.99294662475586, -27.018823623657227, -61.988258361816406, -61.988258361816406, -35.23871612548828, -30.75328826904297, -39.36980438232422, -61.988258361816406, -29.195730209350586, -27.139270782470703, -41.302066802978516, -53.4577751159668, -41.8262939453125, -44.1722526550293, -51.140018463134766, -36.88159942626953, -36.87422561645508, -45.598243713378906, -43.08860778808594, -41.97403335571289, -48.24777603149414, -50.95743179321289, -55.590328216552734, -49.932838439941406, -45.23784255981445, -56.24208068847656, -58.549720764160156, -61.844730377197266, -61.988258361816406, -61.988258361816406, -61.988258361816406, -58.630165100097656, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-6.711409091949463, -43.10158157348633, -58.64519500732422, -43.942569732666016, -44.42556381225586, -45.601280212402344, -50.70763397216797, -36.46030807495117, -2.823646068572998, 9.289549827575684, 1.9260722398757935, -5.188537120819092, -20.662080764770508, -44.18620681762695, -38.93849182128906, -42.919307708740234, -35.89189529418945, -33.568790435791016, -1.3362538814544678, 8.05085563659668, 3.0640814304351807, 7.512564659118652, 12.215842247009277, -5.47698974609375, -37.581298828125, -46.78252410888672, -52.67354965209961, -45.88421630859375, -6.110248565673828, 7.922501564025879, 2.597280740737915, -33.31298065185547, -8.225678443908691, -0.9544842839241028, -4.283644676208496, -29.117185592651367, -46.63283920288086, -48.425045013427734, -12.873514175415039, 2.311479091644287, -2.3034887313842773, -38.669639587402344, -47.6329460144043, -11.511517524719238, -6.056698799133301, -17.986331939697266, -37.62949752807617, -7.426388740539551, -5.42764139175415, -21.520809173583984, -54.61754608154297, -28.76786231994629, -16.21953582763672, -19.766307830810547, -9.895746231079102, -10.043600082397461, -38.966575622558594, -61.988258361816406, -32.31062698364258, -21.987564086914062, -18.14196014404297, -24.360868453979492, -60.959590911865234, -61.988258361816406, -30.151369094848633, -22.945993423461914, -27.846662521362305, -61.988258361816406, -61.988258361816406, -35.93825912475586, -27.640460968017578, -40.737274169921875, -61.988258361816406, -31.199810028076172, -28.89219093322754, -43.672882080078125, -55.777610778808594, -37.9688720703125, -40.816680908203125, -51.75383758544922, -37.79452133178711, -37.40937805175781, -46.42914581298828, -41.43043899536133, -40.10054016113281, -49.87283706665039, -47.48801803588867, -49.75295639038086, -52.414283752441406, -47.92334747314453, -59.491241455078125, -56.27132034301758, -57.95098876953125, -61.988258361816406, -61.988258361816406, -61.988258361816406, -59.461647033691406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-7.769773006439209, -43.70994567871094, -48.47930145263672, -45.63207244873047, -47.93537139892578, -47.08545684814453, -52.25562286376953, -37.480308532714844, -5.554781913757324, 6.641193389892578, 0.7137547731399536, -3.600325345993042, -22.213056564331055, -47.242679595947266, -41.51097106933594, -41.78034973144531, -32.463134765625, -36.562984466552734, -0.3832641839981079, 13.411558151245117, 7.418402671813965, 6.965466499328613, 11.899796485900879, -5.791995525360107, -34.65765380859375, -40.062347412109375, -51.84669876098633, -43.88084030151367, -7.240445613861084, 8.468819618225098, 3.523390054702759, -30.34885597229004, -9.214981079101562, 0.17921847105026245, -3.8248562812805176, -31.646129608154297, -46.71066665649414, -43.15394973754883, -15.403657913208008, -4.069674491882324, -7.474242210388184, -35.23582077026367, -48.86777877807617, -12.762285232543945, -6.915163040161133, -19.02413558959961, -39.895751953125, -5.726474761962891, -2.2686901092529297, -21.257015228271484, -54.86713409423828, -31.40500259399414, -15.723001480102539, -19.2044620513916, -9.042484283447266, -9.105154037475586, -37.69447708129883, -61.988258361816406, -34.59410095214844, -24.051025390625, -23.056537628173828, -29.146699905395508, -61.988258361816406, -59.50080871582031, -31.636219024658203, -22.79292106628418, -27.658708572387695, -61.988258361816406, -61.988258361816406, -35.51753616333008, -27.597949981689453, -40.75927734375, -61.988258361816406, -33.621585845947266, -29.814289093017578, -44.77146530151367, -58.85894775390625, -34.2786979675293, -37.8366584777832, -52.727779388427734, -40.0174560546875, -38.778011322021484, -47.73017501831055, -40.60245895385742, -38.895381927490234, -52.07174301147461, -44.457763671875, -46.37039566040039, -57.928245544433594, -53.15557861328125, -61.988258361816406, -56.063045501708984, -57.78834915161133, -61.988258361816406, -61.1722526550293, -61.988258361816406, -60.008949279785156, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-8.516531944274902, -40.56400680541992, -42.99844741821289, -47.429466247558594, -47.70226287841797, -45.04930877685547, -46.4649658203125, -34.70814514160156, -9.210380554199219, 3.178661346435547, 3.507974624633789, 1.2187472581863403, -22.47027587890625, -43.28276062011719, -45.23463821411133, -39.01572799682617, -29.338165283203125, -28.31897735595703, -0.9800595045089722, 15.629356384277344, 10.392746925354004, 5.201081275939941, 10.482959747314453, -6.349658489227295, -34.95039367675781, -35.62846374511719, -34.3321533203125, -29.55923080444336, -10.464606285095215, 6.304873943328857, 2.435669422149658, -30.8518123626709, -7.155915260314941, 4.540531158447266, -0.22356027364730835, -35.0988655090332, -33.52647018432617, -32.258338928222656, -20.91853904724121, -3.339250087738037, -4.222196578979492, -24.44530487060547, -36.485145568847656, -18.376008987426758, -12.677521705627441, -22.39139747619629, -37.80120849609375, -6.257099628448486, -1.4953858852386475, -19.63359832763672, -43.295249938964844, -36.20880889892578, -13.7263822555542, -16.978487014770508, -14.17586898803711, -13.038369178771973, -31.514482498168945, -51.92321014404297, -37.734405517578125, -27.183076858520508, -23.358976364135742, -26.98490333557129, -49.890235900878906, -49.701541900634766, -32.29440689086914, -21.22008514404297, -28.085172653198242, -53.105987548828125, -49.86060333251953, -34.24944305419922, -24.821889877319336, -38.382816314697266, -51.64515686035156, -34.75223922729492, -30.26502799987793, -45.78221893310547, -55.96247100830078, -34.509159088134766, -35.98601531982422, -51.565948486328125, -42.561920166015625, -39.22142791748047, -49.411407470703125, -41.876373291015625, -38.97142028808594, -53.59748840332031, -43.81194305419922, -44.31934356689453, -61.988258361816406, -53.53438949584961, -59.69249725341797, -58.57497787475586, -58.79391098022461, -61.988258361816406, -59.61681365966797, -61.988258361816406, -59.04655838012695, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-8.368572235107422, -27.03362274169922, -38.51305389404297, -37.406333923339844, -35.29887008666992, -35.813079833984375, -32.96051025390625, -17.956043243408203, -8.183784484863281, 0.5309548377990723, 5.5767035484313965, 3.7415876388549805, -19.62022590637207, -36.71977233886719, -33.48170852661133, -25.49297332763672, -24.546649932861328, -16.341848373413086, 1.959871768951416, 15.563392639160156, 11.284924507141113, 2.9948906898498535, 8.092081069946289, -7.481752395629883, -24.717784881591797, -27.444252014160156, -17.96300506591797, -4.312051773071289, 0.5581431984901428, 4.360333442687988, -1.2681212425231934, -12.760858535766602, -4.637373447418213, 5.596762657165527, 0.4030572772026062, -18.793277740478516, -12.3676118850708, -8.911184310913086, -11.952086448669434, -0.638584554195404, 0.32003238797187805, -13.49936294555664, -22.71815299987793, -21.658048629760742, -22.6126651763916, -23.943058013916016, -17.621788024902344, -11.015243530273438, -5.119083404541016, -19.499208450317383, -23.320514678955078, -27.652761459350586, -16.415180206298828, -18.55453109741211, -15.153863906860352, -11.039106369018555, -26.303194046020508, -32.18635940551758, -27.519065856933594, -19.459684371948242, -19.92922019958496, -25.3640079498291, -32.553348541259766, -29.805744171142578, -24.78823471069336, -27.333385467529297, -30.226964950561523, -32.24559020996094, -26.4711856842041, -31.931564331054688, -24.128923416137695, -33.53041076660156, -31.2855224609375, -33.08045959472656, -33.351783752441406, -34.36869430541992, -33.535255432128906, -32.665367126464844, -32.369117736816406, -38.12953567504883, -45.74156188964844, -40.31501388549805, -42.230587005615234, -42.82915496826172, -38.11470413208008, -47.11784362792969, -46.557289123535156, -45.03282928466797, -50.96723937988281, -46.02006530761719, -47.53937530517578, -54.593177795410156, -48.4525260925293, -55.76830291748047, -49.18171691894531, -60.10055160522461, -55.28805160522461, -60.4350700378418, -58.8158073425293, -61.988258361816406, -59.96952819824219, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.446621894836426, -19.701187133789062, -28.89197540283203, -29.466899871826172, -27.50235366821289, -31.830577850341797, -23.910682678222656, -9.568392753601074, -3.1691787242889404, 3.9318337440490723, 7.0242462158203125, 2.360004186630249, -18.588611602783203, -32.005165100097656, -25.236738204956055, -20.5650691986084, -16.32024383544922, -12.838186264038086, 3.7647476196289062, 10.659842491149902, 6.643075466156006, 0.5509213805198669, 3.4067704677581787, -6.158535957336426, -16.00179100036621, -22.776803970336914, -11.072099685668945, 3.028913974761963, 7.4059672355651855, 4.369149684906006, -7.686402320861816, -5.7933807373046875, -2.35265851020813, 2.4571456909179688, -2.244424343109131, -7.904694557189941, -8.515602111816406, -2.7679035663604736, -8.922492027282715, -3.7036828994750977, -1.634250283241272, -10.24634838104248, -15.847512245178223, -15.608137130737305, -21.89269256591797, -21.175254821777344, -11.024629592895508, -13.311095237731934, -12.879606246948242, -22.508066177368164, -19.50899887084961, -24.966262817382812, -22.431869506835938, -21.811222076416016, -18.517351150512695, -13.903960227966309, -26.702796936035156, -27.79048728942871, -22.599430084228516, -18.085901260375977, -18.491634368896484, -26.076309204101562, -29.047849655151367, -24.090633392333984, -19.645872116088867, -28.665578842163086, -30.603984832763672, -26.899213790893555, -21.188232421875, -30.963348388671875, -29.462448120117188, -29.298505783081055, -26.825679779052734, -29.536033630371094, -33.55301284790039, -28.684600830078125, -27.943519592285156, -35.29705810546875, -33.194190979003906, -33.842430114746094, -45.060028076171875, -41.0338134765625, -39.89155578613281, -42.30544662475586, -39.966094970703125, -41.57577133178711, -49.07793426513672, -44.04600524902344, -47.32122039794922, -43.46755599975586, -43.71406173706055, -50.01869201660156, -43.69952392578125, -51.70843505859375, -45.849632263183594, -56.73393630981445, -52.63933181762695, -56.975921630859375, -55.221832275390625, -58.64213562011719, -57.07360076904297, -60.149757385253906, -60.21226501464844, -59.95963668823242, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-0.6954394578933716, -19.28809928894043, -19.189178466796875, -18.0698184967041, -18.550621032714844, -22.50208854675293, -13.075809478759766, -4.311691761016846, -2.809929370880127, 1.4946287870407104, 2.9344334602355957, -5.9532880783081055, -21.881589889526367, -25.699098587036133, -15.635985374450684, -7.964066982269287, -4.532504081726074, -2.4023282527923584, -2.655489683151245, -1.8750661611557007, -8.139934539794922, -7.566525459289551, -8.563486099243164, -11.135477066040039, -15.818828582763672, -14.402055740356445, -5.224788665771484, 2.43678617477417, 4.131298065185547, -1.9257347583770752, -13.965935707092285, -7.5111188888549805, -7.772544860839844, -7.532589912414551, -8.467544555664062, -7.533188343048096, -8.518804550170898, -4.516275405883789, -11.284686088562012, -15.882450103759766, -11.938980102539062, -13.407305717468262, -15.083049774169922, -10.034394264221191, -12.321063995361328, -20.53736114501953, -12.529455184936523, -14.713058471679688, -21.500255584716797, -20.604930877685547, -14.57038688659668, -17.469009399414062, -26.892040252685547, -25.95170021057129, -26.66224479675293, -23.87653160095215, -23.783082962036133, -23.751047134399414, -25.226707458496094, -26.775127410888672, -24.87081527709961, -23.713848114013672, -25.697744369506836, -26.987323760986328, -24.634849548339844, -32.47294616699219, -33.1942138671875, -30.79288101196289, -25.87612533569336, -27.205324172973633, -25.374929428100586, -33.21775436401367, -30.73572540283203, -27.472679138183594, -28.916244506835938, -31.181259155273438, -30.68630027770996, -31.971107482910156, -33.92251205444336, -35.12712860107422, -39.27532958984375, -41.44328689575195, -34.874359130859375, -37.216209411621094, -41.99424362182617, -35.67784118652344, -43.42610168457031, -41.576560974121094, -40.76362228393555, -46.92169952392578, -45.26435852050781, -45.62135696411133, -41.32495880126953, -46.29608917236328, -39.623294830322266, -49.46925735473633, -44.66993713378906, -51.67760467529297, -51.44158172607422, -52.79759979248047, -54.353939056396484, -47.5136604309082, -52.12204360961914, -50.75498580932617, -56.466651916503906, -57.38603973388672, -61.988258361816406, -53.12657165527344, -54.79912185668945, -55.87465286254883, -60.2039680480957, -61.988258361816406, -61.988258361816406, -60.920005798339844, -61.18515396118164, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.9843903183937073, -20.013336181640625, -14.574726104736328, -12.411332130432129, -14.962451934814453, -19.086671829223633, -10.473018646240234, 2.7232491970062256, 7.09721040725708, 1.1129306554794312, -3.3976097106933594, -11.579498291015625, -22.529695510864258, -24.867935180664062, -11.44891357421875, -2.6254982948303223, 0.4302622377872467, 4.485291481018066, -1.407299280166626, 0.5480072498321533, -4.843267917633057, -13.909036636352539, -11.44962215423584, -8.638446807861328, -10.600866317749023, -7.862681865692139, 3.461205005645752, 5.667243480682373, 1.5928003787994385, -4.500718116760254, -8.107702255249023, -6.236899375915527, -7.256777286529541, -11.837446212768555, -12.441033363342285, -12.964910507202148, -14.288125038146973, -14.054512023925781, -12.767343521118164, -6.517422199249268, -9.973737716674805, -12.348846435546875, -13.32237434387207, -2.6972503662109375, -2.259902000427246, -17.301881790161133, -14.132641792297363, -9.417591094970703, -6.524971961975098, -12.074570655822754, -5.754044055938721, -6.6901421546936035, -24.882238388061523, -24.29681968688965, -17.280397415161133, -15.785175323486328, -18.347270965576172, -19.02788734436035, -22.87662124633789, -34.306678771972656, -27.24158477783203, -19.452678680419922, -19.200881958007812, -27.341365814208984, -29.349403381347656, -30.863807678222656, -28.784713745117188, -31.7653865814209, -29.636354446411133, -19.965848922729492, -12.930296897888184, -24.35889434814453, -34.39542007446289, -19.590106964111328, -18.17194175720215, -28.41421890258789, -31.76825714111328, -25.635204315185547, -30.216461181640625, -31.0600643157959, -30.624584197998047, -33.09407043457031, -25.24709701538086, -26.330434799194336, -34.401451110839844, -25.48395538330078, -34.2634162902832, -33.34423828125, -33.47529602050781, -42.27750778198242, -39.999881744384766, -36.50916290283203, -31.553571701049805, -39.083072662353516, -30.036334991455078, -41.43589782714844, -36.16693878173828, -44.82492446899414, -44.09090042114258, -45.25934600830078, -42.9942626953125, -37.20915985107422, -41.31401443481445, -40.1009407043457, -49.6131477355957, -50.60089874267578, -55.364830017089844, -43.72003936767578, -44.576683044433594, -45.39626693725586, -51.01642990112305, -60.09711837768555, -55.14653778076172, -51.76055908203125, -51.570556640625, -54.74400329589844, -61.988258361816406, -60.500732421875, -56.49458312988281, -58.73447036743164, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [1.3126115798950195, -18.999740600585938, -17.911989212036133, -18.320911407470703, -19.64236068725586, -20.413724899291992, -13.172879219055176, 1.605688452720642, 11.765432357788086, 11.030506134033203, 3.3344979286193848, -12.910351753234863, -24.730484008789062, -27.41360092163086, -16.279403686523438, -7.517480850219727, -3.15582013130188, 7.05107307434082, 2.294227361679077, 4.864729881286621, -1.074573278427124, -14.424229621887207, -9.95714282989502, -8.72475528717041, -9.532362937927246, -6.78090763092041, 4.141019821166992, 2.834528923034668, -4.392611980438232, 0.06793376803398132, -0.3244643211364746, -6.676748275756836, -7.09987211227417, -10.11384105682373, -11.221041679382324, -15.043100357055664, -19.289100646972656, -20.529191970825195, -15.726700782775879, 0.004910379648208618, -1.8848228454589844, -15.388542175292969, -16.122201919555664, -3.0766634941101074, 0.7935065627098083, -14.0801420211792, -15.126373291015625, -4.061728477478027, 1.9247267246246338, -8.21781063079834, -4.4241838455200195, -1.704860806465149, -24.070911407470703, -23.164968490600586, -12.097253799438477, -9.593091011047363, -14.622804641723633, -16.733346939086914, -27.39154624938965, -34.16569900512695, -24.71527862548828, -18.833988189697266, -20.171785354614258, -29.585262298583984, -31.320951461791992, -25.600128173828125, -24.237268447875977, -34.38050842285156, -32.969520568847656, -21.106531143188477, -9.718527793884277, -21.08668327331543, -37.40094757080078, -16.024877548217773, -13.37979793548584, -25.77305030822754, -31.27528953552246, -26.403461456298828, -32.98740768432617, -34.23973083496094, -28.272621154785156, -30.16156005859375, -24.72335433959961, -24.645038604736328, -27.152196884155273, -22.169677734375, -29.07009506225586, -27.600372314453125, -29.85018539428711, -39.80132293701172, -40.446075439453125, -34.62372970581055, -31.212947845458984, -38.0319938659668, -28.533443450927734, -39.66293716430664, -33.015968322753906, -45.634559631347656, -40.48633575439453, -44.513824462890625, -38.325164794921875, -36.68375778198242, -39.240966796875, -37.95452880859375, -47.88496017456055, -46.81787109375, -49.98516845703125, -42.36547088623047, -43.94952392578125, -44.282752990722656, -48.793601989746094, -56.37388229370117, -53.850929260253906, -51.57660675048828, -51.81047058105469, -53.55817413330078, -61.27238845825195, -59.205291748046875, -57.80195617675781, -59.34141540527344, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.4551132917404175, -25.790409088134766, -33.251686096191406, -36.04784393310547, -34.45192337036133, -30.371553421020508, -25.79068946838379, 0.4194757342338562, 11.310922622680664, 11.446968078613281, 3.8525495529174805, -22.176918029785156, -31.159069061279297, -43.757232666015625, -33.48814392089844, -26.181011199951172, -2.2954680919647217, 11.149626731872559, 6.082098484039307, 1.614349126815796, -1.8323898315429688, -21.256486892700195, -21.506824493408203, -20.824480056762695, -21.296131134033203, -10.155835151672363, -2.0807957649230957, -3.6662187576293945, -15.726675987243652, 4.686014652252197, 2.6348376274108887, -19.570127487182617, -19.910085678100586, -20.393043518066406, -21.227359771728516, -15.317343711853027, -17.697612762451172, -27.355566024780273, -27.129175186157227, 1.9466936588287354, 1.146931767463684, -23.833621978759766, -32.845458984375, -4.818796634674072, 0.7385951280593872, -12.37572193145752, -28.09732437133789, -5.5204010009765625, 2.316865921020508, -10.446454048156738, -3.9801697731018066, -0.3575506806373596, -30.624488830566406, -34.42317581176758, -15.835295677185059, -12.512415885925293, -10.656943321228027, -12.42773151397705, -43.15427780151367, -44.72230911254883, -17.623987197875977, -15.394672393798828, -19.736557006835938, -41.98892593383789, -43.40208435058594, -17.6301326751709, -16.394309997558594, -38.28218078613281, -47.181339263916016, -26.271408081054688, -12.795882225036621, -24.52763557434082, -50.165260314941406, -15.637399673461914, -14.619117736816406, -30.330303192138672, -28.63306427001953, -24.486469268798828, -36.51984786987305, -36.59723663330078, -27.7750186920166, -25.521358489990234, -29.79631805419922, -27.29874610900879, -25.132863998413086, -24.964508056640625, -30.153575897216797, -28.056659698486328, -30.134828567504883, -39.46765899658203, -40.83076095581055, -34.94993591308594, -32.20729064941406, -38.00078582763672, -29.460926055908203, -41.13311004638672, -35.85842514038086, -48.97555923461914, -42.18956756591797, -45.55219650268555, -40.16545104980469, -41.16289138793945, -42.353797912597656, -42.46605682373047, -50.68986892700195, -47.309051513671875, -50.11650848388672, -46.57390594482422, -50.05736541748047, -50.27851486206055, -52.867332458496094, -56.39960861206055, -55.570125579833984, -55.83155059814453, -58.287017822265625, -59.56337356567383, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [1.2183332443237305, -37.249725341796875, -39.17926025390625, -43.367671966552734, -52.449344635009766, -45.93227005004883, -35.27336120605469, 1.2658578157424927, 11.98492431640625, 11.13023853302002, 2.023365020751953, -31.960447311401367, -31.571359634399414, -46.148494720458984, -43.88500213623047, -32.24533462524414, 0.24826785922050476, 14.09126091003418, 8.79875659942627, 4.368371486663818, 0.3624288737773895, -32.30866622924805, -40.40283966064453, -44.542381286621094, -40.21073913574219, -8.132572174072266, 3.8397998809814453, 0.9034848809242249, -12.866815567016602, 7.7813029289245605, 4.839071750640869, -35.302268981933594, -39.79520797729492, -34.29608154296875, -25.815744400024414, -16.763723373413086, -19.325214385986328, -33.72941207885742, -35.75593185424805, 1.119693636894226, 0.37660133838653564, -24.25899887084961, -45.46062088012695, -7.818452835083008, -2.6785542964935303, -13.9034423828125, -43.14218521118164, -8.989530563354492, -2.8896400928497314, -12.779878616333008, -6.016620635986328, -2.2683420181274414, -26.224788665771484, -47.489707946777344, -23.347877502441406, -20.742637634277344, -11.760897636413574, -14.059526443481445, -47.61639404296875, -49.63436508178711, -13.823455810546875, -11.5940523147583, -15.979179382324219, -51.55952453613281, -47.885738372802734, -15.835119247436523, -13.067249298095703, -31.619129180908203, -61.988258361816406, -20.83635711669922, -15.258617401123047, -29.589065551757812, -59.90887451171875, -17.376373291015625, -14.897470474243164, -33.031742095947266, -32.63802719116211, -27.36294937133789, -32.78294372558594, -35.34844207763672, -28.267181396484375, -27.38393783569336, -31.496545791625977, -29.761959075927734, -29.506362915039062, -27.84193992614746, -32.58522033691406, -31.064157485961914, -32.721046447753906, -37.557891845703125, -40.84917068481445, -34.31849670410156, -31.322147369384766, -42.42969512939453, -32.6906623840332, -44.213905334472656, -42.63628387451172, -49.74941635131836, -43.293853759765625, -46.248695373535156, -42.37760543823242, -44.234920501708984, -45.83709716796875, -46.86281204223633, -55.234222412109375, -50.99082946777344, -53.85852813720703, -53.06651306152344, -56.63231658935547, -57.41151428222656, -57.593894958496094, -61.053775787353516, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [2.553865909576416, -35.73704528808594, -39.88435745239258, -44.878509521484375, -50.746761322021484, -41.120967864990234, -35.39993667602539, 1.6140797138214111, 11.72853946685791, 8.636014938354492, -1.0237905979156494, -32.17329025268555, -30.788190841674805, -46.64820861816406, -42.668067932128906, -29.8349666595459, 1.8977617025375366, 15.981992721557617, 10.892220497131348, 11.438397407531738, 5.813838958740234, -26.524368286132812, -40.65663146972656, -44.65665817260742, -41.46111297607422, -6.156574249267578, 9.456206321716309, 6.225001335144043, -9.009760856628418, 9.103633880615234, 5.184051990509033, -29.88943099975586, -43.141883850097656, -38.59974670410156, -21.897708892822266, -9.060510635375977, -11.448156356811523, -31.531173706054688, -23.921138763427734, -2.9257047176361084, -3.9758987426757812, -24.20758819580078, -39.26609420776367, -10.293367385864258, -5.59168815612793, -13.419546127319336, -38.30131149291992, -5.217959880828857, -1.0960123538970947, -14.508401870727539, -12.005975723266602, -7.803158760070801, -21.551197052001953, -45.263816833496094, -23.31838607788086, -19.708829879760742, -16.097938537597656, -18.97995376586914, -43.14641571044922, -39.727901458740234, -16.7410945892334, -14.725301742553711, -18.061269760131836, -54.70650100708008, -39.99214553833008, -12.911111831665039, -12.203621864318848, -28.03067398071289, -61.988258361816406, -18.509340286254883, -13.921192169189453, -32.12664031982422, -61.988258361816406, -18.213279724121094, -15.825851440429688, -35.327903747558594, -45.3071403503418, -32.02499008178711, -34.67890167236328, -35.73573303222656, -30.260210037231445, -34.88953399658203, -32.64179992675781, -30.71703338623047, -31.947559356689453, -29.376203536987305, -33.199440002441406, -32.73289489746094, -33.96459197998047, -36.46319580078125, -40.89418411254883, -35.92703628540039, -34.12086868286133, -46.498046875, -42.65227508544922, -50.64838790893555, -46.90306854248047, -49.12250518798828, -44.06181335449219, -47.139984130859375, -44.24226379394531, -47.741355895996094, -49.9714241027832, -50.8436164855957, -57.084251403808594, -55.11677551269531, -58.659217834472656, -58.22193145751953, -61.988258361816406, -61.988258361816406, -61.741451263427734, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [3.6680784225463867, -42.21513366699219, -44.07440948486328, -46.610679626464844, -51.20703887939453, -41.993919372558594, -32.82431411743164, 1.455668330192566, 12.059745788574219, 7.740917205810547, -4.960418224334717, -30.664371490478516, -29.9968318939209, -44.05762481689453, -42.1511116027832, -31.177974700927734, 2.6374270915985107, 16.90637969970703, 12.221779823303223, 15.336565971374512, 8.635538101196289, -25.58010482788086, -41.13392639160156, -46.243038177490234, -42.6890983581543, -5.1702165603637695, 11.691150665283203, 8.626537322998047, -6.17263126373291, 7.961782455444336, 3.2263827323913574, -30.21347427368164, -46.44424819946289, -41.72928237915039, -20.263845443725586, -4.690886497497559, -6.449660301208496, -28.283166885375977, -16.346786499023438, -4.325932502746582, -7.831009864807129, -29.189510345458984, -41.17865753173828, -6.203437805175781, 0.015328474342823029, -10.24752426147461, -33.83723831176758, -1.2318655252456665, 2.1726505756378174, -16.038761138916016, -11.236612319946289, -6.066803932189941, -20.701759338378906, -37.983245849609375, -17.335031509399414, -16.513912200927734, -11.198229789733887, -12.198838233947754, -40.46736145019531, -32.447662353515625, -19.314746856689453, -15.704437255859375, -16.957218170166016, -50.27519607543945, -31.406620025634766, -12.046032905578613, -12.666790008544922, -25.1486873626709, -61.988258361816406, -20.62984848022461, -14.088715553283691, -27.16682243347168, -61.988258361816406, -22.90017318725586, -20.69342041015625, -42.00947570800781, -43.25487518310547, -33.76887512207031, -36.87946701049805, -37.09649658203125, -31.983642578125, -41.44613265991211, -32.66199493408203, -30.41389274597168, -33.93198776245117, -30.083782196044922, -33.0367431640625, -34.56144714355469, -35.22771072387695, -35.157772064208984, -40.59114074707031, -37.74352264404297, -38.59248352050781, -47.86311721801758, -45.985633850097656, -50.13792037963867, -44.3924674987793, -46.63495635986328, -42.05535888671875, -48.23421859741211, -46.29399871826172, -49.727516174316406, -52.16842269897461, -54.29329299926758, -57.18971633911133, -57.1107063293457, -59.04633331298828, -58.386505126953125, -60.63919448852539, -60.880836486816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [3.39310622215271, -40.5290412902832, -48.910621643066406, -46.46126174926758, -50.56772232055664, -45.995086669921875, -37.18648147583008, 1.2915961742401123, 11.482629776000977, 4.665076732635498, -9.02324104309082, -31.260652542114258, -29.766103744506836, -47.41482162475586, -43.707881927490234, -32.71377182006836, 2.3545243740081787, 16.580398559570312, 12.390459060668945, 17.172643661499023, 9.850332260131836, -26.43373680114746, -44.256710052490234, -52.00412368774414, -46.44401931762695, -5.068050384521484, 11.001422882080078, 8.180541038513184, -5.26999568939209, 2.589850664138794, -1.0410747528076172, -29.62761688232422, -42.39032745361328, -40.78843688964844, -20.0432186126709, -5.133429050445557, -6.2662434577941895, -24.470718383789062, -13.057220458984375, 0.9243620038032532, -4.114283084869385, -40.040252685546875, -40.17448043823242, -6.144199371337891, -0.6161967515945435, -10.198600769042969, -32.466392517089844, -2.967054605484009, -0.7390033006668091, -18.26179313659668, -10.864048957824707, -6.4342546463012695, -19.630815505981445, -33.27935791015625, -9.568265914916992, -10.398201942443848, -10.565719604492188, -11.274059295654297, -36.245025634765625, -28.02727699279785, -17.42220687866211, -15.76911735534668, -17.252071380615234, -48.209041595458984, -26.59796142578125, -13.014473915100098, -14.6381196975708, -23.465206146240234, -61.988258361816406, -19.21907615661621, -13.211036682128906, -24.3845157623291, -61.988258361816406, -25.821504592895508, -23.475324630737305, -49.62074661254883, -41.08598709106445, -35.14928436279297, -39.817909240722656, -38.38576889038086, -33.301246643066406, -37.35254669189453, -32.76797866821289, -30.253755569458008, -34.272369384765625, -31.121313095092773, -32.866153717041016, -35.75813674926758, -35.9338264465332, -35.53214645385742, -41.21839904785156, -39.08578872680664, -40.717071533203125, -46.37916564941406, -42.69740676879883, -47.90448760986328, -43.754390716552734, -46.093482971191406, -42.119441986083984, -49.33628463745117, -46.716835021972656, -50.989070892333984, -53.12818908691406, -55.25045394897461, -56.97759246826172, -57.05084991455078, -57.44963836669922, -58.04767608642578, -59.300655364990234, -60.49536895751953, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [2.0174219608306885, -40.500213623046875, -47.78261184692383, -46.7829704284668, -47.68245315551758, -46.31562805175781, -34.87240219116211, 0.6893302202224731, 11.575942039489746, 6.422801971435547, -8.18140697479248, -30.154390335083008, -29.64696502685547, -48.62406921386719, -44.15705108642578, -33.20649337768555, 0.8304694294929504, 14.390426635742188, 10.813423156738281, 16.976715087890625, 9.616764068603516, -27.269868850708008, -42.53708267211914, -50.74573516845703, -45.051910400390625, -5.233938694000244, 6.338386058807373, 4.283585071563721, -4.361134052276611, 3.5957536697387695, -0.9789612293243408, -31.314924240112305, -43.311500549316406, -41.758087158203125, -20.436321258544922, -9.671207427978516, -10.223991394042969, -23.184070587158203, -10.924051284790039, 0.27036166191101074, -4.351176738739014, -37.77317428588867, -43.450439453125, -7.16151762008667, -3.0038909912109375, -10.611717224121094, -33.599273681640625, -2.0569517612457275, -0.7010705471038818, -18.83692169189453, -9.607568740844727, -5.967912673950195, -18.791404724121094, -30.75592803955078, -8.854117393493652, -9.927506446838379, -8.985950469970703, -9.155388832092285, -33.65018081665039, -25.034114837646484, -13.950361251831055, -15.272232055664062, -18.38249397277832, -47.641910552978516, -25.36806869506836, -11.855388641357422, -11.96902084350586, -23.118913650512695, -61.988258361816406, -18.3204345703125, -14.871763229370117, -26.602785110473633, -61.988258361816406, -27.839384078979492, -26.470003128051758, -52.16546630859375, -41.150089263916016, -33.17015838623047, -36.48236846923828, -36.31730270385742, -28.755884170532227, -31.91168212890625, -31.969154357910156, -29.201906204223633, -33.06885528564453, -31.623361587524414, -32.90918731689453, -36.44586944580078, -37.11204147338867, -36.64202880859375, -41.56155014038086, -40.19054412841797, -40.44593048095703, -44.14341354370117, -40.19831085205078, -45.946388244628906, -42.90699005126953, -46.478919982910156, -43.348655700683594, -48.4459228515625, -48.680877685546875, -51.281829833984375, -53.35179901123047, -54.199851989746094, -55.953887939453125, -57.36083984375, -56.34677505493164, -57.465511322021484, -58.95477294921875, -61.037559509277344, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [0.5284417271614075, -36.94343948364258, -47.76972961425781, -45.008827209472656, -48.92676544189453, -44.792877197265625, -35.692501068115234, -0.1070660948753357, 10.098308563232422, 6.65895938873291, -3.3850555419921875, -30.729652404785156, -30.02056884765625, -47.97157287597656, -46.77058410644531, -35.98780822753906, -1.992879033088684, 8.980883598327637, 7.1457719802856445, 14.050436019897461, 7.257159233093262, -24.318349838256836, -40.5084228515625, -47.94933319091797, -45.16200637817383, -5.70664644241333, 4.2415266036987305, 2.9391865730285645, -3.0155959129333496, 8.070626258850098, 1.7526882886886597, -37.22514343261719, -47.83346176147461, -45.615013122558594, -19.650209426879883, -5.4744486808776855, -6.753819465637207, -24.987686157226562, -9.132716178894043, -2.1357855796813965, -5.309342384338379, -39.94183349609375, -42.82433319091797, -5.362361907958984, 0.516516387462616, -9.003872871398926, -30.208223342895508, -1.789861798286438, -0.5307630300521851, -19.093168258666992, -8.338321685791016, -4.537529468536377, -17.113107681274414, -28.443574905395508, -7.357517242431641, -8.893643379211426, -10.158833503723145, -9.86799144744873, -32.66714859008789, -22.781681060791016, -13.07020092010498, -14.616985321044922, -18.20321273803711, -44.55049133300781, -25.649982452392578, -12.680758476257324, -12.098917961120605, -22.692264556884766, -61.53150177001953, -23.016502380371094, -18.389127731323242, -28.068424224853516, -61.988258361816406, -27.966936111450195, -26.766977310180664, -49.441368103027344, -35.472999572753906, -28.627126693725586, -32.809349060058594, -33.73032760620117, -24.78667449951172, -29.00459098815918, -31.619060516357422, -28.807373046875, -33.31845474243164, -32.05182647705078, -33.203433990478516, -36.98051834106445, -37.703399658203125, -37.68527603149414, -40.44786071777344, -41.17633819580078, -39.74978256225586, -42.51358413696289, -39.2226448059082, -44.72323989868164, -42.2154655456543, -48.83551025390625, -46.59013748168945, -50.517364501953125, -48.599853515625, -50.60504150390625, -52.19411849975586, -51.10758972167969, -54.53804397583008, -57.083045959472656, -55.29478454589844, -57.531654357910156, -58.708961486816406, -60.50859451293945, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-0.8793412446975708, -19.083364486694336, -20.3824462890625, -20.269508361816406, -19.40088653564453, -18.3129940032959, -16.415922164916992, -1.8198074102401733, 9.637845039367676, 10.49370288848877, -0.38898414373397827, -15.881063461303711, -20.12201690673828, -20.568693161010742, -18.90105628967285, -14.260456085205078, -1.2280309200286865, 5.428823471069336, 5.250546455383301, 6.583948612213135, 2.8962268829345703, -18.463193893432617, -21.184633255004883, -17.097423553466797, -12.266714096069336, -2.9742074012756348, 8.802818298339844, 7.22318172454834, -1.96491539478302, 6.804042816162109, 0.8406108021736145, -18.301284790039062, -21.195152282714844, -23.631683349609375, -17.961986541748047, -3.899235486984253, -5.084931373596191, -22.100879669189453, -7.655141353607178, 2.326510429382324, -2.3278982639312744, -20.73571014404297, -26.03318977355957, -8.266942024230957, -3.1409811973571777, -9.708803176879883, -14.998292922973633, -2.9344358444213867, -1.8648357391357422, -16.14623260498047, -9.858415603637695, -5.661280155181885, -15.189224243164062, -22.498838424682617, -8.469388008117676, -9.586889266967773, -12.5651273727417, -11.912375450134277, -29.274015426635742, -21.974205017089844, -11.766057014465332, -13.069007873535156, -17.126728057861328, -33.969947814941406, -26.388992309570312, -16.357744216918945, -14.992104530334473, -22.51471519470215, -47.62876510620117, -27.19390869140625, -22.18178939819336, -29.857227325439453, -61.988258361816406, -26.606319427490234, -27.63697052001953, -46.92376708984375, -32.00663757324219, -24.929590225219727, -30.759897232055664, -33.09079360961914, -24.548015594482422, -28.29636001586914, -32.584320068359375, -29.16136932373047, -35.57017135620117, -33.554931640625, -34.34259033203125, -38.113868713378906, -38.42178726196289, -38.83100509643555, -39.28199005126953, -42.38909912109375, -40.26639938354492, -41.58518981933594, -39.26106262207031, -45.252052307128906, -42.73503112792969, -48.80999755859375, -47.686744689941406, -52.50846481323242, -47.381988525390625, -49.233909606933594, -50.991676330566406, -51.231632232666016, -53.51749038696289, -56.48701477050781, -55.925296783447266, -56.36701202392578, -57.9437255859375, -58.105411529541016, -59.41400146484375, -60.129608154296875, -60.9732666015625, -61.84498596191406, -61.75115966796875, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406, -61.988258361816406], [-3.5004806518554688, -11.3478364944458, -12.347545623779297, -12.378963470458984, -11.422348022460938, -10.466415405273438, -8.240558624267578, -3.337078332901001, 5.0871124267578125, 10.188215255737305, -1.6846950054168701, -8.085050582885742, -12.124663352966309, -12.663568496704102, -10.821833610534668, -6.572467803955078, 3.477766513824463, 8.4827880859375, 3.9741082191467285, -0.3747594356536865, 1.4187910556793213, -11.938827514648438, -14.517723083496094, -9.356090545654297, -4.624794960021973, 3.2546043395996094, 7.846271514892578, 8.211302757263184, 1.2367154359817505, 0.25152942538261414, -2.534316062927246, -9.832708358764648, -13.384231567382812, -15.67903995513916, -12.921586990356445, -6.827066421508789, -6.828413486480713, -16.361370086669922, -4.796656131744385, 0.4677237272262573, -1.0538190603256226, -12.579002380371094, -18.054025650024414, -14.208120346069336, -13.232909202575684, -9.78850269317627, -6.629861831665039, -1.4263279438018799, 0.10855261236429214, -10.334395408630371, -8.78702163696289, -3.58961820602417, -17.520462036132812, -16.84980583190918, -11.27630615234375, -8.983682632446289, -14.504566192626953, -15.718530654907227, -23.432804107666016, -21.97238540649414, -12.159452438354492, -10.763894081115723, -19.545881271362305, -28.231502532958984, -25.966983795166016, -20.18916130065918, -15.073808670043945, -23.365772247314453, -40.6544303894043, -30.18996810913086, -27.82195281982422, -35.57120895385742, -59.0355110168457, -24.96422004699707, -27.133405685424805, -47.496864318847656, -28.233469009399414, -23.014236450195312, -28.92414093017578, -33.1284294128418, -24.534542083740234, -26.6970157623291, -34.387840270996094, -33.151100158691406, -37.8096809387207, -34.0700798034668, -35.46026611328125, -39.26472473144531, -40.39177322387695, -38.78105545043945, -37.959388732910156, -43.24217987060547, -39.89440155029297, -39.68659591674805, -38.06682205200195, -46.252662658691406, -44.61403274536133, -46.128536224365234, -44.88315200805664, -49.29287338256836, -45.31755828857422, -47.17428207397461, -49.05957794189453, -49.06821823120117, -49.73809051513672, -53.6534423828125, -51.58980941772461, -51.07658386230469, -53.298946380615234, -52.7983283996582, -54.1260871887207, -54.43464279174805, -54.492496490478516, -54.92631912231445, -54.83893585205078, -55.865379333496094, -55.78761291503906, -56.041961669921875, -56.03123092651367, -56.41376495361328, -56.551780700683594, -56.902488708496094, -56.71989822387695, -56.96674346923828, -57.16245651245117, -57.29151153564453, -57.39493942260742, -57.41645431518555]]\n",
            "one element in data['labels'] is: [1, 1, 0, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "def investigate_data(data):\n",
        "\n",
        "  # verify some informations about data dictionary\n",
        "  print(f\"type of data is: {type(data)}\")\n",
        "  print(f\"dictionary keys of dict are: {data.keys()}\")\n",
        "\n",
        "  # shape\n",
        "  print(f\"shape of data['spectrogram'] is: {np.shape(data['spectrogram'])}\")\n",
        "  print(f\"shape of data['labels'] is: {np.shape(data['labels'])}\")\n",
        "\n",
        "  # length\n",
        "  print(f\"len of data['spectrogram'] is: {len(data['spectrogram'])}\")\n",
        "  print(f\"len of data['labels'] is: {len(data['labels'])}\")\n",
        "\n",
        "  # type\n",
        "  print(f\"type of data['spectrogram'] is: {type(data['spectrogram'])}\")\n",
        "  print(f\"type of data['labels'] is: {type(data['labels'])}\")\n",
        "\n",
        "  # one element\n",
        "  print(f\"one element in data['names'] is: {data['names'][12]}\")\n",
        "  print(f\"one element in data['spectrogram'] is: {data['spectrogram'][12]}\")\n",
        "  print(f\"one element in data['labels'] is: {data['labels'][12]}\")\n",
        "\n",
        "investigate_data(data_complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15nefnUinHJU"
      },
      "outputs": [],
      "source": [
        "# functions\n",
        "\n",
        "def load_data_not_from_file(data):\n",
        "    X = np.array(data[\"spectrogram\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y\n",
        "    \n",
        "    \n",
        "def plot_model_structure(model):\n",
        "    keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)  # added mike\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def verify_input_shape(file):\n",
        "    shape = np.shape(file)\n",
        "    print(f\"X input shape is {shape}\\nthe meaning is (samples, frames, coefficients)\")\n",
        "\n",
        "def normalize_spectrogram(matrix):\n",
        "    \"\"\"normalizes between 0 and 1\"\"\"\n",
        "    min = np.min(matrix)\n",
        "    max = np.max(matrix)\n",
        "    new_matrix = (matrix - min) / (max - min)\n",
        "    return new_matrix\n",
        "\n",
        "def standardize_spectrogram(matrix):\n",
        "    mean = np.mean(matrix)\n",
        "    std = np.std(matrix)\n",
        "    new_matrix = (matrix - mean) / std\n",
        "    return new_matrix\n",
        "\n",
        "\n",
        "# problem: slices of the same guitar track can go in different sets (train and test)\n",
        "def prepare_dataset_for_cnn(data, test_size, validation_size):\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data_not_from_file(data)\n",
        "    \n",
        "    # - - - NEW 05/09/22 - standardize or normalize spectrogram - - -\n",
        "    # X_std = map(standardize_spectrogram, X)\n",
        "    # X_std = np.array(list(X))\n",
        "\n",
        "    # create train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True)\n",
        "\n",
        "    # create train/validation split\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_size, shuffle=True)\n",
        "\n",
        "    # add 3rd dimension for CNN\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_valid = X_valid[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \n",
        "    # create model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 4th conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((2,2), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "\n",
        "    # flatten the output and feed into dense layer\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(5, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def compile_model(model, learning_rate=0.001):  \n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset_for_guitar_cross_validation(data, test_guitar = 'strato'):\n",
        "\n",
        "    # 64000 segments in total2\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    N_test = []\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    N_train = []\n",
        "    \n",
        "    count_test = 0\n",
        "    count_train = 0\n",
        "    \n",
        "    # i goes from 0 to 63999\n",
        "    for i, name in enumerate(data['names']):\n",
        "      if name[:3] == test_guitar[:3]:   \n",
        "        \n",
        "        X_test.append(data['spectrogram'][i])\n",
        "        y_test.append(data['labels'][i])\n",
        "        N_test.append(data['names'][i])\n",
        "        count_test += 1\n",
        "\n",
        "      else:\n",
        "\n",
        "        X_train.append(data['spectrogram'][i])\n",
        "        y_train.append(data['labels'][i])\n",
        "        N_train.append(data['names'][i])\n",
        "        count_train += 1\n",
        "\n",
        "    print(f'train set: {count_train}')\n",
        "    print(f'test set: {count_test} (guitar: {test_guitar})')\n",
        "\n",
        "\n",
        "    # from list to numpy array \n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "    # add 3rd dimension\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, N_train, N_test\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'tele')"
      ],
      "metadata": {
        "id": "a_L2na309JYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1hN5uA-t821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aedd0465-43aa-4c4e-a714-0660b7a68095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: tele)\n",
            "input_shape: (87, 128, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 85, 126, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 43, 63, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 43, 63, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 41, 61, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 21, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 21, 31, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 19, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 10, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 15, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 13, 32)         9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 7, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 7, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 896)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                28704     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,501\n",
            "Trainable params: 58,245\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 15s 9ms/step - loss: 0.6191 - accuracy: 0.1888 - val_loss: 0.5179 - val_accuracy: 0.2374\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.5146 - accuracy: 0.2652 - val_loss: 0.4235 - val_accuracy: 0.3161\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4269 - accuracy: 0.3431 - val_loss: 0.3463 - val_accuracy: 0.4092\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 6s 7ms/step - loss: 0.3599 - accuracy: 0.3985 - val_loss: 0.2746 - val_accuracy: 0.4113\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3212 - accuracy: 0.4212 - val_loss: 0.2475 - val_accuracy: 0.4226\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2965 - accuracy: 0.4365 - val_loss: 0.2366 - val_accuracy: 0.4144\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2777 - accuracy: 0.4446 - val_loss: 0.2388 - val_accuracy: 0.5098\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2626 - accuracy: 0.4501 - val_loss: 0.2123 - val_accuracy: 0.4061\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2507 - accuracy: 0.4564 - val_loss: 0.2024 - val_accuracy: 0.4454\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2401 - accuracy: 0.4591 - val_loss: 0.2013 - val_accuracy: 0.4717\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2296 - accuracy: 0.4562 - val_loss: 0.2019 - val_accuracy: 0.4184\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2195 - accuracy: 0.4582 - val_loss: 0.1884 - val_accuracy: 0.4290\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2129 - accuracy: 0.4550 - val_loss: 0.1772 - val_accuracy: 0.4285\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2021 - accuracy: 0.4487 - val_loss: 0.1840 - val_accuracy: 0.4674\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1919 - accuracy: 0.4538 - val_loss: 0.1646 - val_accuracy: 0.4889\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1799 - accuracy: 0.4515 - val_loss: 0.1521 - val_accuracy: 0.3812\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1644 - accuracy: 0.4492 - val_loss: 0.1425 - val_accuracy: 0.4928\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1516 - accuracy: 0.4514 - val_loss: 0.1313 - val_accuracy: 0.4657\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1387 - accuracy: 0.4507 - val_loss: 0.1007 - val_accuracy: 0.4016\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 6s 7ms/step - loss: 0.1278 - accuracy: 0.4489 - val_loss: 0.0903 - val_accuracy: 0.3953\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0903 - accuracy: 0.3953\n",
            "keras accuracy: 0.39531248807907104\n",
            "manual_accuracy: 0.855375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# import time\n",
        "# from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/4__thesis/models/CNN_5_effects_entire_dataset.h5'\n",
        "\n",
        "# name of the model\n",
        "#time_float = int(time.time()) + 2 * 60 * 60\n",
        "#date = datetime.fromtimestamp(time_float)\n",
        "\n",
        "def generic_cnn():\n",
        " \n",
        "  # old - create train, validation and test sets\n",
        "  #X_train, X_valid, X_test, y_train, y_valid, y_test = prepare_dataset_for_cnn(data_complete, 0.15, 0.15)\n",
        "\n",
        "  # new - use one guitar as test the other 3 guitars as train\n",
        "  X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'tele')\n",
        "\n",
        "  # build the CNN net\n",
        "  input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "  print(f\"input_shape: {input_shape}\")\n",
        "\n",
        "  model = build_model(input_shape)\n",
        "  model = compile_model(model, learning_rate=0.00005)\n",
        "  history = model.fit(X_train, y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      batch_size=64, epochs=20, shuffle=True)  \n",
        "                      # con epochs = 50 e learning_rate= 0.00005 -> acc > 97%\n",
        "                      # keras accuracy: 0.77   (but with segments of same audio file in different sets)\n",
        "                      # manual_accuracy: 0.97  (idem)\n",
        "\n",
        "  test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "  print(f\"keras accuracy: {test_accuracy}\")\n",
        "\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred = y_pred.round()\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"manual_accuracy:\", accuracy)\n",
        "\n",
        "  # plot history\n",
        "\n",
        "  plot_history(history)\n",
        "  model.save(MODEL_SAVE_PATH)\n",
        "\n",
        "generic_cnn()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test accuracy_score function\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "a = np.array([[1, 1, 1], [1, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
        "b = np.array([[1, 1, 1], [1, 0, 0], [0, 1, 0], [1, 1, 1], [0, 0, 0]])\n",
        "\n",
        "acc = accuracy_score(a, b)\n",
        "print(acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j91LRtKWmxe",
        "outputId": "47b6bb9d-aa79-46e6-9f74-8f88ac6e043d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU6i9o-jFc6e"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "model = keras.models.load_model(MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHDkiG0Fsil5"
      },
      "source": [
        "INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SubdxTEMptI"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "inference_folder_path = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/inference/inference_5_effects'\n",
        "inference_folder_path2 = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/inference/inference_3_effects'\n",
        "\n",
        "SAMPLING_RATE = 22050\n",
        "SEGMENT_LENGTH = 44100\n",
        "NUM_SEGMENTS = 5\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/4__thesis/models/CNN_5_effects_entire_dataset.h5'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_inference(folder_path):\n",
        "  for path, folders, files in os.walk(folder_path):\n",
        "    \n",
        "    # inference data\n",
        "    inference_data = {\n",
        "        \"file_name\": [],\n",
        "        \"spectrogram\": []\n",
        "    }\n",
        "\n",
        "    # load audio files\n",
        "    for i, audio_file_name in enumerate(files):\n",
        "\n",
        "      print(f\"preprocessing file number {i+1}\")\n",
        "      # create entire path and load signal\n",
        "      audio_path = os.path.join(path, audio_file_name)\n",
        "      signal, _ = librosa.load(audio_path, SAMPLING_RATE)\n",
        "      \n",
        "      # slice signal into segments\n",
        "      for segment_index in range(NUM_SEGMENTS):\n",
        "        segment_start = segment_index * SEGMENT_LENGTH\n",
        "        current_segment = signal[segment_start:segment_start + SEGMENT_LENGTH]\n",
        "\n",
        "        # get the mel spectrogram\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=current_segment, sr=SAMPLING_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
        "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
        "        log_mel_spectrogram = log_mel_spectrogram.T\n",
        "\n",
        "        # save data      \n",
        "        current_name = audio_file_name[:-4] + f'__segm{segment_index + 1}'             \n",
        "        inference_data[\"file_name\"].append(current_name)\n",
        "        inference_data[\"spectrogram\"].append(log_mel_spectrogram.tolist())\n",
        "        \n",
        "\n",
        "  return inference_data\n",
        "\n",
        "inference_data = prepare_data_for_inference(inference_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn4JUIeiYln9",
        "outputId": "40be3dd1-641a-4d03-cb9a-366b4f50eb21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing file number 1\n",
            "preprocessing file number 2\n",
            "preprocessing file number 3\n",
            "preprocessing file number 4\n",
            "preprocessing file number 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = tf.keras.models.load_model(MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "uu201GXyikZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_88qSEin3jz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6294e8c-58c4-4020-b3ac-08f4cd4f0896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 0. 1.]  les_neck_pick05__11101__segm1\n",
            "[1. 1. 1. 0. 1.]  les_neck_pick05__11101__segm2\n",
            "[1. 1. 1. 0. 1.]  les_neck_pick05__11101__segm3\n",
            "[1. 1. 1. 0. 1.]  les_neck_pick05__11101__segm4\n",
            "[1. 1. 1. 0. 1.]  les_neck_pick05__11101__segm5\n",
            "[1. 1. 0. 0. 0.]  prs_neck_fing10__11000__segm1\n",
            "[1. 1. 0. 0. 0.]  prs_neck_fing10__11000__segm2\n",
            "[1. 1. 0. 0. 0.]  prs_neck_fing10__11000__segm3\n",
            "[1. 1. 0. 0. 0.]  prs_neck_fing10__11000__segm4\n",
            "[1. 1. 0. 0. 0.]  prs_neck_fing10__11000__segm5\n",
            "[1. 0. 1. 0. 1.]  strat_bridge_pick15__10101__segm1\n",
            "[1. 0. 1. 0. 1.]  strat_bridge_pick15__10101__segm2\n",
            "[1. 0. 1. 0. 1.]  strat_bridge_pick15__10101__segm3\n",
            "[1. 0. 1. 0. 1.]  strat_bridge_pick15__10101__segm4\n",
            "[1. 0. 1. 0. 1.]  strat_bridge_pick15__10101__segm5\n",
            "[0. 0. 0. 0. 0.]  tele_bridge_fing20__00000__segm1\n",
            "[0. 0. 0. 0. 0.]  tele_bridge_fing20__00000__segm2\n",
            "[0. 0. 0. 0. 0.]  tele_bridge_fing20__00000__segm3\n",
            "[0. 0. 0. 0. 0.]  tele_bridge_fing20__00000__segm4\n",
            "[0. 0. 0. 0. 0.]  tele_bridge_fing20__00000__segm5\n",
            "[1. 0. 0. 1. 1.]  tele_neck_pick25__10011__segm1\n",
            "[1. 0. 0. 1. 1.]  tele_neck_pick25__10011__segm2\n",
            "[1. 0. 0. 1. 1.]  tele_neck_pick25__10011__segm3\n",
            "[1. 0. 0. 1. 1.]  tele_neck_pick25__10011__segm4\n",
            "[1. 0. 0. 1. 1.]  tele_neck_pick25__10011__segm5\n"
          ]
        }
      ],
      "source": [
        "# load X and convert to numpy array\n",
        "X_inference = np.array(inference_data[\"spectrogram\"])\n",
        "\n",
        "# add 3rd dimension for feeding the CNN\n",
        "X_inference = X_inference[..., np.newaxis]\n",
        "\n",
        "# make prediction and round\n",
        "prediction = model.predict(X_inference)\n",
        "prediction_rounded = np.round(prediction)\n",
        "#prediction_rounded_decimals = np.round(prediction, decimals=2)\n",
        "\n",
        "# print results\n",
        "for index in range(len(prediction_rounded)):\n",
        "  print(prediction_rounded[index], end = \"  \") \n",
        "  print(inference_data[\"file_name\"][index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6qthDdbPD_u"
      },
      "outputs": [],
      "source": [
        "# load data for next cell\n",
        "X, y = load_data_not_from_file(data_complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vTgaMZ09tzl"
      },
      "outputs": [],
      "source": [
        "# for this function the generic_cnn should not be a function. In order for this cell to get the value of X_test\n",
        "predictions = []\n",
        "index_bad_results = []\n",
        "\n",
        "for i in range(2000):\n",
        "  prediction = model.predict(X[i:i+1])\n",
        "  prediction_rounded = np.around(prediction, decimals=0)\n",
        "  true_label_value = y[i]\n",
        "  result = (prediction_rounded==true_label_value)\n",
        "\n",
        "  count = 0   # count how many False each prediction\n",
        "  for j in result[0]:\n",
        "    if j==False:\n",
        "      count+=1\n",
        "  if count > 0:\n",
        "    # save wrong indexes and anwers\n",
        "    index_bad_results.append(i)\n",
        "    predictions.append(prediction_rounded)\n",
        "\n",
        "print(index_bad_results)\n",
        "print(len(index_bad_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIbLnukDPkBa"
      },
      "outputs": [],
      "source": [
        "for i, index in enumerate(index_bad_results):\n",
        "  print('current index:', index)\n",
        "  print('correct:', data_complete['names'][index][-13:-6])\n",
        "  print('predicted:', predictions[i])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VOrH_ij0uVh"
      },
      "source": [
        "GENETIC ALGORITHMS OPTIMIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y94pJtM20t1N"
      },
      "outputs": [],
      "source": [
        "from random import randint, uniform, random\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz3iScAWEZJ1"
      },
      "outputs": [],
      "source": [
        "def initialize_first_population(population_size, verbose=True, start_with_low_values=True):\n",
        "  \"\"\"Initialize the fist population of Genetic Algorithms(GAs).\n",
        "  Create each individual randomly\"\"\"\n",
        "\n",
        "  # parameters\n",
        "  # 0 - HOW MANY CONV. LAYERS                   [min: 1, max: 5]\n",
        "  \n",
        "  # 1 - filters          of 1st conv layer      [2 -> 64]\n",
        "  # 2 - x kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 3 - y kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 4 - x size           of 1st maxpool layer   [1 -> 2]\n",
        "  # 5 - y size           of 1st maxpool layer   [1 -> 2]\n",
        "\n",
        "  #  6,  7,  8,  9, 10 - same but considering 2nd layer (if present)\n",
        "  # 11, 12, 13, 14, 15 - same but considering 3rd layer (if present)\n",
        "  # 16, 17, 18, 19, 20 - same but considering 4th layer (if present)\n",
        "  # 21, 22, 23, 24, 25 - same but considering 5th layer (if present)\n",
        "  # ----------------------------------------------------\n",
        "  \n",
        "  # 26 - HOW MANY DENSE LAYERS [min: 1, max: 3]\n",
        "  \n",
        "  # 27 - neurons         of 1st dense layer     [2 -> 64]\n",
        "  # 28 - dropout prob.   of 1st dense layer     [0 -> 0.5]\n",
        "  # 29 - neurons         of 2nd dense layer (if present)\n",
        "  # 30 - dropout prob.   of 2nd dense layer (if present)\n",
        "  # 31 - neurons         of 3rd dense layer (if present)\n",
        "  # 32 - dropout prob.   of 3rd dense layer (if present)\n",
        "\n",
        "  print_info_first_individual = verbose\n",
        "  \n",
        "  \n",
        "  # list that will contain all the individuals\n",
        "  population = []\n",
        "\n",
        "  for individual_index in range(population_size):\n",
        "    \n",
        "    if verbose:\n",
        "      print(f\"Creating individual {individual_index + 1} out of {population_size}\")\n",
        "    \n",
        "    current_individual = [0] * 33  # [0, 0, 0...., 0]\n",
        "    \n",
        "    # define how many conv layers and dense layers\n",
        "    current_individual[0] = randint(1, 5)\n",
        "    current_individual[26] = randint(1, 3)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\")\n",
        "    for list_index in range(1, 22, 5):\n",
        "      if start_with_low_values:\n",
        "        current_individual[list_index] = randint(2, 8)\n",
        "      else:\n",
        "        current_individual[list_index] = randint(2, 64)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\")\n",
        "    for list_index in range(2, 23, 5):\n",
        "      current_individual[list_index] = randint(2, 7)\n",
        "      current_individual[list_index + 1] = randint(2, 7)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\")\n",
        "    for list_index in range(4, 25, 5):\n",
        "      current_individual[list_index] = randint(1, 2)\n",
        "      current_individual[list_index + 1] = randint(1, 2)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working # of neurons in dense layers     (index: 27, 29, 31)\")\n",
        "    for list_index in range(27, 32, 2):\n",
        "      if start_with_low_values:\n",
        "        current_individual[list_index] = randint(2, 8)\n",
        "      else:\n",
        "        current_individual[list_index] = randint(2, 64)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working dropout prob. after dense layers (index: 28, 30, 32)\")\n",
        "    for list_index in range(28, 33, 2):\n",
        "      # round approx. the number to second decimal\n",
        "      current_individual[list_index] = round(uniform(0.0, 0.5), 2)\n",
        "\n",
        "    if verbose:\n",
        "      print(current_individual, end=\"\\n\\n\")\n",
        "\n",
        "    population.append(current_individual)\n",
        "\n",
        "    print_info_first_individual = False\n",
        "      \n",
        "  return population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_GxyF-bzV7O"
      },
      "outputs": [],
      "source": [
        "# build and compile the model\n",
        "def build_and_compile_model(indiv, input_shape):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # create first conv layer + pooling layer\n",
        "  model.add(keras.layers.Conv2D(filters=indiv[1], kernel_size=(indiv[2], indiv[3]), input_shape=input_shape, activation='relu', padding='same'))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=(indiv[4], indiv[5]), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # create other conv layers + pooling layers\n",
        "  remain_conv_layer = indiv[0] - 1\n",
        "  for i in range(6, 6 + remain_conv_layer * 4, 5):\n",
        "    model.add(keras.layers.Conv2D(filters=indiv[i], kernel_size=(indiv[i+1], indiv[i+2]), activation='relu', padding='same'))\n",
        "    #model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "    \n",
        "  # flatten\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  # create dense layers + dropout\n",
        "  dense_layers = indiv[26]  # how many dense layers we have\n",
        "  for j in range(27, 27 + dense_layers * 2, 2):\n",
        "    model.add(keras.layers.Dense(units=indiv[j], activation='relu'))\n",
        "    model.add(keras.layers.Dropout(indiv[j+1]))\n",
        "\n",
        "  # add final layer\n",
        "  model.add(keras.layers.Dense(units=5, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "#individual = [2, 44, 3, 7, 1, 1, 33, 2, 2, 1, 2, 51, 6, 5, 1, 1, 28, 5, 5, 2, 1, 36, 3, 4, 2, 1, 3, 9, 0.15, 63, 0.13, 38, 0.25]\n",
        "#build_and_compile_model(individual, (78, 80, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZXC4JdOghIg"
      },
      "outputs": [],
      "source": [
        "#INPUT_SHAPE = (87, 128)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def fitness_evaluation(individual, dataset):\n",
        "\n",
        "  # print current individual\n",
        "  print(f\"fitness_evaluation function. Individual considered:\\n{individual}\")\n",
        "\n",
        "  # get train and test data from dataset (or it is better to make here the train/test split??)\n",
        "  (X_train, y_train), (X_valid, y_valid) = dataset\n",
        "\n",
        "\n",
        "  # --- NEW - CONSIDER ONLY A PART OF THE DATASET FOR EVALUATION ---\n",
        "  #X_reduced, X_discarded, y_reduced, y_discaded = train_test_split(X_train, y_train, test_size = 0.7, random_state=7, shuffle=True)\n",
        "\n",
        "\n",
        "  # build CNN associated to the individual\n",
        "  input_shape = np.shape(X_train[1])\n",
        "  #print(f\"input_shape: {input_shape}\")\n",
        "  model = build_and_compile_model(individual, input_shape)\n",
        "\n",
        "  # evaluate the model/individual (implementing early stopping??)\n",
        "  model.fit(X_train, y_train, epochs=15, batch_size=64, shuffle=True, validation_data = (X_valid, y_valid))\n",
        "\n",
        "  # get the accuracy on valid set (not used now)\n",
        "  loss, accuracy = model.evaluate(X_valid, y_valid)   # can use loss intead of accuracy\n",
        "\n",
        "  # NEW - sklearn accuracy\n",
        "  y_pred = model.predict(X_valid)\n",
        "  y_pred = y_pred.round()\n",
        "  sklearn_accuracy = accuracy_score(y_valid, y_pred)\n",
        "  print(f\"sklearn_accuracy:\", sklearn_accuracy)\n",
        "\n",
        "  # i can consider to return - (1/loss)\n",
        "  return sklearn_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBvarPb6gtlT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# population evaluation (funzione testata)\n",
        "def population_evaluation(population, dataset):\n",
        "  \"\"\"population_evaluation gets the performace of each individual in the current population. \n",
        "  It stores in a dictionary 3 elements: the current population and the fitness and the probability\n",
        "  of each individal\"\"\"\n",
        "  \n",
        "  # print individual to verify if population is correct\n",
        "  #print(f\"POPULATION EVALUATION\\n Here the list of the {POLPULATION_SIZE} individuals\")\n",
        "  #for individual in population:\n",
        "  #  print(individual)\n",
        "\n",
        "  # dictionary to store information about population\n",
        "  population_eval ={\n",
        "      \"population\":[],\n",
        "      \"fitness\":[],\n",
        "      \"probability\":[],\n",
        "      \"best_individual\": [],\n",
        "      \"statistics\": {\"min\":0, \"max\":0, \"average\":0}\n",
        "  }\n",
        "  # save pupulation into dictionary\n",
        "  population_eval[\"population\"] = population.copy()\n",
        "\n",
        "  # perform and save fitness for each individual - enumerate counts starting from 1\n",
        "  for i, individual in enumerate(population, 1):\n",
        "\n",
        "    # Here a CNN is built and evaluated\n",
        "    print(f\"\\n({i}/{POPULATION_SIZE})\", end=\" - \")\n",
        "    fitness = fitness_evaluation(individual, dataset)\n",
        "\n",
        "    # free memory occupied by keras model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "    population_eval[\"fitness\"].append(fitness)\n",
        "  \n",
        "  # perform and save probability for each individual\n",
        "  sum_of_fitnesses = np.sum(population_eval[\"fitness\"])\n",
        "  for fitness_value in population_eval[\"fitness\"]:\n",
        "    probability_value = fitness_value / sum_of_fitnesses\n",
        "    population_eval[\"probability\"].append(probability_value)\n",
        "\n",
        "  # save best individual\n",
        "  best_individual_index = np.argmax(population_eval[\"fitness\"])\n",
        "  best_individual = population_eval[\"population\"][best_individual_index]\n",
        "  population_eval[\"best_individual\"].append(best_individual)\n",
        "\n",
        "  # save min, max and average\n",
        "  max = np.max(population_eval[\"fitness\"])\n",
        "  min = np.min(population_eval[\"fitness\"])\n",
        "  average = np.average(population_eval[\"fitness\"])\n",
        "\n",
        "  population_eval[\"statistics\"][\"min\"] = min\n",
        "  population_eval[\"statistics\"][\"max\"] = max\n",
        "  population_eval[\"statistics\"][\"average\"] = average\n",
        "\n",
        "  return population_eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rm1T2E4Fp3O"
      },
      "outputs": [],
      "source": [
        "# selection function\n",
        "def selection(population_eval):\n",
        "  \"\"\"selects one individual based on roulette wheels selection\"\"\"\n",
        "\n",
        "  # implement roulette wheel selection\n",
        "  R = random()\n",
        "  #print(R)\n",
        "\n",
        "  # first iter (p.1), second iter (p.1 + p.2), ...\n",
        "  sum_of_probabilities = 0\n",
        "  for index in range(len(population_eval[\"probability\"])):\n",
        "\n",
        "    sum_of_probabilities += population_eval[\"probability\"][index]\n",
        "\n",
        "    if sum_of_probabilities > R:\n",
        "\n",
        "      selected_individual = population_eval[\"population\"][index]\n",
        "      break\n",
        "\n",
        "  return selected_individual, index\n",
        "\n",
        "\n",
        "def select_two_individuals(population_eval):\n",
        "  \"\"\"selects two different individuals in current population \"\"\"\n",
        "\n",
        "  first_individual, first_index = selection(population_eval)\n",
        "  second_individual, second_index = selection(population_eval)\n",
        "\n",
        "  while first_index == second_index:\n",
        "    second_individual, second_index = selection(population_eval)\n",
        "\n",
        "  return first_individual, second_individual\n",
        "\n",
        "\n",
        "# test selection\n",
        "def test_selection():\n",
        "  indiv = [[1,2,3], [4,5,6], [7,8,9], [10,11,12], [2, 3, 2]]\n",
        "  indiv_prob = [0.1, 0.2, 0.2, 0.4, 0.1]\n",
        "\n",
        "\n",
        "  p_eval = {\n",
        "      \"population\": indiv,\n",
        "      \"probability\": indiv_prob\n",
        "  }\n",
        "  print(select_two_individuals(p_eval))\n",
        "  # return the two individuals\n",
        "\n",
        "#test_selection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwnJTJ0ENt_t"
      },
      "outputs": [],
      "source": [
        "# crossover function\n",
        "def single_point_crossover(individual_1, individual_2, CROSSOVER_PROB):\n",
        "  \"\"\"performs single point crossover between two individuals with a certain probability.\n",
        "  returns 1' individual if crossover is not performed \"\"\"\n",
        "\n",
        "  # single point crossover\n",
        "  random_crossover_point = randint(1, len(individual_1)-1)  # how many elements I keep from 1' individual\n",
        "  #print(f\"crossover_point: {random_crossover_point}\")\n",
        "\n",
        "  # create new individual\n",
        "  new_individual = []\n",
        "  for index in range(len(individual_1)):\n",
        "    if index < random_crossover_point:\n",
        "      new_individual.append(individual_1[index])\n",
        "    else:\n",
        "       new_individual.append(individual_2[index])\n",
        "\n",
        "  # consider crossover probability\n",
        "  random_value = random()\n",
        "  #print(\"random_value:\", random_value)\n",
        "  if CROSSOVER_PROB > random_value:\n",
        "    return new_individual\n",
        "  return individual_1\n",
        " \n",
        "def test_crossover():\n",
        "  ind_1 = [1, 2, 3, 4, 5, 6, 7, 8, 9 ]\n",
        "  ind_2 = [10,20,30,40,50,60,70,80,90]\n",
        "\n",
        "  print(single_point_crossover(ind_1, ind_2, 0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5m1QqKWCQE8"
      },
      "outputs": [],
      "source": [
        "# mutation function\n",
        "def mutation(individual, MUTATION_PROB):\n",
        "\n",
        "  # parameters\n",
        "  # 0 - HOW MANY CONV. LAYERS                   [min: 1, max: 5]\n",
        "  \n",
        "  # 1 - filters          of 1st conv layer      [2 -> 64]\n",
        "  # 2 - x kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 3 - y kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 4 - x size           of 1st maxpool layer   [1 -> 2]\n",
        "  # 5 - y size           of 1st maxpool layer   [1 -> 2]\n",
        "\n",
        "  #  6,  7,  8,  9, 10 - same but considering 2nd layer (if present)\n",
        "  # 11, 12, 13, 14, 15 - same but considering 3rd layer (if present)\n",
        "  # 16, 17, 18, 19, 20 - same but considering 4th layer (if present)\n",
        "  # 21, 22, 23, 24, 25 - same but considering 5th layer (if present)\n",
        "  # ----------------------------------------------------\n",
        "  \n",
        "  # 26 - HOW MANY DENSE LAYERS [min: 1, max: 3]\n",
        "  \n",
        "  # 27 - neurons         of 1st dense layer     [2 -> 64]\n",
        "  # 28 - dropout prob.   of 1st dense layer     [0 -> 0.5]\n",
        "  # 29 - neurons         of 2nd dense layer (if present)\n",
        "  # 30 - dropout prob.   of 2nd dense layer (if present)\n",
        "  # 31 - neurons         of 3rd dense layer (if present)\n",
        "  # 32 - dropout prob.   of 3rd dense layer (if present)\n",
        "\n",
        "  # define how many conv layers and dense layers\n",
        "    \n",
        "  indeces_with_filters_or_neurons = [1, 6, 11, 16, 21, 27, 29, 31]\n",
        "  indeces_with_kernel_dim = [2, 3, 7, 8, 12, 13, 17, 18, 22, 23]\n",
        "  indeces_with_MaxPool_dim = [4, 5, 9, 10, 14, 15, 19, 20, 24, 25]\n",
        "  indeces_with_dropout_prob = [28, 30, 32]\n",
        "\n",
        "  for index in range(len(individual)):\n",
        "\n",
        "    random_number = random()\n",
        "    if MUTATION_PROB > random_number:\n",
        "\n",
        "      # new - use lower probability (half!) for number of layers\n",
        "      if random() > 0.5:  # not in thesis implementation\n",
        "        if index == 0:\n",
        "          individual[index] = randint(1, 5)\n",
        "\n",
        "        if index == 26:\n",
        "          individual[index] = randint(1, 3)\n",
        "\n",
        "      # consider conv filters and neurons in dense layer\n",
        "      if index in indeces_with_filters_or_neurons:\n",
        "        new_value = individual[index] + randint(-3, 3) + 5  # in thesis implementation +3 (not + 5)\n",
        "        # if value is not in range try again\n",
        "        while (not 2 <= new_value <= 64):\n",
        "          new_value = individual[index] + randint(-3, 3) + 5\n",
        "        individual[index] = new_value\n",
        "\n",
        "      # consider kernel dimension\n",
        "      if index in indeces_with_kernel_dim:\n",
        "        individual[index] = randint(2, 7)\n",
        "\n",
        "      # consider maxpool dimension\n",
        "      if index in indeces_with_MaxPool_dim:\n",
        "        individual[index] = randint(1, 2)\n",
        "\n",
        "      # consider dropout probability\n",
        "      if index in indeces_with_dropout_prob:\n",
        "\n",
        "        variation = (random() - 0.5) * 0.2  # from [-0.1 to 0.1) \n",
        "        new_value = round(individual[index] + variation, 2)\n",
        "        # if value is not in range try again (try to avoid -0.0)\n",
        "\n",
        "        while (not 0.001 <= new_value <= 0.5):\n",
        "          variation = (random() - 0.5) * 0.2\n",
        "          new_value = round(individual[index] + variation, 2)\n",
        "        individual[index] = new_value \n",
        "\n",
        "  # I'm not makineg individual.copy at the beginning, so I'm modifying the individual\n",
        "  return individual\n",
        "\n",
        "    \n",
        "   \n",
        "#individual = [2, 44, 3, 7, 1, 1, 33, 2, 2, 1, 2, 51, 6, 5, 1, 1, 28, 5, 5, 2, 1, 36, 3, 4, 2, 1, 3, 9, 0.15, 63, 0.13, 38, 0.25]\n",
        "#print(mutation(individual, 0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBDsx7XNFu9_",
        "outputId": "9c80e57c-470e-4cf0-af2b-d808be41750b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_82 (Conv2D)          (None, 87, 128, 9)        324       \n",
            "                                                                 \n",
            " max_pooling2d_82 (MaxPoolin  (None, 44, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_82 (Bat  (None, 44, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 44, 128, 6)        546       \n",
            "                                                                 \n",
            " max_pooling2d_83 (MaxPoolin  (None, 22, 128, 6)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_83 (Bat  (None, 22, 128, 6)       24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_33 (Flatten)        (None, 16896)             0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 12)                202764    \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 12)                0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 6)                 78        \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 5)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,807\n",
            "Trainable params: 203,777\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.6479 - accuracy: 0.2224 - val_loss: 0.5829 - val_accuracy: 0.1541\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5935 - accuracy: 0.1599 - val_loss: 0.5632 - val_accuracy: 0.2663\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5670 - accuracy: 0.2792 - val_loss: 0.5005 - val_accuracy: 0.2935\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5555 - accuracy: 0.2555 - val_loss: 0.4899 - val_accuracy: 0.3338\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5492 - accuracy: 0.2482 - val_loss: 0.5495 - val_accuracy: 0.2418\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5473 - accuracy: 0.2548 - val_loss: 0.4710 - val_accuracy: 0.2923\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5438 - accuracy: 0.2489 - val_loss: 0.4608 - val_accuracy: 0.3374\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5417 - accuracy: 0.2560 - val_loss: 0.4803 - val_accuracy: 0.2836\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5401 - accuracy: 0.2528 - val_loss: 0.4561 - val_accuracy: 0.3080\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5394 - accuracy: 0.2550 - val_loss: 0.4573 - val_accuracy: 0.2904\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5369 - accuracy: 0.2555 - val_loss: 0.4633 - val_accuracy: 0.3308\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5346 - accuracy: 0.2599 - val_loss: 0.4639 - val_accuracy: 0.2887\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5345 - accuracy: 0.2508 - val_loss: 0.4648 - val_accuracy: 0.3337\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5341 - accuracy: 0.2542 - val_loss: 0.4805 - val_accuracy: 0.2908\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5338 - accuracy: 0.2512 - val_loss: 0.4566 - val_accuracy: 0.2957\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4566 - accuracy: 0.2957\n",
            "sklearn_accuracy: 0.2133125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 9, 5, 4, 2, 1, 2, 5, 5, 1, 1, 3, 7, 2, 1, 2, 14, 2, 6, 1, 2, 9, 7, 6, 2, 2, 2, 5, 0.1, 7, 0.24, 14, 0.41]\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_84 (Conv2D)          (None, 87, 128, 9)        189       \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 44, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_84 (Bat  (None, 44, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_34 (Flatten)        (None, 50688)             0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 5)                 253445    \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 7)                 42        \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 253,752\n",
            "Trainable params: 253,734\n",
            "Non-trainable params: 18\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.6932 - accuracy: 0.2219 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1830 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1745 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1981 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.0671 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1864 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1527 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1940 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.2074 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.0973 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.2012 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1996 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.2331 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.2704 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.1783 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 1, 2, 2, 5, 2, 1, 3, 4, 2, 1, 2, 14, 5, 6, 2, 2, 10, 7, 2, 2, 1, 2, 12, 0.23, 6, 0.14, 8, 0.06]\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_85 (Conv2D)          (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_85 (MaxPoolin  (None, 44, 128, 4)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_85 (Bat  (None, 44, 128, 4)       16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 44, 128, 2)        82        \n",
            "                                                                 \n",
            " max_pooling2d_86 (MaxPoolin  (None, 22, 128, 2)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_86 (Bat  (None, 22, 128, 2)       8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_35 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 12)                67596     \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 12)                0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 6)                 78        \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 5)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,959\n",
            "Trainable params: 67,947\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6511 - accuracy: 0.1059 - val_loss: 0.5942 - val_accuracy: 0.0937\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6151 - accuracy: 0.1337 - val_loss: 0.5323 - val_accuracy: 0.3100\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5290 - accuracy: 0.3589 - val_loss: 0.4831 - val_accuracy: 0.3184\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4868 - accuracy: 0.3910 - val_loss: 0.4657 - val_accuracy: 0.3761\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4684 - accuracy: 0.4012 - val_loss: 0.4440 - val_accuracy: 0.3301\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4610 - accuracy: 0.3945 - val_loss: 0.4418 - val_accuracy: 0.4222\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4498 - accuracy: 0.4155 - val_loss: 0.4375 - val_accuracy: 0.3258\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4439 - accuracy: 0.4159 - val_loss: 0.4570 - val_accuracy: 0.3453\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4344 - accuracy: 0.4262 - val_loss: 0.4451 - val_accuracy: 0.3568\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4322 - accuracy: 0.4211 - val_loss: 0.4551 - val_accuracy: 0.3284\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4285 - accuracy: 0.4159 - val_loss: 0.4570 - val_accuracy: 0.3492\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4244 - accuracy: 0.4183 - val_loss: 0.4720 - val_accuracy: 0.3006\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4210 - accuracy: 0.4180 - val_loss: 0.4627 - val_accuracy: 0.3878\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4180 - accuracy: 0.4132 - val_loss: 0.6506 - val_accuracy: 0.3965\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4155 - accuracy: 0.4133 - val_loss: 0.4920 - val_accuracy: 0.3412\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.3412\n",
            "sklearn_accuracy: 0.1854375\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 1, 2, 2, 7, 2, 1, 11, 4, 7, 1, 1, 18, 4, 5, 1, 1, 11, 4, 3, 1, 1, 3, 9, 0.01, 8, 0.37, 11, 0.11]\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_87 (Conv2D)          (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_87 (MaxPoolin  (None, 44, 128, 4)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_87 (Bat  (None, 44, 128, 4)       16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 44, 128, 2)        114       \n",
            "                                                                 \n",
            " max_pooling2d_88 (MaxPoolin  (None, 22, 128, 2)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_88 (Bat  (None, 22, 128, 2)       8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_36 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 9)                 50697     \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 8)                 80        \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 11)                99        \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 11)                0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 5)                 60        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,218\n",
            "Trainable params: 51,206\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.5847 - accuracy: 0.1294 - val_loss: 0.5057 - val_accuracy: 0.1481\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4991 - accuracy: 0.1477 - val_loss: 0.4697 - val_accuracy: 0.1529\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4768 - accuracy: 0.1705 - val_loss: 0.5026 - val_accuracy: 0.1932\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4697 - accuracy: 0.1832 - val_loss: 0.4570 - val_accuracy: 0.1941\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4666 - accuracy: 0.1876 - val_loss: 0.4580 - val_accuracy: 0.1863\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4591 - accuracy: 0.2003 - val_loss: 0.4553 - val_accuracy: 0.1988\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 13ms/step - loss: 0.4589 - accuracy: 0.2129 - val_loss: 0.5075 - val_accuracy: 0.2576\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4545 - accuracy: 0.2079 - val_loss: 0.5159 - val_accuracy: 0.1893\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4492 - accuracy: 0.2130 - val_loss: 0.4545 - val_accuracy: 0.2100\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4484 - accuracy: 0.2214 - val_loss: 0.4705 - val_accuracy: 0.2237\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4475 - accuracy: 0.2200 - val_loss: 0.4664 - val_accuracy: 0.2155\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4476 - accuracy: 0.2239 - val_loss: 0.4567 - val_accuracy: 0.2257\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4425 - accuracy: 0.2295 - val_loss: 0.4577 - val_accuracy: 0.2192\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.4433 - accuracy: 0.2329 - val_loss: 0.4618 - val_accuracy: 0.2299\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 13ms/step - loss: 0.4414 - accuracy: 0.2348 - val_loss: 0.4595 - val_accuracy: 0.2362\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4595 - accuracy: 0.2362\n",
            "sklearn_accuracy: 0.204375\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 12, 2, 3, 1, 1, 7, 5, 5, 2, 2, 7, 4, 6, 2, 1, 7, 2, 5, 1, 2, 7, 5, 6, 2, 2, 2, 5, 0.12, 9, 0.32, 9, 0.37]\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_89 (Conv2D)          (None, 87, 128, 12)       84        \n",
            "                                                                 \n",
            " max_pooling2d_89 (MaxPoolin  (None, 87, 128, 12)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_89 (Bat  (None, 87, 128, 12)      48        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_90 (Conv2D)          (None, 87, 128, 7)        2107      \n",
            "                                                                 \n",
            " max_pooling2d_90 (MaxPoolin  (None, 44, 64, 7)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_90 (Bat  (None, 44, 64, 7)        28        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 44, 64, 7)         1183      \n",
            "                                                                 \n",
            " max_pooling2d_91 (MaxPoolin  (None, 22, 64, 7)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 22, 64, 7)        28        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_92 (Conv2D)          (None, 22, 64, 7)         497       \n",
            "                                                                 \n",
            " max_pooling2d_92 (MaxPoolin  (None, 22, 32, 7)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_92 (Bat  (None, 22, 32, 7)        28        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 22, 32, 7)         1477      \n",
            "                                                                 \n",
            " max_pooling2d_93 (MaxPoolin  (None, 11, 16, 7)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 11, 16, 7)        28        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_37 (Flatten)        (None, 1232)              0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 5)                 6165      \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 9)                 54        \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 5)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,777\n",
            "Trainable params: 11,697\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 33ms/step - loss: 0.6933 - accuracy: 0.1392 - val_loss: 0.6931 - val_accuracy: 0.5314\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.6932 - accuracy: 0.2393 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.6932 - accuracy: 0.2671 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.2309 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1366 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.3171 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1941 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1576 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.2582 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1023 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1992 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1388 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1690 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.1796 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6932 - accuracy: 0.2174 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 9, 5, 7, 2, 1, 2, 5, 3, 2, 2, 3, 7, 2, 1, 2, 19, 4, 3, 1, 1, 12, 7, 7, 1, 2, 3, 5, 0.01, 7, 0.4, 13, 0.33]\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_94 (Conv2D)          (None, 87, 128, 9)        324       \n",
            "                                                                 \n",
            " max_pooling2d_94 (MaxPoolin  (None, 44, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 44, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 44, 128, 2)        272       \n",
            "                                                                 \n",
            " max_pooling2d_95 (MaxPoolin  (None, 22, 64, 2)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 22, 64, 2)        8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_38 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 5)                 14085     \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 7)                 42        \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 13)                104       \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 5)                 70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,941\n",
            "Trainable params: 14,919\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6320 - accuracy: 0.1376 - val_loss: 0.5650 - val_accuracy: 0.0974\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5648 - accuracy: 0.1146 - val_loss: 0.5673 - val_accuracy: 0.0778\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5475 - accuracy: 0.1340 - val_loss: 0.5245 - val_accuracy: 0.1206\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5341 - accuracy: 0.1501 - val_loss: 0.5209 - val_accuracy: 0.1375\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5291 - accuracy: 0.1583 - val_loss: 0.5766 - val_accuracy: 0.1447\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5262 - accuracy: 0.1487 - val_loss: 0.5168 - val_accuracy: 0.1132\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5217 - accuracy: 0.1580 - val_loss: 0.5234 - val_accuracy: 0.1459\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5193 - accuracy: 0.1562 - val_loss: 0.5281 - val_accuracy: 0.1592\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5231 - accuracy: 0.1535 - val_loss: 0.5247 - val_accuracy: 0.1513\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5240 - accuracy: 0.1550 - val_loss: 0.5186 - val_accuracy: 0.1408\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5172 - accuracy: 0.1592 - val_loss: 0.5197 - val_accuracy: 0.1834\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5192 - accuracy: 0.1593 - val_loss: 0.5162 - val_accuracy: 0.1675\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5167 - accuracy: 0.1580 - val_loss: 0.5194 - val_accuracy: 0.1721\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5153 - accuracy: 0.1583 - val_loss: 0.5186 - val_accuracy: 0.1766\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5140 - accuracy: 0.1602 - val_loss: 0.5235 - val_accuracy: 0.1901\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.5235 - accuracy: 0.1901\n",
            "sklearn_accuracy: 0.103625\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 1, 2, 2, 5, 2, 1, 3, 4, 3, 2, 2, 14, 4, 4, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 14, 0.1]\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_96 (Conv2D)          (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_96 (MaxPoolin  (None, 44, 128, 4)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 44, 128, 4)       16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 44, 128, 2)        82        \n",
            "                                                                 \n",
            " max_pooling2d_97 (MaxPoolin  (None, 22, 128, 2)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 22, 128, 2)       8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_39 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 15)                84495     \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,825\n",
            "Trainable params: 84,813\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.3531 - accuracy: 0.3244 - val_loss: 0.2370 - val_accuracy: 0.3321\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1906 - accuracy: 0.3062 - val_loss: 0.3067 - val_accuracy: 0.3147\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1545 - accuracy: 0.2898 - val_loss: 0.2481 - val_accuracy: 0.2652\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1388 - accuracy: 0.2859 - val_loss: 0.2600 - val_accuracy: 0.2672\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1261 - accuracy: 0.2772 - val_loss: 0.2885 - val_accuracy: 0.2252\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1195 - accuracy: 0.2734 - val_loss: 0.3064 - val_accuracy: 0.2534\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1148 - accuracy: 0.2683 - val_loss: 0.3040 - val_accuracy: 0.2469\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1098 - accuracy: 0.2732 - val_loss: 0.3319 - val_accuracy: 0.2278\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1043 - accuracy: 0.2738 - val_loss: 0.3156 - val_accuracy: 0.2346\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1023 - accuracy: 0.2746 - val_loss: 0.3171 - val_accuracy: 0.2735\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1001 - accuracy: 0.2747 - val_loss: 0.3236 - val_accuracy: 0.2387\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.0963 - accuracy: 0.2740 - val_loss: 0.3310 - val_accuracy: 0.2444\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.0934 - accuracy: 0.2706 - val_loss: 0.5470 - val_accuracy: 0.2183\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.0933 - accuracy: 0.2705 - val_loss: 0.4360 - val_accuracy: 0.2434\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.0911 - accuracy: 0.2735 - val_loss: 0.4382 - val_accuracy: 0.2389\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4382 - accuracy: 0.2389\n",
            "sklearn_accuracy: 0.6338125\n",
            "\n",
            "(main) 5' population has been evaluated\n",
            "best individual: [[2, 4, 5, 7, 2, 1, 2, 2, 5, 2, 1, 3, 4, 3, 2, 2, 14, 4, 4, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 14, 0.1]]\n",
            "statistics: {'min': 0.03125, 'max': 0.6338125, 'average': 0.247015625}\n",
            "(main) 6' population initialized\n",
            "[2, 4, 5, 7, 2, 1, 2, 2, 5, 2, 1, 3, 4, 3, 2, 2, 14, 4, 4, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 14, 0.1]\n",
            "[2, 10, 5, 3, 1, 2, 2, 2, 5, 1, 1, 3, 4, 7, 1, 2, 18, 4, 3, 1, 1, 11, 4, 3, 2, 1, 3, 9, 0.04, 8, 0.37, 11, 0.11]\n",
            "[3, 6, 5, 7, 1, 1, 2, 2, 5, 2, 2, 3, 4, 3, 2, 2, 17, 4, 4, 2, 1, 6, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "[2, 8, 5, 7, 2, 1, 2, 3, 5, 2, 1, 12, 4, 4, 2, 2, 14, 4, 7, 2, 1, 6, 7, 2, 1, 1, 2, 12, 0.26, 6, 0.23, 11, 0.06]\n",
            "[2, 4, 5, 7, 2, 2, 2, 2, 5, 2, 1, 3, 4, 2, 1, 2, 14, 4, 6, 2, 1, 6, 7, 2, 1, 1, 1, 15, 0.18, 12, 0.14, 14, 0.16]\n",
            "[2, 4, 5, 6, 2, 1, 2, 2, 5, 2, 1, 3, 4, 3, 1, 2, 14, 4, 6, 2, 2, 6, 5, 6, 1, 1, 1, 12, 0.18, 6, 0.14, 8, 0.06]\n",
            "[2, 4, 5, 7, 2, 1, 7, 5, 5, 2, 2, 9, 4, 6, 2, 1, 7, 7, 5, 1, 2, 7, 5, 7, 2, 2, 2, 5, 0.12, 9, 0.28, 9, 0.46]\n",
            "[2, 9, 5, 7, 1, 1, 5, 2, 5, 2, 2, 3, 4, 3, 2, 1, 18, 4, 4, 2, 1, 6, 4, 7, 2, 1, 3, 9, 0.01, 8, 0.37, 11, 0.11]\n",
            "\n",
            " - GENERATION 6\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 1, 2, 2, 5, 2, 1, 3, 4, 3, 2, 2, 14, 4, 4, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 14, 0.1]\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_98 (Conv2D)          (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_98 (MaxPoolin  (None, 44, 128, 4)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 44, 128, 4)       16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 44, 128, 2)        82        \n",
            "                                                                 \n",
            " max_pooling2d_99 (MaxPoolin  (None, 22, 128, 2)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 22, 128, 2)       8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_40 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 15)                84495     \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,825\n",
            "Trainable params: 84,813\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.6192 - accuracy: 0.1628 - val_loss: 0.5244 - val_accuracy: 0.2293\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5158 - accuracy: 0.1787 - val_loss: 0.4001 - val_accuracy: 0.2004\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4241 - accuracy: 0.2010 - val_loss: 0.3585 - val_accuracy: 0.2490\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4000 - accuracy: 0.1936 - val_loss: 0.3463 - val_accuracy: 0.2350\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3708 - accuracy: 0.2158 - val_loss: 0.2822 - val_accuracy: 0.2945\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3224 - accuracy: 0.2544 - val_loss: 0.2710 - val_accuracy: 0.2976\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3031 - accuracy: 0.2739 - val_loss: 0.2515 - val_accuracy: 0.3781\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2705 - accuracy: 0.3308 - val_loss: 0.2342 - val_accuracy: 0.3682\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2541 - accuracy: 0.3238 - val_loss: 0.2286 - val_accuracy: 0.3338\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2455 - accuracy: 0.2690 - val_loss: 0.2454 - val_accuracy: 0.2581\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2398 - accuracy: 0.2201 - val_loss: 0.2376 - val_accuracy: 0.2312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2370 - accuracy: 0.2191 - val_loss: 0.2649 - val_accuracy: 0.2217\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2365 - accuracy: 0.2204 - val_loss: 0.2472 - val_accuracy: 0.2133\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2316 - accuracy: 0.2226 - val_loss: 0.2702 - val_accuracy: 0.2161\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2292 - accuracy: 0.2225 - val_loss: 0.2776 - val_accuracy: 0.2303\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.2303\n",
            "sklearn_accuracy: 0.6559375\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 10, 5, 3, 1, 2, 2, 2, 5, 1, 1, 3, 4, 7, 1, 2, 18, 4, 3, 1, 1, 11, 4, 3, 2, 1, 3, 9, 0.04, 8, 0.37, 11, 0.11]\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_100 (Conv2D)         (None, 87, 128, 10)       160       \n",
            "                                                                 \n",
            " max_pooling2d_100 (MaxPooli  (None, 87, 64, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 87, 64, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 87, 64, 2)         202       \n",
            "                                                                 \n",
            " max_pooling2d_101 (MaxPooli  (None, 87, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 87, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_41 (Flatten)        (None, 11136)             0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 9)                 100233    \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 8)                 80        \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 11)                99        \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 11)                0         \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 5)                 60        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100,882\n",
            "Trainable params: 100,858\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.6334 - accuracy: 0.1512 - val_loss: 0.5823 - val_accuracy: 0.1550\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5835 - accuracy: 0.1450 - val_loss: 0.5639 - val_accuracy: 0.2017\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.5707 - accuracy: 0.1424 - val_loss: 0.5636 - val_accuracy: 0.1880\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5644 - accuracy: 0.1421 - val_loss: 0.5561 - val_accuracy: 0.0941\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5562 - accuracy: 0.1371 - val_loss: 0.5721 - val_accuracy: 0.0830\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5470 - accuracy: 0.1352 - val_loss: 0.5397 - val_accuracy: 0.1305\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5370 - accuracy: 0.1307 - val_loss: 0.5530 - val_accuracy: 0.1144\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5286 - accuracy: 0.1381 - val_loss: 0.5491 - val_accuracy: 0.1311\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5207 - accuracy: 0.1551 - val_loss: 0.5813 - val_accuracy: 0.1199\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5136 - accuracy: 0.1683 - val_loss: 0.5109 - val_accuracy: 0.2114\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.5055 - accuracy: 0.1770 - val_loss: 0.5066 - val_accuracy: 0.1851\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.4976 - accuracy: 0.1832 - val_loss: 0.4948 - val_accuracy: 0.1975\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.4931 - accuracy: 0.1881 - val_loss: 0.5038 - val_accuracy: 0.1842\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.4908 - accuracy: 0.1900 - val_loss: 0.5005 - val_accuracy: 0.1956\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.4879 - accuracy: 0.1915 - val_loss: 0.5263 - val_accuracy: 0.1808\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.5263 - accuracy: 0.1808\n",
            "sklearn_accuracy: 0.1033125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 5, 7, 1, 1, 2, 2, 5, 2, 2, 3, 4, 3, 2, 2, 17, 4, 4, 2, 1, 6, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_102 (Conv2D)         (None, 87, 128, 6)        216       \n",
            "                                                                 \n",
            " max_pooling2d_102 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 87, 128, 2)        122       \n",
            "                                                                 \n",
            " max_pooling2d_103 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 44, 64, 3)         75        \n",
            "                                                                 \n",
            " max_pooling2d_104 (MaxPooli  (None, 22, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_104 (Ba  (None, 22, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_42 (Flatten)        (None, 2112)              0         \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 15)                31695     \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,232\n",
            "Trainable params: 32,210\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 16s 20ms/step - loss: 0.4686 - accuracy: 0.2742 - val_loss: 0.2995 - val_accuracy: 0.3718\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.2598 - accuracy: 0.3483 - val_loss: 0.2931 - val_accuracy: 0.3413\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.2074 - accuracy: 0.3336 - val_loss: 0.2248 - val_accuracy: 0.3643\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1810 - accuracy: 0.3154 - val_loss: 0.2159 - val_accuracy: 0.3041\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1656 - accuracy: 0.3058 - val_loss: 0.2425 - val_accuracy: 0.2764\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1555 - accuracy: 0.2946 - val_loss: 0.2386 - val_accuracy: 0.2821\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1462 - accuracy: 0.2823 - val_loss: 0.2438 - val_accuracy: 0.2476\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1366 - accuracy: 0.2700 - val_loss: 0.2422 - val_accuracy: 0.2512\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1298 - accuracy: 0.2619 - val_loss: 0.2571 - val_accuracy: 0.2457\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1253 - accuracy: 0.2570 - val_loss: 0.2551 - val_accuracy: 0.2373\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1186 - accuracy: 0.2534 - val_loss: 0.3276 - val_accuracy: 0.2177\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1139 - accuracy: 0.2535 - val_loss: 0.2644 - val_accuracy: 0.2302\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1086 - accuracy: 0.2515 - val_loss: 0.2962 - val_accuracy: 0.2273\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1059 - accuracy: 0.2516 - val_loss: 0.2686 - val_accuracy: 0.2457\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1047 - accuracy: 0.2498 - val_loss: 0.2907 - val_accuracy: 0.2251\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2907 - accuracy: 0.2251\n",
            "sklearn_accuracy: 0.657125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 8, 5, 7, 2, 1, 2, 3, 5, 2, 1, 12, 4, 4, 2, 2, 14, 4, 7, 2, 1, 6, 7, 2, 1, 1, 2, 12, 0.26, 6, 0.23, 11, 0.06]\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_105 (Conv2D)         (None, 87, 128, 8)        288       \n",
            "                                                                 \n",
            " max_pooling2d_105 (MaxPooli  (None, 44, 128, 8)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_105 (Ba  (None, 44, 128, 8)       32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 44, 128, 2)        242       \n",
            "                                                                 \n",
            " max_pooling2d_106 (MaxPooli  (None, 22, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_106 (Ba  (None, 22, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_43 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 12)                67596     \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 12)                0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 6)                 78        \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 5)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,279\n",
            "Trainable params: 68,259\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6254 - accuracy: 0.1756 - val_loss: 0.5458 - val_accuracy: 0.1667\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5737 - accuracy: 0.1726 - val_loss: 0.4939 - val_accuracy: 0.2021\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5440 - accuracy: 0.1843 - val_loss: 0.4702 - val_accuracy: 0.2422\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5324 - accuracy: 0.1711 - val_loss: 0.4651 - val_accuracy: 0.2191\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5254 - accuracy: 0.1652 - val_loss: 0.4607 - val_accuracy: 0.1887\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5237 - accuracy: 0.1581 - val_loss: 0.4799 - val_accuracy: 0.1813\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5213 - accuracy: 0.1581 - val_loss: 0.4516 - val_accuracy: 0.1892\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5185 - accuracy: 0.1584 - val_loss: 0.4543 - val_accuracy: 0.1810\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5089 - accuracy: 0.1647 - val_loss: 0.4531 - val_accuracy: 0.1863\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5066 - accuracy: 0.1676 - val_loss: 0.4734 - val_accuracy: 0.1815\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5047 - accuracy: 0.1653 - val_loss: 0.4590 - val_accuracy: 0.1793\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5048 - accuracy: 0.1673 - val_loss: 0.4478 - val_accuracy: 0.1844\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5003 - accuracy: 0.1707 - val_loss: 0.4397 - val_accuracy: 0.1811\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.4949 - accuracy: 0.1717 - val_loss: 0.4620 - val_accuracy: 0.1859\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.4943 - accuracy: 0.1723 - val_loss: 0.4415 - val_accuracy: 0.1847\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4415 - accuracy: 0.1847\n",
            "sklearn_accuracy: 0.1826875\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 2, 2, 2, 5, 2, 1, 3, 4, 2, 1, 2, 14, 4, 6, 2, 1, 6, 7, 2, 1, 1, 1, 15, 0.18, 12, 0.14, 14, 0.16]\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_107 (Conv2D)         (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_107 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_107 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 44, 64, 2)         82        \n",
            "                                                                 \n",
            " max_pooling2d_108 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_108 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_44 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 15)                42255     \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,585\n",
            "Trainable params: 42,573\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4647 - accuracy: 0.2049 - val_loss: 0.3213 - val_accuracy: 0.2531\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2815 - accuracy: 0.2987 - val_loss: 0.3365 - val_accuracy: 0.2854\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2216 - accuracy: 0.3294 - val_loss: 0.2239 - val_accuracy: 0.3117\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2013 - accuracy: 0.3441 - val_loss: 0.3796 - val_accuracy: 0.3241\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1900 - accuracy: 0.3619 - val_loss: 0.2684 - val_accuracy: 0.3157\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1798 - accuracy: 0.3726 - val_loss: 0.4168 - val_accuracy: 0.3780\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1744 - accuracy: 0.3879 - val_loss: 0.6145 - val_accuracy: 0.3248\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1716 - accuracy: 0.4032 - val_loss: 0.2498 - val_accuracy: 0.3590\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1660 - accuracy: 0.4149 - val_loss: 0.2859 - val_accuracy: 0.3803\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1635 - accuracy: 0.4302 - val_loss: 0.2456 - val_accuracy: 0.4297\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1580 - accuracy: 0.4462 - val_loss: 0.4685 - val_accuracy: 0.4427\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1543 - accuracy: 0.4521 - val_loss: 0.3145 - val_accuracy: 0.4152\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1497 - accuracy: 0.4476 - val_loss: 0.3698 - val_accuracy: 0.3751\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1438 - accuracy: 0.4360 - val_loss: 0.4025 - val_accuracy: 0.4226\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1419 - accuracy: 0.4306 - val_loss: 0.4349 - val_accuracy: 0.3696\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.3696\n",
            "sklearn_accuracy: 0.5989375\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 6, 2, 1, 2, 2, 5, 2, 1, 3, 4, 3, 1, 2, 14, 4, 6, 2, 2, 6, 5, 6, 1, 1, 1, 12, 0.18, 6, 0.14, 8, 0.06]\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_109 (Conv2D)         (None, 87, 128, 4)        124       \n",
            "                                                                 \n",
            " max_pooling2d_109 (MaxPooli  (None, 44, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_109 (Ba  (None, 44, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 44, 128, 2)        82        \n",
            "                                                                 \n",
            " max_pooling2d_110 (MaxPooli  (None, 22, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_110 (Ba  (None, 22, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_45 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 12)                67596     \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 12)                0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 5)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,891\n",
            "Trainable params: 67,879\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.5160 - accuracy: 0.4373 - val_loss: 0.4325 - val_accuracy: 0.4374\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3515 - accuracy: 0.5014 - val_loss: 0.3701 - val_accuracy: 0.4054\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2995 - accuracy: 0.5095 - val_loss: 0.3670 - val_accuracy: 0.4649\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2813 - accuracy: 0.5153 - val_loss: 0.4207 - val_accuracy: 0.5639\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2719 - accuracy: 0.5142 - val_loss: 0.3876 - val_accuracy: 0.5339\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2653 - accuracy: 0.5223 - val_loss: 0.4363 - val_accuracy: 0.3454\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2618 - accuracy: 0.5246 - val_loss: 0.4123 - val_accuracy: 0.5294\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2579 - accuracy: 0.5245 - val_loss: 0.4610 - val_accuracy: 0.4270\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2543 - accuracy: 0.5235 - val_loss: 0.4550 - val_accuracy: 0.4757\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2509 - accuracy: 0.5270 - val_loss: 0.5042 - val_accuracy: 0.5346\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2499 - accuracy: 0.5254 - val_loss: 0.4244 - val_accuracy: 0.5387\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2453 - accuracy: 0.5262 - val_loss: 0.4691 - val_accuracy: 0.5546\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2438 - accuracy: 0.5293 - val_loss: 0.4582 - val_accuracy: 0.5446\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2423 - accuracy: 0.5308 - val_loss: 0.4096 - val_accuracy: 0.4972\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.2410 - accuracy: 0.5363 - val_loss: 0.4728 - val_accuracy: 0.5309\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4728 - accuracy: 0.5309\n",
            "sklearn_accuracy: 0.533875\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 1, 7, 5, 5, 2, 2, 9, 4, 6, 2, 1, 7, 7, 5, 1, 2, 7, 5, 7, 2, 2, 2, 5, 0.12, 9, 0.28, 9, 0.46]\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_111 (Conv2D)         (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_111 (MaxPooli  (None, 44, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_111 (Ba  (None, 44, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_112 (Conv2D)         (None, 44, 128, 7)        707       \n",
            "                                                                 \n",
            " max_pooling2d_112 (MaxPooli  (None, 22, 64, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_112 (Ba  (None, 22, 64, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_46 (Flatten)        (None, 9856)              0         \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 5)                 49285     \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 9)                 54        \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 5)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,284\n",
            "Trainable params: 50,262\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 9s 11ms/step - loss: 0.6934 - accuracy: 0.1323 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.1135 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.2166 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.2002 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.2248 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.1922 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.1515 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.3474 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.1162 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.6932 - accuracy: 0.0987 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.1842 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.2452 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.2430 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.1547 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.6932 - accuracy: 0.2453 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 9, 5, 7, 1, 1, 5, 2, 5, 2, 2, 3, 4, 3, 2, 1, 18, 4, 4, 2, 1, 6, 4, 7, 2, 1, 3, 9, 0.01, 8, 0.37, 11, 0.11]\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_113 (Conv2D)         (None, 87, 128, 9)        324       \n",
            "                                                                 \n",
            " max_pooling2d_113 (MaxPooli  (None, 87, 128, 9)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_113 (Ba  (None, 87, 128, 9)       36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_114 (Conv2D)         (None, 87, 128, 5)        455       \n",
            "                                                                 \n",
            " max_pooling2d_114 (MaxPooli  (None, 44, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_114 (Ba  (None, 44, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_47 (Flatten)        (None, 14080)             0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 9)                 126729    \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 8)                 80        \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 11)                99        \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 11)                0         \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 5)                 60        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,803\n",
            "Trainable params: 127,775\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.6940 - accuracy: 0.2125 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1654 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2404 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1649 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1938 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1520 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2587 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1663 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2461 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1286 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1655 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1792 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.3234 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1911 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.0629 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(main) 6' population has been evaluated\n",
            "best individual: [[3, 6, 5, 7, 1, 1, 2, 2, 5, 2, 2, 3, 4, 3, 2, 2, 17, 4, 4, 2, 1, 6, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]]\n",
            "statistics: {'min': 0.03125, 'max': 0.657125, 'average': 0.349296875}\n",
            "(main) 7' population initialized\n",
            "[3, 6, 5, 7, 1, 1, 2, 2, 5, 2, 2, 3, 4, 3, 2, 2, 17, 4, 4, 2, 1, 6, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "[2, 4, 5, 7, 2, 2, 2, 2, 5, 2, 1, 9, 4, 2, 1, 2, 14, 3, 6, 2, 1, 9, 5, 6, 1, 2, 3, 12, 0.18, 6, 0.14, 8, 0.06]\n",
            "[2, 4, 5, 7, 2, 1, 2, 6, 5, 2, 2, 3, 4, 7, 2, 2, 14, 4, 4, 2, 2, 6, 5, 2, 1, 1, 1, 15, 0.18, 7, 0.14, 15, 0.11]\n",
            "[2, 10, 5, 6, 2, 1, 6, 2, 5, 1, 1, 3, 2, 3, 1, 2, 14, 6, 4, 1, 2, 6, 4, 2, 1, 1, 3, 16, 0.19, 6, 0.14, 17, 0.11]\n",
            "[3, 4, 3, 7, 2, 1, 4, 2, 5, 2, 1, 8, 4, 3, 1, 2, 14, 4, 4, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 9, 0.14, 14, 0.1]\n",
            "[2, 11, 5, 5, 1, 1, 2, 2, 5, 2, 2, 5, 4, 3, 1, 2, 17, 4, 6, 2, 1, 6, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 11, 0.2]\n",
            "[2, 17, 5, 5, 1, 1, 2, 3, 5, 2, 2, 5, 4, 3, 1, 2, 14, 4, 3, 2, 1, 6, 5, 3, 1, 1, 1, 15, 0.18, 9, 0.17, 14, 0.1]\n",
            "[2, 4, 2, 7, 2, 2, 2, 2, 4, 2, 1, 8, 7, 2, 1, 2, 14, 2, 3, 2, 1, 6, 2, 2, 1, 1, 3, 18, 0.18, 9, 0.14, 14, 0.1]\n",
            "\n",
            " - GENERATION 7\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 5, 7, 1, 1, 2, 2, 5, 2, 2, 3, 4, 3, 2, 2, 17, 4, 4, 2, 1, 6, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_115 (Conv2D)         (None, 87, 128, 6)        216       \n",
            "                                                                 \n",
            " max_pooling2d_115 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_115 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_116 (Conv2D)         (None, 87, 128, 2)        122       \n",
            "                                                                 \n",
            " max_pooling2d_116 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_116 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_117 (Conv2D)         (None, 44, 64, 3)         75        \n",
            "                                                                 \n",
            " max_pooling2d_117 (MaxPooli  (None, 22, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_117 (Ba  (None, 22, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_48 (Flatten)        (None, 2112)              0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 15)                31695     \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,232\n",
            "Trainable params: 32,210\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 16s 20ms/step - loss: 0.4789 - accuracy: 0.2626 - val_loss: 0.4915 - val_accuracy: 0.2184\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.3201 - accuracy: 0.3975 - val_loss: 0.8953 - val_accuracy: 0.2849\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.2581 - accuracy: 0.4520 - val_loss: 0.4949 - val_accuracy: 0.3645\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.2187 - accuracy: 0.4932 - val_loss: 0.2881 - val_accuracy: 0.5387\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1959 - accuracy: 0.5025 - val_loss: 0.2399 - val_accuracy: 0.4781\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1792 - accuracy: 0.5167 - val_loss: 0.4902 - val_accuracy: 0.3742\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1671 - accuracy: 0.5157 - val_loss: 0.2442 - val_accuracy: 0.4741\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1586 - accuracy: 0.5241 - val_loss: 0.2442 - val_accuracy: 0.5477\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1524 - accuracy: 0.5192 - val_loss: 0.2683 - val_accuracy: 0.5118\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1480 - accuracy: 0.5207 - val_loss: 0.2824 - val_accuracy: 0.5309\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.1445 - accuracy: 0.5227 - val_loss: 0.4565 - val_accuracy: 0.5922\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1392 - accuracy: 0.5287 - val_loss: 0.2587 - val_accuracy: 0.4846\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1372 - accuracy: 0.5290 - val_loss: 0.3678 - val_accuracy: 0.5296\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1370 - accuracy: 0.5265 - val_loss: 0.4732 - val_accuracy: 0.3231\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1343 - accuracy: 0.5219 - val_loss: 0.3285 - val_accuracy: 0.5602\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.5602\n",
            "sklearn_accuracy: 0.652125\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 2, 2, 2, 5, 2, 1, 9, 4, 2, 1, 2, 14, 3, 6, 2, 1, 9, 5, 6, 1, 2, 3, 12, 0.18, 6, 0.14, 8, 0.06]\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_118 (Conv2D)         (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_118 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_118 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_119 (Conv2D)         (None, 44, 64, 2)         82        \n",
            "                                                                 \n",
            " max_pooling2d_119 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_119 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_49 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 12)                33804     \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 12)                0         \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 6)                 78        \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 8)                 56        \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 5)                 45        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,233\n",
            "Trainable params: 34,221\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.6097 - accuracy: 0.2447 - val_loss: 0.5617 - val_accuracy: 0.3159\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.5412 - accuracy: 0.2963 - val_loss: 0.5425 - val_accuracy: 0.3069\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.5247 - accuracy: 0.2946 - val_loss: 0.5061 - val_accuracy: 0.3182\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.5156 - accuracy: 0.3106 - val_loss: 0.4955 - val_accuracy: 0.3221\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4980 - accuracy: 0.3233 - val_loss: 0.5415 - val_accuracy: 0.3039\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4883 - accuracy: 0.3240 - val_loss: 0.4844 - val_accuracy: 0.3131\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4795 - accuracy: 0.3319 - val_loss: 0.4840 - val_accuracy: 0.2842\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4766 - accuracy: 0.3420 - val_loss: 0.4751 - val_accuracy: 0.3136\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4741 - accuracy: 0.3394 - val_loss: 0.4764 - val_accuracy: 0.3014\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4707 - accuracy: 0.3440 - val_loss: 0.4696 - val_accuracy: 0.3436\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4681 - accuracy: 0.3660 - val_loss: 0.4767 - val_accuracy: 0.3906\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4672 - accuracy: 0.3628 - val_loss: 0.5559 - val_accuracy: 0.4024\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4659 - accuracy: 0.3670 - val_loss: 0.5095 - val_accuracy: 0.4042\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4649 - accuracy: 0.3701 - val_loss: 0.5775 - val_accuracy: 0.4009\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.4645 - accuracy: 0.3718 - val_loss: 0.4715 - val_accuracy: 0.3794\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4715 - accuracy: 0.3794\n",
            "sklearn_accuracy: 0.1943125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 5, 7, 2, 1, 2, 6, 5, 2, 2, 3, 4, 7, 2, 2, 14, 4, 4, 2, 2, 6, 5, 2, 1, 1, 1, 15, 0.18, 7, 0.14, 15, 0.11]\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_120 (Conv2D)         (None, 87, 128, 4)        144       \n",
            "                                                                 \n",
            " max_pooling2d_120 (MaxPooli  (None, 44, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_120 (Ba  (None, 44, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_121 (Conv2D)         (None, 44, 128, 2)        242       \n",
            "                                                                 \n",
            " max_pooling2d_121 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_121 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_50 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 15)                42255     \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,745\n",
            "Trainable params: 42,733\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.5446 - accuracy: 0.2480 - val_loss: 0.3549 - val_accuracy: 0.2835\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.2980 - accuracy: 0.3213 - val_loss: 0.2677 - val_accuracy: 0.2520\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.2110 - accuracy: 0.3211 - val_loss: 0.2398 - val_accuracy: 0.2962\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1685 - accuracy: 0.3243 - val_loss: 0.2675 - val_accuracy: 0.3045\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1492 - accuracy: 0.3255 - val_loss: 0.2872 - val_accuracy: 0.3164\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1342 - accuracy: 0.3304 - val_loss: 0.2646 - val_accuracy: 0.3470\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1226 - accuracy: 0.3337 - val_loss: 0.3056 - val_accuracy: 0.3090\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1128 - accuracy: 0.3358 - val_loss: 0.3667 - val_accuracy: 0.3401\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1099 - accuracy: 0.3308 - val_loss: 0.4274 - val_accuracy: 0.3230\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.1050 - accuracy: 0.3383 - val_loss: 0.4378 - val_accuracy: 0.3817\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0999 - accuracy: 0.3342 - val_loss: 0.3913 - val_accuracy: 0.3514\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0983 - accuracy: 0.3376 - val_loss: 0.4017 - val_accuracy: 0.3438\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0960 - accuracy: 0.3387 - val_loss: 0.3990 - val_accuracy: 0.3532\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0931 - accuracy: 0.3376 - val_loss: 0.3867 - val_accuracy: 0.3488\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0911 - accuracy: 0.3363 - val_loss: 0.4420 - val_accuracy: 0.3492\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4420 - accuracy: 0.3492\n",
            "sklearn_accuracy: 0.6245\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 10, 5, 6, 2, 1, 6, 2, 5, 1, 1, 3, 2, 3, 1, 2, 14, 6, 4, 1, 2, 6, 4, 2, 1, 1, 3, 16, 0.19, 6, 0.14, 17, 0.11]\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_122 (Conv2D)         (None, 87, 128, 10)       310       \n",
            "                                                                 \n",
            " max_pooling2d_122 (MaxPooli  (None, 44, 128, 10)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_122 (Ba  (None, 44, 128, 10)      40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_123 (Conv2D)         (None, 44, 128, 6)        606       \n",
            "                                                                 \n",
            " max_pooling2d_123 (MaxPooli  (None, 44, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_123 (Ba  (None, 44, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_51 (Flatten)        (None, 33792)             0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 16)                540688    \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 6)                 102       \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 17)                119       \n",
            "                                                                 \n",
            " dropout_100 (Dropout)       (None, 17)                0         \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 5)                 90        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541,979\n",
            "Trainable params: 541,947\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6426 - accuracy: 0.1125 - val_loss: 0.6006 - val_accuracy: 0.2501\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.6107 - accuracy: 0.1178 - val_loss: 0.5746 - val_accuracy: 0.2407\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.6011 - accuracy: 0.1544 - val_loss: 0.5663 - val_accuracy: 0.2991\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.5921 - accuracy: 0.1841 - val_loss: 0.5822 - val_accuracy: 0.2308\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.5598 - accuracy: 0.2231 - val_loss: 0.5457 - val_accuracy: 0.2785\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.5505 - accuracy: 0.2517 - val_loss: 0.5486 - val_accuracy: 0.3037\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.5450 - accuracy: 0.2688 - val_loss: 0.5747 - val_accuracy: 0.2857\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.5307 - accuracy: 0.2829 - val_loss: 0.5251 - val_accuracy: 0.3236\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.5119 - accuracy: 0.2846 - val_loss: 0.5193 - val_accuracy: 0.3309\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.4932 - accuracy: 0.3104 - val_loss: 0.4839 - val_accuracy: 0.3326\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.4814 - accuracy: 0.3231 - val_loss: 0.4905 - val_accuracy: 0.3435\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.4776 - accuracy: 0.3246 - val_loss: 0.4845 - val_accuracy: 0.3501\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.4734 - accuracy: 0.3266 - val_loss: 0.4620 - val_accuracy: 0.3719\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.4709 - accuracy: 0.3272 - val_loss: 0.4560 - val_accuracy: 0.3639\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.4669 - accuracy: 0.3290 - val_loss: 0.4764 - val_accuracy: 0.3440\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4764 - accuracy: 0.3440\n",
            "sklearn_accuracy: 0.1783125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 4, 3, 7, 2, 1, 4, 2, 5, 2, 1, 8, 4, 3, 1, 2, 14, 4, 4, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 9, 0.14, 14, 0.1]\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_124 (Conv2D)         (None, 87, 128, 4)        88        \n",
            "                                                                 \n",
            " max_pooling2d_124 (MaxPooli  (None, 44, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_124 (Ba  (None, 44, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_125 (Conv2D)         (None, 44, 128, 4)        164       \n",
            "                                                                 \n",
            " max_pooling2d_125 (MaxPooli  (None, 22, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_125 (Ba  (None, 22, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_126 (Conv2D)         (None, 22, 128, 8)        392       \n",
            "                                                                 \n",
            " max_pooling2d_126 (MaxPooli  (None, 22, 64, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_126 (Ba  (None, 22, 64, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_52 (Flatten)        (None, 11264)             0         \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 15)                168975    \n",
            "                                                                 \n",
            " dropout_101 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,763\n",
            "Trainable params: 169,731\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 13s 16ms/step - loss: 0.6938 - accuracy: 0.1866 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.1354 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.2180 - val_loss: 0.6932 - val_accuracy: 0.5313\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.3189 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.2374 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.1739 - val_loss: 0.6932 - val_accuracy: 0.5313\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.2850 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.1706 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.0605 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.2101 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.1630 - val_loss: 0.6931 - val_accuracy: 0.5313\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.6932 - accuracy: 0.2004 - val_loss: 0.6931 - val_accuracy: 0.5313\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.6932 - accuracy: 0.1223 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.6932 - accuracy: 0.2734 - val_loss: 0.6932 - val_accuracy: 0.0313\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.6932 - accuracy: 0.1061 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.0313\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 5, 1, 1, 2, 2, 5, 2, 2, 5, 4, 3, 1, 2, 17, 4, 6, 2, 1, 6, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 11, 0.2]\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_127 (Conv2D)         (None, 87, 128, 11)       286       \n",
            "                                                                 \n",
            " max_pooling2d_127 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_127 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_128 (Conv2D)         (None, 87, 128, 2)        222       \n",
            "                                                                 \n",
            " max_pooling2d_128 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_128 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_53 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 21)                118293    \n",
            "                                                                 \n",
            " dropout_102 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,963\n",
            "Trainable params: 118,937\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 17ms/step - loss: 0.2997 - accuracy: 0.4151 - val_loss: 0.2457 - val_accuracy: 0.4886\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.1327 - accuracy: 0.4950 - val_loss: 0.2212 - val_accuracy: 0.4626\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0997 - accuracy: 0.4930 - val_loss: 0.1990 - val_accuracy: 0.4450\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0799 - accuracy: 0.4841 - val_loss: 0.2263 - val_accuracy: 0.4564\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0701 - accuracy: 0.4836 - val_loss: 0.2602 - val_accuracy: 0.3720\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0598 - accuracy: 0.4871 - val_loss: 0.3567 - val_accuracy: 0.4896\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0542 - accuracy: 0.4941 - val_loss: 0.3805 - val_accuracy: 0.5176\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0492 - accuracy: 0.4980 - val_loss: 0.2653 - val_accuracy: 0.4248\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0462 - accuracy: 0.4974 - val_loss: 0.5700 - val_accuracy: 0.5012\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0457 - accuracy: 0.5044 - val_loss: 0.2973 - val_accuracy: 0.4277\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0430 - accuracy: 0.5097 - val_loss: 0.3891 - val_accuracy: 0.4543\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0414 - accuracy: 0.5155 - val_loss: 0.3776 - val_accuracy: 0.4706\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0400 - accuracy: 0.5158 - val_loss: 0.3902 - val_accuracy: 0.4662\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0389 - accuracy: 0.5149 - val_loss: 0.4125 - val_accuracy: 0.4695\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0369 - accuracy: 0.5089 - val_loss: 0.3975 - val_accuracy: 0.4843\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3975 - accuracy: 0.4843\n",
            "sklearn_accuracy: 0.735\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 17, 5, 5, 1, 1, 2, 3, 5, 2, 2, 5, 4, 3, 1, 2, 14, 4, 3, 2, 1, 6, 5, 3, 1, 1, 1, 15, 0.18, 9, 0.17, 14, 0.1]\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_129 (Conv2D)         (None, 87, 128, 17)       442       \n",
            "                                                                 \n",
            " max_pooling2d_129 (MaxPooli  (None, 87, 128, 17)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_129 (Ba  (None, 87, 128, 17)      68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_130 (Conv2D)         (None, 87, 128, 2)        512       \n",
            "                                                                 \n",
            " max_pooling2d_130 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_130 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_54 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 15)                84495     \n",
            "                                                                 \n",
            " dropout_103 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,605\n",
            "Trainable params: 85,567\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.3906 - accuracy: 0.4237 - val_loss: 0.2796 - val_accuracy: 0.4252\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.2088 - accuracy: 0.5157 - val_loss: 0.2545 - val_accuracy: 0.4334\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.1795 - accuracy: 0.5463 - val_loss: 0.1859 - val_accuracy: 0.5899\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.1523 - accuracy: 0.5972 - val_loss: 0.2235 - val_accuracy: 0.5724\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.1357 - accuracy: 0.6228 - val_loss: 0.6434 - val_accuracy: 0.7002\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.1152 - accuracy: 0.6206 - val_loss: 0.3464 - val_accuracy: 0.6444\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.1069 - accuracy: 0.6229 - val_loss: 0.2660 - val_accuracy: 0.6162\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.1015 - accuracy: 0.6145 - val_loss: 0.4537 - val_accuracy: 0.6194\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0927 - accuracy: 0.6103 - val_loss: 0.4816 - val_accuracy: 0.5817\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0882 - accuracy: 0.6124 - val_loss: 0.6298 - val_accuracy: 0.5266\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0865 - accuracy: 0.6083 - val_loss: 0.2718 - val_accuracy: 0.5579\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0854 - accuracy: 0.6148 - val_loss: 0.2950 - val_accuracy: 0.5541\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0802 - accuracy: 0.6176 - val_loss: 0.4312 - val_accuracy: 0.6272\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0809 - accuracy: 0.6160 - val_loss: 0.4153 - val_accuracy: 0.6116\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.0776 - accuracy: 0.6175 - val_loss: 0.4042 - val_accuracy: 0.6152\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4042 - accuracy: 0.6152\n",
            "sklearn_accuracy: 0.726875\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 4, 2, 7, 2, 2, 2, 2, 4, 2, 1, 8, 7, 2, 1, 2, 14, 2, 3, 2, 1, 6, 2, 2, 1, 1, 3, 18, 0.18, 9, 0.14, 14, 0.1]\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_131 (Conv2D)         (None, 87, 128, 4)        60        \n",
            "                                                                 \n",
            " max_pooling2d_131 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_131 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_132 (Conv2D)         (None, 44, 64, 2)         66        \n",
            "                                                                 \n",
            " max_pooling2d_132 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_132 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_55 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 18)                50706     \n",
            "                                                                 \n",
            " dropout_104 (Dropout)       (None, 18)                0         \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 9)                 171       \n",
            "                                                                 \n",
            " dropout_105 (Dropout)       (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 14)                140       \n",
            "                                                                 \n",
            " dropout_106 (Dropout)       (None, 14)                0         \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 5)                 75        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,242\n",
            "Trainable params: 51,230\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.5706 - accuracy: 0.1926 - val_loss: 0.4914 - val_accuracy: 0.2216\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4627 - accuracy: 0.2553 - val_loss: 0.4474 - val_accuracy: 0.2572\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4056 - accuracy: 0.2674 - val_loss: 0.3981 - val_accuracy: 0.2536\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3727 - accuracy: 0.2728 - val_loss: 0.3835 - val_accuracy: 0.2579\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3575 - accuracy: 0.2755 - val_loss: 0.3654 - val_accuracy: 0.2604\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3446 - accuracy: 0.2846 - val_loss: 0.3664 - val_accuracy: 0.2611\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3365 - accuracy: 0.2948 - val_loss: 0.3542 - val_accuracy: 0.2944\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3283 - accuracy: 0.3149 - val_loss: 0.3686 - val_accuracy: 0.3018\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3197 - accuracy: 0.3284 - val_loss: 0.3491 - val_accuracy: 0.3178\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3173 - accuracy: 0.3321 - val_loss: 0.3522 - val_accuracy: 0.3141\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3119 - accuracy: 0.3372 - val_loss: 0.3492 - val_accuracy: 0.3119\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3078 - accuracy: 0.3370 - val_loss: 0.3527 - val_accuracy: 0.3127\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3034 - accuracy: 0.3338 - val_loss: 0.3666 - val_accuracy: 0.2943\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2963 - accuracy: 0.3196 - val_loss: 0.3558 - val_accuracy: 0.3052\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2940 - accuracy: 0.3135 - val_loss: 0.3649 - val_accuracy: 0.2887\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3649 - accuracy: 0.2887\n",
            "sklearn_accuracy: 0.3156875\n",
            "\n",
            "(main) 7' population has been evaluated\n",
            "best individual: [[2, 11, 5, 5, 1, 1, 2, 2, 5, 2, 2, 5, 4, 3, 1, 2, 17, 4, 6, 2, 1, 6, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 11, 0.2]]\n",
            "statistics: {'min': 0.03125, 'max': 0.735, 'average': 0.4322578125}\n",
            "(main) 8' population initialized\n",
            "[2, 11, 5, 5, 1, 1, 2, 2, 5, 2, 2, 5, 4, 3, 1, 2, 17, 4, 6, 2, 1, 6, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 11, 0.2]\n",
            "[2, 11, 5, 7, 1, 1, 2, 2, 5, 2, 1, 5, 4, 2, 1, 2, 17, 4, 6, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 7, 0.14, 15, 0.11]\n",
            "[2, 11, 5, 5, 1, 1, 4, 2, 5, 2, 2, 5, 3, 3, 1, 2, 21, 4, 3, 2, 2, 12, 3, 3, 1, 2, 2, 15, 0.18, 9, 0.23, 16, 0.1]\n",
            "[2, 6, 7, 7, 1, 1, 2, 5, 5, 2, 2, 3, 4, 3, 1, 2, 17, 4, 4, 2, 1, 12, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "[2, 17, 3, 5, 1, 1, 2, 4, 5, 2, 2, 6, 4, 3, 1, 2, 14, 4, 5, 2, 1, 6, 5, 5, 1, 2, 3, 18, 0.18, 9, 0.14, 20, 0.1]\n",
            "[3, 6, 5, 6, 1, 1, 2, 2, 4, 2, 1, 3, 4, 2, 2, 2, 17, 4, 4, 2, 1, 10, 4, 2, 1, 1, 1, 16, 0.18, 11, 0.14, 11, 0.12]\n",
            "[3, 6, 5, 6, 1, 1, 2, 4, 4, 2, 2, 3, 4, 7, 2, 2, 14, 4, 4, 2, 2, 6, 5, 2, 1, 2, 1, 15, 0.18, 13, 0.14, 15, 0.11]\n",
            "[2, 11, 2, 3, 1, 1, 2, 2, 3, 2, 2, 3, 4, 2, 2, 2, 17, 7, 4, 2, 1, 10, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 12, 0.12]\n",
            "\n",
            " - GENERATION 8\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 5, 1, 1, 2, 2, 5, 2, 2, 5, 4, 3, 1, 2, 17, 4, 6, 2, 1, 6, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 11, 0.2]\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_133 (Conv2D)         (None, 87, 128, 11)       286       \n",
            "                                                                 \n",
            " max_pooling2d_133 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_133 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_134 (Conv2D)         (None, 87, 128, 2)        222       \n",
            "                                                                 \n",
            " max_pooling2d_134 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_134 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_56 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 21)                118293    \n",
            "                                                                 \n",
            " dropout_107 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,963\n",
            "Trainable params: 118,937\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 17ms/step - loss: 0.3705 - accuracy: 0.2990 - val_loss: 0.2553 - val_accuracy: 0.3052\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.1921 - accuracy: 0.3724 - val_loss: 0.2233 - val_accuracy: 0.4115\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.1366 - accuracy: 0.4858 - val_loss: 0.2259 - val_accuracy: 0.4556\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.1107 - accuracy: 0.5297 - val_loss: 0.3518 - val_accuracy: 0.4699\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0930 - accuracy: 0.5335 - val_loss: 0.4936 - val_accuracy: 0.5401\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0833 - accuracy: 0.5325 - val_loss: 0.4228 - val_accuracy: 0.4831\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0754 - accuracy: 0.5433 - val_loss: 0.4248 - val_accuracy: 0.5346\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0701 - accuracy: 0.5508 - val_loss: 0.5337 - val_accuracy: 0.4586\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0622 - accuracy: 0.5416 - val_loss: 0.6365 - val_accuracy: 0.5240\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0570 - accuracy: 0.5460 - val_loss: 0.5522 - val_accuracy: 0.5265\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0528 - accuracy: 0.5511 - val_loss: 0.6449 - val_accuracy: 0.5351\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0511 - accuracy: 0.5435 - val_loss: 0.4816 - val_accuracy: 0.5030\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.0468 - accuracy: 0.5410 - val_loss: 0.5788 - val_accuracy: 0.5298\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0452 - accuracy: 0.5404 - val_loss: 0.8046 - val_accuracy: 0.4614\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0457 - accuracy: 0.5473 - val_loss: 0.9842 - val_accuracy: 0.5054\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.9842 - accuracy: 0.5054\n",
            "sklearn_accuracy: 0.53925\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 7, 1, 1, 2, 2, 5, 2, 1, 5, 4, 2, 1, 2, 17, 4, 6, 2, 1, 6, 5, 2, 1, 1, 1, 15, 0.18, 7, 0.14, 15, 0.11]\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_135 (Conv2D)         (None, 87, 128, 11)       396       \n",
            "                                                                 \n",
            " max_pooling2d_135 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_135 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_136 (Conv2D)         (None, 87, 128, 2)        222       \n",
            "                                                                 \n",
            " max_pooling2d_136 (MaxPooli  (None, 44, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_136 (Ba  (None, 44, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_57 (Flatten)        (None, 11264)             0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 15)                168975    \n",
            "                                                                 \n",
            " dropout_108 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,725\n",
            "Trainable params: 169,699\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.4886 - accuracy: 0.2303 - val_loss: 0.3082 - val_accuracy: 0.2706\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3476 - accuracy: 0.2571 - val_loss: 0.2833 - val_accuracy: 0.2793\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3291 - accuracy: 0.2707 - val_loss: 0.2816 - val_accuracy: 0.3009\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3217 - accuracy: 0.2858 - val_loss: 0.3225 - val_accuracy: 0.3195\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3112 - accuracy: 0.3066 - val_loss: 0.2717 - val_accuracy: 0.2961\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3047 - accuracy: 0.3276 - val_loss: 0.2836 - val_accuracy: 0.3054\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2972 - accuracy: 0.3412 - val_loss: 0.2836 - val_accuracy: 0.3161\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2891 - accuracy: 0.3493 - val_loss: 0.2754 - val_accuracy: 0.3332\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2862 - accuracy: 0.3570 - val_loss: 0.2847 - val_accuracy: 0.3174\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2827 - accuracy: 0.3622 - val_loss: 0.3595 - val_accuracy: 0.3446\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2783 - accuracy: 0.3636 - val_loss: 0.3305 - val_accuracy: 0.3531\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2717 - accuracy: 0.3661 - val_loss: 0.2995 - val_accuracy: 0.3395\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2704 - accuracy: 0.3736 - val_loss: 0.3238 - val_accuracy: 0.3739\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2695 - accuracy: 0.3750 - val_loss: 0.3039 - val_accuracy: 0.3891\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2673 - accuracy: 0.3837 - val_loss: 0.3400 - val_accuracy: 0.3212\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3400 - accuracy: 0.3212\n",
            "sklearn_accuracy: 0.581375\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 5, 1, 1, 4, 2, 5, 2, 2, 5, 3, 3, 1, 2, 21, 4, 3, 2, 2, 12, 3, 3, 1, 2, 2, 15, 0.18, 9, 0.23, 16, 0.1]\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_137 (Conv2D)         (None, 87, 128, 11)       286       \n",
            "                                                                 \n",
            " max_pooling2d_137 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_137 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_138 (Conv2D)         (None, 87, 128, 4)        444       \n",
            "                                                                 \n",
            " max_pooling2d_138 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_138 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_58 (Flatten)        (None, 11264)             0         \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 15)                168975    \n",
            "                                                                 \n",
            " dropout_109 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_168 (Dense)           (None, 9)                 144       \n",
            "                                                                 \n",
            " dropout_110 (Dropout)       (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 5)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,959\n",
            "Trainable params: 169,929\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.6455 - accuracy: 0.1072 - val_loss: 0.6020 - val_accuracy: 0.0962\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.6145 - accuracy: 0.1184 - val_loss: 0.6213 - val_accuracy: 0.1930\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.6048 - accuracy: 0.1544 - val_loss: 0.5944 - val_accuracy: 0.2511\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5961 - accuracy: 0.1890 - val_loss: 0.5863 - val_accuracy: 0.2634\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5637 - accuracy: 0.2138 - val_loss: 0.5286 - val_accuracy: 0.2656\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5437 - accuracy: 0.2344 - val_loss: 0.5147 - val_accuracy: 0.2934\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5349 - accuracy: 0.2366 - val_loss: 0.6470 - val_accuracy: 0.1716\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5300 - accuracy: 0.2394 - val_loss: 0.5124 - val_accuracy: 0.2668\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5260 - accuracy: 0.2463 - val_loss: 0.5115 - val_accuracy: 0.3445\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5215 - accuracy: 0.2513 - val_loss: 0.5091 - val_accuracy: 0.2368\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5209 - accuracy: 0.2486 - val_loss: 0.7336 - val_accuracy: 0.2434\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5186 - accuracy: 0.2548 - val_loss: 0.5117 - val_accuracy: 0.3257\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5167 - accuracy: 0.2571 - val_loss: 0.5215 - val_accuracy: 0.3175\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5139 - accuracy: 0.2580 - val_loss: 0.4969 - val_accuracy: 0.2988\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.5138 - accuracy: 0.2631 - val_loss: 0.5041 - val_accuracy: 0.3040\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.5041 - accuracy: 0.3040\n",
            "sklearn_accuracy: 0.125875\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 6, 7, 7, 1, 1, 2, 5, 5, 2, 2, 3, 4, 3, 1, 2, 17, 4, 4, 2, 1, 12, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_139 (Conv2D)         (None, 87, 128, 6)        300       \n",
            "                                                                 \n",
            " max_pooling2d_139 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_139 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_140 (Conv2D)         (None, 87, 128, 2)        302       \n",
            "                                                                 \n",
            " max_pooling2d_140 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_140 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_59 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 15)                84495     \n",
            "                                                                 \n",
            " dropout_111 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,209\n",
            "Trainable params: 85,193\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.5320 - accuracy: 0.2160 - val_loss: 0.2975 - val_accuracy: 0.3414\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.2633 - accuracy: 0.3259 - val_loss: 0.2359 - val_accuracy: 0.3243\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1630 - accuracy: 0.3722 - val_loss: 0.2148 - val_accuracy: 0.3550\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1251 - accuracy: 0.3672 - val_loss: 0.2135 - val_accuracy: 0.3431\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1046 - accuracy: 0.3596 - val_loss: 0.2226 - val_accuracy: 0.3444\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0918 - accuracy: 0.3512 - val_loss: 0.2281 - val_accuracy: 0.3389\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0851 - accuracy: 0.3571 - val_loss: 0.2153 - val_accuracy: 0.3511\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0788 - accuracy: 0.3683 - val_loss: 0.2866 - val_accuracy: 0.3610\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0739 - accuracy: 0.3615 - val_loss: 0.3379 - val_accuracy: 0.3681\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0740 - accuracy: 0.3663 - val_loss: 0.3274 - val_accuracy: 0.3575\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0688 - accuracy: 0.3706 - val_loss: 0.3431 - val_accuracy: 0.3579\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0671 - accuracy: 0.3637 - val_loss: 0.3102 - val_accuracy: 0.3579\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0650 - accuracy: 0.3718 - val_loss: 0.3951 - val_accuracy: 0.3644\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0638 - accuracy: 0.3771 - val_loss: 0.4004 - val_accuracy: 0.3977\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0626 - accuracy: 0.3866 - val_loss: 0.3393 - val_accuracy: 0.3761\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3393 - accuracy: 0.3761\n",
            "sklearn_accuracy: 0.67175\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 17, 3, 5, 1, 1, 2, 4, 5, 2, 2, 6, 4, 3, 1, 2, 14, 4, 5, 2, 1, 6, 5, 5, 1, 2, 3, 18, 0.18, 9, 0.14, 20, 0.1]\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_141 (Conv2D)         (None, 87, 128, 17)       272       \n",
            "                                                                 \n",
            " max_pooling2d_141 (MaxPooli  (None, 87, 128, 17)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_141 (Ba  (None, 87, 128, 17)      68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_142 (Conv2D)         (None, 87, 128, 2)        682       \n",
            "                                                                 \n",
            " max_pooling2d_142 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_142 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_60 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_172 (Dense)           (None, 18)                101394    \n",
            "                                                                 \n",
            " dropout_112 (Dropout)       (None, 18)                0         \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 9)                 171       \n",
            "                                                                 \n",
            " dropout_113 (Dropout)       (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 20)                200       \n",
            "                                                                 \n",
            " dropout_114 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,900\n",
            "Trainable params: 102,862\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 27s 34ms/step - loss: 0.5782 - accuracy: 0.1673 - val_loss: 0.4766 - val_accuracy: 0.2467\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4625 - accuracy: 0.2482 - val_loss: 0.3767 - val_accuracy: 0.2829\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4124 - accuracy: 0.2700 - val_loss: 0.3606 - val_accuracy: 0.2539\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3793 - accuracy: 0.2763 - val_loss: 0.3253 - val_accuracy: 0.3004\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3681 - accuracy: 0.2803 - val_loss: 0.3207 - val_accuracy: 0.2488\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3604 - accuracy: 0.2865 - val_loss: 0.3209 - val_accuracy: 0.2510\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3570 - accuracy: 0.2861 - val_loss: 0.3201 - val_accuracy: 0.2484\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.3561 - accuracy: 0.2962 - val_loss: 0.3122 - val_accuracy: 0.3001\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.3525 - accuracy: 0.2993 - val_loss: 0.3153 - val_accuracy: 0.2705\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3499 - accuracy: 0.3077 - val_loss: 0.3342 - val_accuracy: 0.2615\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.3478 - accuracy: 0.3036 - val_loss: 0.3197 - val_accuracy: 0.2678\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3402 - accuracy: 0.3097 - val_loss: 0.3164 - val_accuracy: 0.3282\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3377 - accuracy: 0.3167 - val_loss: 0.3032 - val_accuracy: 0.3017\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3365 - accuracy: 0.3155 - val_loss: 0.3093 - val_accuracy: 0.3413\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.3364 - accuracy: 0.3204 - val_loss: 0.3123 - val_accuracy: 0.3385\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.3123 - accuracy: 0.3385\n",
            "sklearn_accuracy: 0.3580625\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 5, 6, 1, 1, 2, 2, 4, 2, 1, 3, 4, 2, 2, 2, 17, 4, 4, 2, 1, 10, 4, 2, 1, 1, 1, 16, 0.18, 11, 0.14, 11, 0.12]\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_143 (Conv2D)         (None, 87, 128, 6)        186       \n",
            "                                                                 \n",
            " max_pooling2d_143 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_143 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_144 (Conv2D)         (None, 87, 128, 2)        98        \n",
            "                                                                 \n",
            " max_pooling2d_144 (MaxPooli  (None, 44, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_144 (Ba  (None, 44, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 44, 128, 3)        51        \n",
            "                                                                 \n",
            " max_pooling2d_145 (MaxPooli  (None, 22, 64, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_145 (Ba  (None, 22, 64, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_61 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 16)                67600     \n",
            "                                                                 \n",
            " dropout_115 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,064\n",
            "Trainable params: 68,042\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 21s 26ms/step - loss: 0.4133 - accuracy: 0.3180 - val_loss: 0.3373 - val_accuracy: 0.3154\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.2660 - accuracy: 0.3785 - val_loss: 0.3141 - val_accuracy: 0.3718\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.2264 - accuracy: 0.4040 - val_loss: 0.4241 - val_accuracy: 0.4672\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1870 - accuracy: 0.4394 - val_loss: 0.3390 - val_accuracy: 0.4347\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1656 - accuracy: 0.4642 - val_loss: 0.4693 - val_accuracy: 0.4717\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1546 - accuracy: 0.4727 - val_loss: 0.4244 - val_accuracy: 0.4673\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1453 - accuracy: 0.4722 - val_loss: 0.4225 - val_accuracy: 0.4089\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1385 - accuracy: 0.4736 - val_loss: 0.5007 - val_accuracy: 0.4466\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1274 - accuracy: 0.4769 - val_loss: 0.6795 - val_accuracy: 0.5126\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1215 - accuracy: 0.4708 - val_loss: 0.5815 - val_accuracy: 0.4683\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1163 - accuracy: 0.4745 - val_loss: 0.5563 - val_accuracy: 0.4889\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.1120 - accuracy: 0.4744 - val_loss: 0.5846 - val_accuracy: 0.4529\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1097 - accuracy: 0.4660 - val_loss: 0.6243 - val_accuracy: 0.4638\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1055 - accuracy: 0.4663 - val_loss: 0.6238 - val_accuracy: 0.4249\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.1035 - accuracy: 0.4630 - val_loss: 0.7821 - val_accuracy: 0.4851\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.7821 - accuracy: 0.4851\n",
            "sklearn_accuracy: 0.5381875\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 5, 6, 1, 1, 2, 4, 4, 2, 2, 3, 4, 7, 2, 2, 14, 4, 4, 2, 2, 6, 5, 2, 1, 2, 1, 15, 0.18, 13, 0.14, 15, 0.11]\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_146 (Conv2D)         (None, 87, 128, 6)        186       \n",
            "                                                                 \n",
            " max_pooling2d_146 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_146 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 87, 128, 2)        194       \n",
            "                                                                 \n",
            " max_pooling2d_147 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_147 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_148 (Conv2D)         (None, 44, 64, 3)         171       \n",
            "                                                                 \n",
            " max_pooling2d_148 (MaxPooli  (None, 22, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_148 (Ba  (None, 22, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_62 (Flatten)        (None, 2112)              0         \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 15)                31695     \n",
            "                                                                 \n",
            " dropout_116 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,370\n",
            "Trainable params: 32,348\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5067 - accuracy: 0.2020 - val_loss: 0.4124 - val_accuracy: 0.1732\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3591 - accuracy: 0.2627 - val_loss: 0.3770 - val_accuracy: 0.1992\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2552 - accuracy: 0.3036 - val_loss: 0.2259 - val_accuracy: 0.2774\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2086 - accuracy: 0.3347 - val_loss: 0.2470 - val_accuracy: 0.3224\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1841 - accuracy: 0.3600 - val_loss: 0.2418 - val_accuracy: 0.3565\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1687 - accuracy: 0.3715 - val_loss: 0.2450 - val_accuracy: 0.3534\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1518 - accuracy: 0.3992 - val_loss: 0.3571 - val_accuracy: 0.3228\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1383 - accuracy: 0.4210 - val_loss: 0.3062 - val_accuracy: 0.4116\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1295 - accuracy: 0.4286 - val_loss: 0.2806 - val_accuracy: 0.4065\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1251 - accuracy: 0.4459 - val_loss: 0.2937 - val_accuracy: 0.3643\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1200 - accuracy: 0.4549 - val_loss: 0.2771 - val_accuracy: 0.4304\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1179 - accuracy: 0.4592 - val_loss: 0.3426 - val_accuracy: 0.4403\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1124 - accuracy: 0.4623 - val_loss: 0.3311 - val_accuracy: 0.4679\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1121 - accuracy: 0.4668 - val_loss: 0.2983 - val_accuracy: 0.4231\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1084 - accuracy: 0.4711 - val_loss: 0.3069 - val_accuracy: 0.4064\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3069 - accuracy: 0.4064\n",
            "sklearn_accuracy: 0.6629375\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 2, 3, 1, 1, 2, 2, 3, 2, 2, 3, 4, 2, 2, 2, 17, 7, 4, 2, 1, 10, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 12, 0.12]\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_149 (Conv2D)         (None, 87, 128, 11)       77        \n",
            "                                                                 \n",
            " max_pooling2d_149 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_149 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_150 (Conv2D)         (None, 87, 128, 2)        134       \n",
            "                                                                 \n",
            " max_pooling2d_150 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_150 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_63 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_180 (Dense)           (None, 16)                90128     \n",
            "                                                                 \n",
            " dropout_117 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,476\n",
            "Trainable params: 90,450\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 17s 21ms/step - loss: 0.3916 - accuracy: 0.3279 - val_loss: 0.2748 - val_accuracy: 0.4915\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.2088 - accuracy: 0.4280 - val_loss: 0.2499 - val_accuracy: 0.3622\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.1505 - accuracy: 0.4484 - val_loss: 0.3367 - val_accuracy: 0.4880\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.1134 - accuracy: 0.4673 - val_loss: 0.2952 - val_accuracy: 0.4915\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0971 - accuracy: 0.4724 - val_loss: 0.3144 - val_accuracy: 0.4806\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0894 - accuracy: 0.4711 - val_loss: 0.3161 - val_accuracy: 0.4178\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0851 - accuracy: 0.4694 - val_loss: 0.4160 - val_accuracy: 0.4960\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0809 - accuracy: 0.4639 - val_loss: 0.4925 - val_accuracy: 0.4209\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0773 - accuracy: 0.4611 - val_loss: 0.4052 - val_accuracy: 0.4527\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0736 - accuracy: 0.4582 - val_loss: 0.4352 - val_accuracy: 0.4532\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0716 - accuracy: 0.4613 - val_loss: 0.5737 - val_accuracy: 0.5334\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0707 - accuracy: 0.4619 - val_loss: 0.4296 - val_accuracy: 0.4888\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0663 - accuracy: 0.4646 - val_loss: 0.4784 - val_accuracy: 0.3898\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0674 - accuracy: 0.4650 - val_loss: 0.4360 - val_accuracy: 0.4809\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.0663 - accuracy: 0.4652 - val_loss: 0.5099 - val_accuracy: 0.3826\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.5099 - accuracy: 0.3826\n",
            "sklearn_accuracy: 0.6211875\n",
            "\n",
            "(main) 8' population has been evaluated\n",
            "best individual: [[2, 6, 7, 7, 1, 1, 2, 5, 5, 2, 2, 3, 4, 3, 1, 2, 17, 4, 4, 2, 1, 12, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]]\n",
            "statistics: {'min': 0.125875, 'max': 0.67175, 'average': 0.512328125}\n",
            "(main) 9' population initialized\n",
            "[2, 6, 7, 7, 1, 1, 2, 5, 5, 2, 2, 3, 4, 3, 1, 2, 17, 4, 4, 2, 1, 12, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "[3, 6, 4, 6, 1, 2, 7, 2, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 1, 2, 1, 15, 0.13, 13, 0.06, 15, 0.11]\n",
            "[2, 11, 5, 3, 1, 1, 7, 2, 5, 2, 2, 10, 4, 3, 1, 2, 17, 4, 4, 1, 1, 10, 7, 2, 1, 1, 1, 16, 0.18, 15, 0.14, 13, 0.08]\n",
            "[2, 11, 5, 4, 2, 1, 2, 2, 5, 2, 2, 5, 4, 6, 1, 1, 20, 6, 4, 2, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]\n",
            "[4, 11, 5, 3, 1, 1, 2, 2, 5, 2, 1, 5, 4, 2, 1, 2, 17, 4, 6, 2, 1, 11, 7, 2, 1, 1, 1, 21, 0.18, 7, 0.15, 15, 0.03]\n",
            "[2, 14, 2, 3, 2, 1, 2, 4, 5, 1, 1, 5, 4, 3, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.2]\n",
            "[1, 11, 6, 3, 1, 1, 2, 7, 7, 2, 1, 5, 4, 2, 1, 2, 17, 4, 4, 2, 1, 13, 4, 2, 1, 2, 1, 15, 0.18, 6, 0.14, 11, 0.03]\n",
            "[3, 6, 7, 5, 1, 1, 6, 2, 4, 2, 2, 8, 7, 3, 1, 2, 17, 4, 6, 1, 1, 6, 5, 7, 2, 2, 2, 21, 0.18, 6, 0.12, 11, 0.26]\n",
            "\n",
            " - GENERATION 9\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 6, 7, 7, 1, 1, 2, 5, 5, 2, 2, 3, 4, 3, 1, 2, 17, 4, 4, 2, 1, 12, 4, 2, 1, 1, 1, 15, 0.18, 6, 0.14, 11, 0.11]\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_151 (Conv2D)         (None, 87, 128, 6)        300       \n",
            "                                                                 \n",
            " max_pooling2d_151 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_151 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_152 (Conv2D)         (None, 87, 128, 2)        302       \n",
            "                                                                 \n",
            " max_pooling2d_152 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_152 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_64 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 15)                84495     \n",
            "                                                                 \n",
            " dropout_118 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,209\n",
            "Trainable params: 85,193\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.5283 - accuracy: 0.1862 - val_loss: 0.3498 - val_accuracy: 0.3516\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.2599 - accuracy: 0.4311 - val_loss: 0.2125 - val_accuracy: 0.5349\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1528 - accuracy: 0.4934 - val_loss: 0.3185 - val_accuracy: 0.5727\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1139 - accuracy: 0.5088 - val_loss: 0.2148 - val_accuracy: 0.4812\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0969 - accuracy: 0.5135 - val_loss: 0.2629 - val_accuracy: 0.5126\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0833 - accuracy: 0.5264 - val_loss: 0.2842 - val_accuracy: 0.5184\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0780 - accuracy: 0.5298 - val_loss: 0.4182 - val_accuracy: 0.5525\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0725 - accuracy: 0.5342 - val_loss: 0.3441 - val_accuracy: 0.5450\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0692 - accuracy: 0.5320 - val_loss: 0.3420 - val_accuracy: 0.5161\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0682 - accuracy: 0.5335 - val_loss: 0.3909 - val_accuracy: 0.5272\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0648 - accuracy: 0.5400 - val_loss: 0.3954 - val_accuracy: 0.5566\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0645 - accuracy: 0.5459 - val_loss: 0.5736 - val_accuracy: 0.4803\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0642 - accuracy: 0.5381 - val_loss: 0.4711 - val_accuracy: 0.5444\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0622 - accuracy: 0.5411 - val_loss: 0.4088 - val_accuracy: 0.5129\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0573 - accuracy: 0.5393 - val_loss: 0.3988 - val_accuracy: 0.5116\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3988 - accuracy: 0.5116\n",
            "sklearn_accuracy: 0.68975\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 4, 6, 1, 2, 7, 2, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 1, 2, 1, 15, 0.13, 13, 0.06, 15, 0.11]\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_153 (Conv2D)         (None, 87, 128, 6)        150       \n",
            "                                                                 \n",
            " max_pooling2d_153 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_153 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_154 (Conv2D)         (None, 87, 64, 7)         175       \n",
            "                                                                 \n",
            " max_pooling2d_154 (MaxPooli  (None, 87, 64, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_154 (Ba  (None, 87, 64, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_155 (Conv2D)         (None, 87, 64, 3)         339       \n",
            "                                                                 \n",
            " max_pooling2d_155 (MaxPooli  (None, 87, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_155 (Ba  (None, 87, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_65 (Flatten)        (None, 8352)              0         \n",
            "                                                                 \n",
            " dense_184 (Dense)           (None, 15)                125295    \n",
            "                                                                 \n",
            " dropout_119 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126,103\n",
            "Trainable params: 126,071\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 16s 20ms/step - loss: 0.5144 - accuracy: 0.3158 - val_loss: 0.4119 - val_accuracy: 0.4886\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.3926 - accuracy: 0.4761 - val_loss: 0.3490 - val_accuracy: 0.5278\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.3697 - accuracy: 0.5210 - val_loss: 0.3859 - val_accuracy: 0.5642\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.3534 - accuracy: 0.5545 - val_loss: 0.3171 - val_accuracy: 0.5780\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2850 - accuracy: 0.5801 - val_loss: 0.3213 - val_accuracy: 0.5822\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2602 - accuracy: 0.5727 - val_loss: 0.2614 - val_accuracy: 0.6325\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2504 - accuracy: 0.5695 - val_loss: 0.2341 - val_accuracy: 0.5362\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2429 - accuracy: 0.5687 - val_loss: 0.3910 - val_accuracy: 0.6986\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2368 - accuracy: 0.5753 - val_loss: 0.2673 - val_accuracy: 0.5344\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2318 - accuracy: 0.5780 - val_loss: 0.2693 - val_accuracy: 0.6740\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2265 - accuracy: 0.5783 - val_loss: 0.2689 - val_accuracy: 0.5601\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2274 - accuracy: 0.5756 - val_loss: 0.2831 - val_accuracy: 0.5946\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2236 - accuracy: 0.5814 - val_loss: 0.2246 - val_accuracy: 0.5901\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2249 - accuracy: 0.5690 - val_loss: 0.2690 - val_accuracy: 0.5567\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2235 - accuracy: 0.5742 - val_loss: 0.2380 - val_accuracy: 0.5974\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2380 - accuracy: 0.5974\n",
            "sklearn_accuracy: 0.6835625\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 3, 1, 1, 7, 2, 5, 2, 2, 10, 4, 3, 1, 2, 17, 4, 4, 1, 1, 10, 7, 2, 1, 1, 1, 16, 0.18, 15, 0.14, 13, 0.08]\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_156 (Conv2D)         (None, 87, 128, 11)       176       \n",
            "                                                                 \n",
            " max_pooling2d_156 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_156 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 87, 128, 7)        777       \n",
            "                                                                 \n",
            " max_pooling2d_157 (MaxPooli  (None, 44, 64, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_157 (Ba  (None, 44, 64, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_66 (Flatten)        (None, 19712)             0         \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 16)                315408    \n",
            "                                                                 \n",
            " dropout_120 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 316,518\n",
            "Trainable params: 316,482\n",
            "Non-trainable params: 36\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 24ms/step - loss: 0.6364 - accuracy: 0.2809 - val_loss: 0.6010 - val_accuracy: 0.3079\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.6004 - accuracy: 0.2596 - val_loss: 0.5690 - val_accuracy: 0.3048\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5937 - accuracy: 0.2622 - val_loss: 0.5642 - val_accuracy: 0.3081\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.5906 - accuracy: 0.2631 - val_loss: 0.5646 - val_accuracy: 0.3071\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5908 - accuracy: 0.2623 - val_loss: 0.5581 - val_accuracy: 0.3044\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5885 - accuracy: 0.2642 - val_loss: 0.5612 - val_accuracy: 0.2973\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5897 - accuracy: 0.2631 - val_loss: 0.5589 - val_accuracy: 0.2994\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5892 - accuracy: 0.2629 - val_loss: 0.5632 - val_accuracy: 0.3031\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5893 - accuracy: 0.2634 - val_loss: 0.6015 - val_accuracy: 0.2717\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5872 - accuracy: 0.2631 - val_loss: 0.5608 - val_accuracy: 0.2921\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5880 - accuracy: 0.2634 - val_loss: 0.5580 - val_accuracy: 0.2946\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.5462 - accuracy: 0.2636 - val_loss: 0.5020 - val_accuracy: 0.2739\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5292 - accuracy: 0.2628 - val_loss: 0.5008 - val_accuracy: 0.2791\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5286 - accuracy: 0.2645 - val_loss: 0.4979 - val_accuracy: 0.2808\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5264 - accuracy: 0.2660 - val_loss: 0.4986 - val_accuracy: 0.2811\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4986 - accuracy: 0.2811\n",
            "sklearn_accuracy: 0.131\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 4, 2, 1, 2, 2, 5, 2, 2, 5, 4, 6, 1, 1, 20, 6, 4, 2, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_158 (Conv2D)         (None, 87, 128, 11)       231       \n",
            "                                                                 \n",
            " max_pooling2d_158 (MaxPooli  (None, 44, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_158 (Ba  (None, 44, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 44, 128, 2)        222       \n",
            "                                                                 \n",
            " max_pooling2d_159 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_159 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_67 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_188 (Dense)           (None, 16)                45072     \n",
            "                                                                 \n",
            " dropout_121 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,662\n",
            "Trainable params: 45,636\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.4148 - accuracy: 0.3421 - val_loss: 0.3358 - val_accuracy: 0.4227\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2175 - accuracy: 0.4248 - val_loss: 0.2518 - val_accuracy: 0.4479\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1569 - accuracy: 0.4706 - val_loss: 0.2748 - val_accuracy: 0.4909\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1309 - accuracy: 0.5098 - val_loss: 0.2314 - val_accuracy: 0.5364\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1162 - accuracy: 0.5289 - val_loss: 0.2377 - val_accuracy: 0.4651\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1072 - accuracy: 0.5324 - val_loss: 0.4343 - val_accuracy: 0.5936\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1007 - accuracy: 0.5371 - val_loss: 0.2882 - val_accuracy: 0.4433\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0938 - accuracy: 0.5186 - val_loss: 0.4041 - val_accuracy: 0.4884\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0864 - accuracy: 0.5246 - val_loss: 0.3348 - val_accuracy: 0.4931\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0822 - accuracy: 0.5190 - val_loss: 0.3871 - val_accuracy: 0.4296\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0798 - accuracy: 0.5226 - val_loss: 0.3704 - val_accuracy: 0.5161\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0772 - accuracy: 0.5221 - val_loss: 0.4007 - val_accuracy: 0.5458\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0747 - accuracy: 0.5214 - val_loss: 0.3788 - val_accuracy: 0.4834\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0737 - accuracy: 0.5268 - val_loss: 0.2867 - val_accuracy: 0.4946\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0721 - accuracy: 0.5276 - val_loss: 0.3551 - val_accuracy: 0.5187\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3551 - accuracy: 0.5187\n",
            "sklearn_accuracy: 0.7019375\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 11, 5, 3, 1, 1, 2, 2, 5, 2, 1, 5, 4, 2, 1, 2, 17, 4, 6, 2, 1, 11, 7, 2, 1, 1, 1, 21, 0.18, 7, 0.15, 15, 0.03]\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_160 (Conv2D)         (None, 87, 128, 11)       176       \n",
            "                                                                 \n",
            " max_pooling2d_160 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_160 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_161 (Conv2D)         (None, 87, 128, 2)        222       \n",
            "                                                                 \n",
            " max_pooling2d_161 (MaxPooli  (None, 44, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_161 (Ba  (None, 44, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_162 (Conv2D)         (None, 44, 128, 5)        85        \n",
            "                                                                 \n",
            " max_pooling2d_162 (MaxPooli  (None, 44, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_162 (Ba  (None, 44, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_163 (Conv2D)         (None, 44, 64, 17)        2057      \n",
            "                                                                 \n",
            " max_pooling2d_163 (MaxPooli  (None, 22, 64, 17)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_163 (Ba  (None, 22, 64, 17)       68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_68 (Flatten)        (None, 23936)             0         \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 21)                502677    \n",
            "                                                                 \n",
            " dropout_122 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505,467\n",
            "Trainable params: 505,397\n",
            "Non-trainable params: 70\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.6369 - accuracy: 0.1097 - val_loss: 0.6077 - val_accuracy: 0.0957\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6101 - accuracy: 0.1115 - val_loss: 0.5788 - val_accuracy: 0.1443\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6040 - accuracy: 0.1113 - val_loss: 0.5755 - val_accuracy: 0.0934\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.6013 - accuracy: 0.1117 - val_loss: 0.5847 - val_accuracy: 0.1311\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5995 - accuracy: 0.1094 - val_loss: 0.5713 - val_accuracy: 0.0932\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5984 - accuracy: 0.1180 - val_loss: 0.5793 - val_accuracy: 0.0925\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5952 - accuracy: 0.1168 - val_loss: 0.5608 - val_accuracy: 0.1281\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5930 - accuracy: 0.1136 - val_loss: 0.5612 - val_accuracy: 0.0999\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5914 - accuracy: 0.1124 - val_loss: 0.5625 - val_accuracy: 0.0922\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5919 - accuracy: 0.1096 - val_loss: 0.5559 - val_accuracy: 0.1206\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5894 - accuracy: 0.1063 - val_loss: 0.5567 - val_accuracy: 0.1148\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5895 - accuracy: 0.1082 - val_loss: 0.5605 - val_accuracy: 0.1247\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5875 - accuracy: 0.1092 - val_loss: 0.5634 - val_accuracy: 0.1339\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5880 - accuracy: 0.1069 - val_loss: 0.5561 - val_accuracy: 0.1336\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.5877 - accuracy: 0.1094 - val_loss: 0.5677 - val_accuracy: 0.1220\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.1220\n",
            "sklearn_accuracy: 0.0871875\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 14, 2, 3, 2, 1, 2, 4, 5, 1, 1, 5, 4, 3, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.2]\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_164 (Conv2D)         (None, 87, 128, 14)       98        \n",
            "                                                                 \n",
            " max_pooling2d_164 (MaxPooli  (None, 44, 128, 14)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_164 (Ba  (None, 44, 128, 14)      56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_165 (Conv2D)         (None, 44, 128, 2)        562       \n",
            "                                                                 \n",
            " max_pooling2d_165 (MaxPooli  (None, 44, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_165 (Ba  (None, 44, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_69 (Flatten)        (None, 11264)             0         \n",
            "                                                                 \n",
            " dense_192 (Dense)           (None, 21)                236565    \n",
            "                                                                 \n",
            " dropout_123 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 237,399\n",
            "Trainable params: 237,367\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.6067 - accuracy: 0.1833 - val_loss: 0.6684 - val_accuracy: 0.3248\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4977 - accuracy: 0.3384 - val_loss: 0.3927 - val_accuracy: 0.4705\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4086 - accuracy: 0.4532 - val_loss: 0.3618 - val_accuracy: 0.4482\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3956 - accuracy: 0.4678 - val_loss: 0.3672 - val_accuracy: 0.5189\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3812 - accuracy: 0.4729 - val_loss: 0.3497 - val_accuracy: 0.4781\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3544 - accuracy: 0.4734 - val_loss: 0.3168 - val_accuracy: 0.4682\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3428 - accuracy: 0.4876 - val_loss: 0.3268 - val_accuracy: 0.4876\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3371 - accuracy: 0.4856 - val_loss: 0.3558 - val_accuracy: 0.4671\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3330 - accuracy: 0.4963 - val_loss: 0.3821 - val_accuracy: 0.4262\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3153 - accuracy: 0.4892 - val_loss: 0.3527 - val_accuracy: 0.5216\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2988 - accuracy: 0.4780 - val_loss: 0.3468 - val_accuracy: 0.5199\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2876 - accuracy: 0.4758 - val_loss: 0.3348 - val_accuracy: 0.4344\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2780 - accuracy: 0.4789 - val_loss: 0.2846 - val_accuracy: 0.4796\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2722 - accuracy: 0.4688 - val_loss: 0.2785 - val_accuracy: 0.4409\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2679 - accuracy: 0.4521 - val_loss: 0.2886 - val_accuracy: 0.4250\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2886 - accuracy: 0.4250\n",
            "sklearn_accuracy: 0.6228125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 11, 6, 3, 1, 1, 2, 7, 7, 2, 1, 5, 4, 2, 1, 2, 17, 4, 4, 2, 1, 13, 4, 2, 1, 2, 1, 15, 0.18, 6, 0.14, 11, 0.03]\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_166 (Conv2D)         (None, 87, 128, 11)       209       \n",
            "                                                                 \n",
            " max_pooling2d_166 (MaxPooli  (None, 87, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_166 (Ba  (None, 87, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_70 (Flatten)        (None, 122496)            0         \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 15)                1837455   \n",
            "                                                                 \n",
            " dropout_124 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,837,788\n",
            "Trainable params: 1,837,766\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 17ms/step - loss: 0.7725 - accuracy: 0.2128 - val_loss: 0.6940 - val_accuracy: 0.1254\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2027 - val_loss: 0.6939 - val_accuracy: 0.5314\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2352 - val_loss: 0.6939 - val_accuracy: 0.5314\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1871 - val_loss: 0.6939 - val_accuracy: 0.1252\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2370 - val_loss: 0.6939 - val_accuracy: 0.0316\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2322 - val_loss: 0.6939 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1988 - val_loss: 0.6939 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1583 - val_loss: 0.6939 - val_accuracy: 0.5314\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2894 - val_loss: 0.6939 - val_accuracy: 0.0316\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2079 - val_loss: 0.6939 - val_accuracy: 0.1252\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1899 - val_loss: 0.6939 - val_accuracy: 0.0316\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1345 - val_loss: 0.6939 - val_accuracy: 0.5314\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2562 - val_loss: 0.6939 - val_accuracy: 0.0627\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1233 - val_loss: 0.6939 - val_accuracy: 0.2500\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2093 - val_loss: 0.6939 - val_accuracy: 0.0627\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.6939 - accuracy: 0.0627\n",
            "sklearn_accuracy: 0.0313125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 7, 5, 1, 1, 6, 2, 4, 2, 2, 8, 7, 3, 1, 2, 17, 4, 6, 1, 1, 6, 5, 7, 2, 2, 2, 21, 0.18, 6, 0.12, 11, 0.26]\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_167 (Conv2D)         (None, 87, 128, 6)        216       \n",
            "                                                                 \n",
            " max_pooling2d_167 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_167 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_168 (Conv2D)         (None, 87, 128, 6)        294       \n",
            "                                                                 \n",
            " max_pooling2d_168 (MaxPooli  (None, 44, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_168 (Ba  (None, 44, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_169 (Conv2D)         (None, 44, 64, 8)         1016      \n",
            "                                                                 \n",
            " max_pooling2d_169 (MaxPooli  (None, 44, 32, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_169 (Ba  (None, 44, 32, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_71 (Flatten)        (None, 11264)             0         \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 21)                236565    \n",
            "                                                                 \n",
            " dropout_125 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 6)                 132       \n",
            "                                                                 \n",
            " dropout_126 (Dropout)       (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 5)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,338\n",
            "Trainable params: 238,298\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 21s 27ms/step - loss: 0.5630 - accuracy: 0.2325 - val_loss: 0.4776 - val_accuracy: 0.2534\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 20s 26ms/step - loss: 0.4414 - accuracy: 0.2380 - val_loss: 0.3870 - val_accuracy: 0.2526\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 20s 26ms/step - loss: 0.3906 - accuracy: 0.2481 - val_loss: 0.2935 - val_accuracy: 0.2885\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3522 - accuracy: 0.2590 - val_loss: 0.2560 - val_accuracy: 0.3062\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3389 - accuracy: 0.2535 - val_loss: 0.2729 - val_accuracy: 0.2821\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3348 - accuracy: 0.2488 - val_loss: 0.2611 - val_accuracy: 0.2764\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3301 - accuracy: 0.2486 - val_loss: 0.2413 - val_accuracy: 0.2652\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3244 - accuracy: 0.2472 - val_loss: 0.2519 - val_accuracy: 0.3077\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3209 - accuracy: 0.2525 - val_loss: 0.3571 - val_accuracy: 0.2553\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3187 - accuracy: 0.2527 - val_loss: 0.3076 - val_accuracy: 0.3005\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3174 - accuracy: 0.2531 - val_loss: 0.5064 - val_accuracy: 0.2666\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3112 - accuracy: 0.2618 - val_loss: 0.2625 - val_accuracy: 0.3312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3087 - accuracy: 0.2592 - val_loss: 0.3021 - val_accuracy: 0.3083\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3039 - accuracy: 0.2606 - val_loss: 0.2600 - val_accuracy: 0.3088\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 19s 26ms/step - loss: 0.3026 - accuracy: 0.2582 - val_loss: 0.2458 - val_accuracy: 0.3231\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.3231\n",
            "sklearn_accuracy: 0.5785\n",
            "\n",
            "(main) 9' population has been evaluated\n",
            "best individual: [[2, 11, 5, 4, 2, 1, 2, 2, 5, 2, 2, 5, 4, 6, 1, 1, 20, 6, 4, 2, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]]\n",
            "statistics: {'min': 0.0313125, 'max': 0.7019375, 'average': 0.44075781249999996}\n",
            "(main) 10' population initialized\n",
            "[2, 11, 5, 4, 2, 1, 2, 2, 5, 2, 2, 5, 4, 6, 1, 1, 20, 6, 4, 2, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]\n",
            "[2, 6, 7, 7, 1, 1, 5, 5, 5, 1, 1, 3, 4, 3, 2, 2, 22, 4, 5, 1, 1, 10, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 15, 0.2]\n",
            "[3, 6, 4, 2, 1, 2, 10, 6, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.19, 13, 0.06, 15, 0.09]\n",
            "[2, 7, 7, 5, 1, 1, 6, 2, 4, 1, 1, 8, 7, 3, 1, 2, 20, 4, 6, 1, 1, 6, 5, 7, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]\n",
            "[3, 6, 7, 7, 1, 2, 2, 7, 6, 2, 2, 4, 4, 3, 1, 2, 17, 6, 4, 2, 1, 12, 4, 2, 2, 1, 3, 20, 0.18, 11, 0.14, 15, 0.11]\n",
            "[2, 14, 2, 6, 2, 1, 4, 4, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.2]\n",
            "[3, 6, 7, 5, 2, 1, 6, 5, 4, 2, 1, 3, 2, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 1, 2, 2, 15, 0.25, 13, 0.09, 15, 0.09]\n",
            "[4, 11, 6, 6, 2, 1, 2, 7, 5, 2, 2, 5, 4, 6, 2, 1, 23, 6, 4, 1, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.1, 17, 0.15]\n",
            "\n",
            " - GENERATION 10\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 11, 5, 4, 2, 1, 2, 2, 5, 2, 2, 5, 4, 6, 1, 1, 20, 6, 4, 2, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_170 (Conv2D)         (None, 87, 128, 11)       231       \n",
            "                                                                 \n",
            " max_pooling2d_170 (MaxPooli  (None, 44, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_170 (Ba  (None, 44, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_171 (Conv2D)         (None, 44, 128, 2)        222       \n",
            "                                                                 \n",
            " max_pooling2d_171 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_171 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_72 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 16)                45072     \n",
            "                                                                 \n",
            " dropout_127 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_200 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,662\n",
            "Trainable params: 45,636\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.4401 - accuracy: 0.2509 - val_loss: 0.4301 - val_accuracy: 0.2263\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2409 - accuracy: 0.3878 - val_loss: 0.2336 - val_accuracy: 0.4137\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1693 - accuracy: 0.3985 - val_loss: 0.3874 - val_accuracy: 0.3359\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1460 - accuracy: 0.3876 - val_loss: 0.7144 - val_accuracy: 0.2422\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.1327 - accuracy: 0.3859 - val_loss: 0.2231 - val_accuracy: 0.3636\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1215 - accuracy: 0.3810 - val_loss: 0.2860 - val_accuracy: 0.3797\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1120 - accuracy: 0.3676 - val_loss: 0.3246 - val_accuracy: 0.3404\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1049 - accuracy: 0.3670 - val_loss: 0.3509 - val_accuracy: 0.3179\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0993 - accuracy: 0.3713 - val_loss: 0.3399 - val_accuracy: 0.3786\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0968 - accuracy: 0.3727 - val_loss: 0.3069 - val_accuracy: 0.3517\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0932 - accuracy: 0.3778 - val_loss: 0.3683 - val_accuracy: 0.3530\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0898 - accuracy: 0.3802 - val_loss: 0.3741 - val_accuracy: 0.3485\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0876 - accuracy: 0.3764 - val_loss: 0.3773 - val_accuracy: 0.3842\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.0856 - accuracy: 0.3752 - val_loss: 0.5496 - val_accuracy: 0.3101\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.0839 - accuracy: 0.3800 - val_loss: 0.3659 - val_accuracy: 0.3604\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3659 - accuracy: 0.3604\n",
            "sklearn_accuracy: 0.670375\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 6, 7, 7, 1, 1, 5, 5, 5, 1, 1, 3, 4, 3, 2, 2, 22, 4, 5, 1, 1, 10, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 15, 0.2]\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_172 (Conv2D)         (None, 87, 128, 6)        300       \n",
            "                                                                 \n",
            " max_pooling2d_172 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_172 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_173 (Conv2D)         (None, 87, 128, 5)        755       \n",
            "                                                                 \n",
            " max_pooling2d_173 (MaxPooli  (None, 87, 128, 5)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_173 (Ba  (None, 87, 128, 5)       20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_73 (Flatten)        (None, 55680)             0         \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 21)                1169301   \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,170,510\n",
            "Trainable params: 1,170,488\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.7046 - accuracy: 0.1937 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1157 - val_loss: 0.6932 - val_accuracy: 0.0313\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1783 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.2777 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6938 - accuracy: 0.1216 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.2487 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1059 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.2298 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.2233 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.2084 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1418 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.2375 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1399 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1203 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.6932 - accuracy: 0.1369 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 4, 2, 1, 2, 10, 6, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.19, 13, 0.06, 15, 0.09]\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_174 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_174 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_174 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 87, 64, 10)        730       \n",
            "                                                                 \n",
            " max_pooling2d_175 (MaxPooli  (None, 87, 64, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_175 (Ba  (None, 87, 64, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_176 (Conv2D)         (None, 87, 64, 3)         483       \n",
            "                                                                 \n",
            " max_pooling2d_176 (MaxPooli  (None, 87, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_176 (Ba  (None, 87, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_74 (Flatten)        (None, 8352)              0         \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 15)                125295    \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_204 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126,718\n",
            "Trainable params: 126,680\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 16s 20ms/step - loss: 0.5242 - accuracy: 0.1646 - val_loss: 0.3246 - val_accuracy: 0.1893\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.3333 - accuracy: 0.2124 - val_loss: 0.2697 - val_accuracy: 0.2288\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.2716 - accuracy: 0.2245 - val_loss: 0.2443 - val_accuracy: 0.2396\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2476 - accuracy: 0.2366 - val_loss: 0.2302 - val_accuracy: 0.2472\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.2363 - accuracy: 0.2477 - val_loss: 0.2214 - val_accuracy: 0.2271\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2267 - accuracy: 0.2589 - val_loss: 0.2265 - val_accuracy: 0.2503\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2142 - accuracy: 0.2656 - val_loss: 0.2469 - val_accuracy: 0.2699\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2035 - accuracy: 0.2616 - val_loss: 0.2039 - val_accuracy: 0.2546\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1992 - accuracy: 0.2569 - val_loss: 0.2687 - val_accuracy: 0.2356\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1958 - accuracy: 0.2508 - val_loss: 0.2378 - val_accuracy: 0.2573\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1939 - accuracy: 0.2457 - val_loss: 0.2448 - val_accuracy: 0.2456\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1910 - accuracy: 0.2535 - val_loss: 0.2781 - val_accuracy: 0.2645\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1880 - accuracy: 0.2507 - val_loss: 0.3027 - val_accuracy: 0.2189\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1868 - accuracy: 0.2511 - val_loss: 0.2366 - val_accuracy: 0.2319\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.1856 - accuracy: 0.2513 - val_loss: 0.2167 - val_accuracy: 0.2399\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2167 - accuracy: 0.2399\n",
            "sklearn_accuracy: 0.7258125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 7, 7, 5, 1, 1, 6, 2, 4, 1, 1, 8, 7, 3, 1, 2, 20, 4, 6, 1, 1, 6, 5, 7, 1, 2, 1, 16, 0.17, 11, 0.14, 17, 0.15]\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_177 (Conv2D)         (None, 87, 128, 7)        252       \n",
            "                                                                 \n",
            " max_pooling2d_177 (MaxPooli  (None, 87, 128, 7)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_177 (Ba  (None, 87, 128, 7)       28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_178 (Conv2D)         (None, 87, 128, 6)        342       \n",
            "                                                                 \n",
            " max_pooling2d_178 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_178 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_75 (Flatten)        (None, 66816)             0         \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 16)                1069072   \n",
            "                                                                 \n",
            " dropout_130 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,069,803\n",
            "Trainable params: 1,069,777\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 22s 28ms/step - loss: 0.6943 - accuracy: 0.1567 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6933 - accuracy: 0.2158 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1590 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.2076 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1961 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.4172 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.0926 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.2761 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1764 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1705 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1389 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1783 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1887 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.2423 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.6932 - accuracy: 0.1212 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.6932 - accuracy: 0.2500\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 7, 7, 1, 2, 2, 7, 6, 2, 2, 4, 4, 3, 1, 2, 17, 6, 4, 2, 1, 12, 4, 2, 2, 1, 3, 20, 0.18, 11, 0.14, 15, 0.11]\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_179 (Conv2D)         (None, 87, 128, 6)        300       \n",
            "                                                                 \n",
            " max_pooling2d_179 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_179 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_180 (Conv2D)         (None, 87, 64, 2)         506       \n",
            "                                                                 \n",
            " max_pooling2d_180 (MaxPooli  (None, 44, 32, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_180 (Ba  (None, 44, 32, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_181 (Conv2D)         (None, 44, 32, 4)         100       \n",
            "                                                                 \n",
            " max_pooling2d_181 (MaxPooli  (None, 44, 16, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_181 (Ba  (None, 44, 16, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_76 (Flatten)        (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 20)                56340     \n",
            "                                                                 \n",
            " dropout_131 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 11)                231       \n",
            "                                                                 \n",
            " dropout_132 (Dropout)       (None, 11)                0         \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 15)                180       \n",
            "                                                                 \n",
            " dropout_133 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,785\n",
            "Trainable params: 57,761\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.5492 - accuracy: 0.1832 - val_loss: 0.4086 - val_accuracy: 0.1826\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4307 - accuracy: 0.2034 - val_loss: 0.3787 - val_accuracy: 0.2175\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3886 - accuracy: 0.2561 - val_loss: 0.3513 - val_accuracy: 0.2869\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3600 - accuracy: 0.3058 - val_loss: 0.3199 - val_accuracy: 0.3311\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3304 - accuracy: 0.3605 - val_loss: 0.3537 - val_accuracy: 0.4105\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3109 - accuracy: 0.4029 - val_loss: 0.3046 - val_accuracy: 0.3438\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2898 - accuracy: 0.4339 - val_loss: 0.3667 - val_accuracy: 0.4204\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2787 - accuracy: 0.4474 - val_loss: 0.3806 - val_accuracy: 0.4561\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2701 - accuracy: 0.4644 - val_loss: 0.2927 - val_accuracy: 0.4164\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2642 - accuracy: 0.4747 - val_loss: 0.3934 - val_accuracy: 0.5566\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2553 - accuracy: 0.4773 - val_loss: 0.4055 - val_accuracy: 0.5371\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2514 - accuracy: 0.4779 - val_loss: 0.3395 - val_accuracy: 0.4186\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2478 - accuracy: 0.4740 - val_loss: 0.3035 - val_accuracy: 0.4910\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2442 - accuracy: 0.4765 - val_loss: 0.3050 - val_accuracy: 0.5045\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2412 - accuracy: 0.4749 - val_loss: 0.4342 - val_accuracy: 0.5536\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4342 - accuracy: 0.5536\n",
            "sklearn_accuracy: 0.355875\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 14, 2, 6, 2, 1, 4, 4, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.2]\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_182 (Conv2D)         (None, 87, 128, 14)       182       \n",
            "                                                                 \n",
            " max_pooling2d_182 (MaxPooli  (None, 44, 128, 14)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_182 (Ba  (None, 44, 128, 14)      56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_183 (Conv2D)         (None, 44, 128, 4)        676       \n",
            "                                                                 \n",
            " max_pooling2d_183 (MaxPooli  (None, 44, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_183 (Ba  (None, 44, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_77 (Flatten)        (None, 22528)             0         \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 21)                473109    \n",
            "                                                                 \n",
            " dropout_134 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 474,149\n",
            "Trainable params: 474,113\n",
            "Non-trainable params: 36\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.6172 - accuracy: 0.2889 - val_loss: 0.5525 - val_accuracy: 0.1939\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.5538 - accuracy: 0.1718 - val_loss: 0.5246 - val_accuracy: 0.1970\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.4874 - accuracy: 0.2510 - val_loss: 0.4033 - val_accuracy: 0.3217\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.4383 - accuracy: 0.2734 - val_loss: 0.3973 - val_accuracy: 0.3151\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.4234 - accuracy: 0.2785 - val_loss: 0.4098 - val_accuracy: 0.3172\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3857 - accuracy: 0.3000 - val_loss: 0.3730 - val_accuracy: 0.3566\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3456 - accuracy: 0.3257 - val_loss: 0.3731 - val_accuracy: 0.3447\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3365 - accuracy: 0.3318 - val_loss: 0.3999 - val_accuracy: 0.3832\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3343 - accuracy: 0.3394 - val_loss: 0.3610 - val_accuracy: 0.3600\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3288 - accuracy: 0.3501 - val_loss: 0.3433 - val_accuracy: 0.3776\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3313 - accuracy: 0.3594 - val_loss: 0.3537 - val_accuracy: 0.3826\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3307 - accuracy: 0.3607 - val_loss: 0.3590 - val_accuracy: 0.3864\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3297 - accuracy: 0.3668 - val_loss: 0.3587 - val_accuracy: 0.3713\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3262 - accuracy: 0.3676 - val_loss: 0.4773 - val_accuracy: 0.3650\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3269 - accuracy: 0.3676 - val_loss: 0.3892 - val_accuracy: 0.4072\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3892 - accuracy: 0.4072\n",
            "sklearn_accuracy: 0.353\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 7, 5, 2, 1, 6, 5, 4, 2, 1, 3, 2, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 1, 2, 2, 15, 0.25, 13, 0.09, 15, 0.09]\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_184 (Conv2D)         (None, 87, 128, 6)        216       \n",
            "                                                                 \n",
            " max_pooling2d_184 (MaxPooli  (None, 44, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_184 (Ba  (None, 44, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_185 (Conv2D)         (None, 44, 128, 6)        726       \n",
            "                                                                 \n",
            " max_pooling2d_185 (MaxPooli  (None, 22, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_185 (Ba  (None, 22, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_186 (Conv2D)         (None, 22, 128, 3)        147       \n",
            "                                                                 \n",
            " max_pooling2d_186 (MaxPooli  (None, 22, 64, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_186 (Ba  (None, 22, 64, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_78 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 15)                63375     \n",
            "                                                                 \n",
            " dropout_135 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 13)                208       \n",
            "                                                                 \n",
            " dropout_136 (Dropout)       (None, 13)                0         \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 5)                 70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,802\n",
            "Trainable params: 64,772\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.5974 - accuracy: 0.0908 - val_loss: 0.4563 - val_accuracy: 0.1778\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.4050 - accuracy: 0.2380 - val_loss: 0.3150 - val_accuracy: 0.2580\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3030 - accuracy: 0.2661 - val_loss: 0.2547 - val_accuracy: 0.2611\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2540 - accuracy: 0.2508 - val_loss: 0.2274 - val_accuracy: 0.2332\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2279 - accuracy: 0.2445 - val_loss: 0.2687 - val_accuracy: 0.2403\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2091 - accuracy: 0.2445 - val_loss: 0.2169 - val_accuracy: 0.2385\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1964 - accuracy: 0.2461 - val_loss: 0.2769 - val_accuracy: 0.2260\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1789 - accuracy: 0.2804 - val_loss: 0.2336 - val_accuracy: 0.2603\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1714 - accuracy: 0.2798 - val_loss: 0.2468 - val_accuracy: 0.2517\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1673 - accuracy: 0.2781 - val_loss: 0.2648 - val_accuracy: 0.2586\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1608 - accuracy: 0.2691 - val_loss: 0.2906 - val_accuracy: 0.2369\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1508 - accuracy: 0.2619 - val_loss: 0.2681 - val_accuracy: 0.2514\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1466 - accuracy: 0.2585 - val_loss: 0.2491 - val_accuracy: 0.2567\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1439 - accuracy: 0.2589 - val_loss: 0.2771 - val_accuracy: 0.2368\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.1414 - accuracy: 0.2629 - val_loss: 0.3885 - val_accuracy: 0.2311\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3885 - accuracy: 0.2311\n",
            "sklearn_accuracy: 0.710625\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 11, 6, 6, 2, 1, 2, 7, 5, 2, 2, 5, 4, 6, 2, 1, 23, 6, 4, 1, 1, 16, 4, 3, 1, 2, 1, 16, 0.17, 11, 0.1, 17, 0.15]\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_187 (Conv2D)         (None, 87, 128, 11)       407       \n",
            "                                                                 \n",
            " max_pooling2d_187 (MaxPooli  (None, 44, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_187 (Ba  (None, 44, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_188 (Conv2D)         (None, 44, 128, 2)        772       \n",
            "                                                                 \n",
            " max_pooling2d_188 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_188 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_189 (Conv2D)         (None, 22, 64, 5)         245       \n",
            "                                                                 \n",
            " max_pooling2d_189 (MaxPooli  (None, 11, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_189 (Ba  (None, 11, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_190 (Conv2D)         (None, 11, 64, 23)        2783      \n",
            "                                                                 \n",
            " max_pooling2d_190 (MaxPooli  (None, 11, 64, 23)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_190 (Ba  (None, 11, 64, 23)       92        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_79 (Flatten)        (None, 16192)             0         \n",
            "                                                                 \n",
            " dense_216 (Dense)           (None, 16)                259088    \n",
            "                                                                 \n",
            " dropout_137 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 263,544\n",
            "Trainable params: 263,462\n",
            "Non-trainable params: 82\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 24ms/step - loss: 0.5811 - accuracy: 0.1396 - val_loss: 0.4965 - val_accuracy: 0.1319\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.4966 - accuracy: 0.1376 - val_loss: 0.4588 - val_accuracy: 0.1331\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.4861 - accuracy: 0.1557 - val_loss: 0.4403 - val_accuracy: 0.2093\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.4657 - accuracy: 0.1969 - val_loss: 0.4552 - val_accuracy: 0.2673\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.4239 - accuracy: 0.2499 - val_loss: 0.3709 - val_accuracy: 0.2608\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.4090 - accuracy: 0.2429 - val_loss: 0.3668 - val_accuracy: 0.2433\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3947 - accuracy: 0.2304 - val_loss: 0.3304 - val_accuracy: 0.2420\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3251 - accuracy: 0.2455 - val_loss: 0.2973 - val_accuracy: 0.2528\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3083 - accuracy: 0.2523 - val_loss: 0.3135 - val_accuracy: 0.2381\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3030 - accuracy: 0.2512 - val_loss: 0.3079 - val_accuracy: 0.2421\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.2993 - accuracy: 0.2510 - val_loss: 0.3141 - val_accuracy: 0.2537\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.2962 - accuracy: 0.2496 - val_loss: 0.2848 - val_accuracy: 0.2406\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.2929 - accuracy: 0.2494 - val_loss: 0.2889 - val_accuracy: 0.2392\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.2925 - accuracy: 0.2493 - val_loss: 0.2850 - val_accuracy: 0.2447\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.2902 - accuracy: 0.2495 - val_loss: 0.2942 - val_accuracy: 0.2261\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2942 - accuracy: 0.2261\n",
            "sklearn_accuracy: 0.3760625\n",
            "\n",
            "(main) 10' population has been evaluated\n",
            "best individual: [[3, 6, 4, 2, 1, 2, 10, 6, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.19, 13, 0.06, 15, 0.09]]\n",
            "statistics: {'min': 0.03125, 'max': 0.7258125, 'average': 0.40678125}\n",
            "(main) 11' population initialized\n",
            "[3, 6, 4, 2, 1, 2, 10, 6, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.19, 13, 0.06, 15, 0.09]\n",
            "[3, 6, 4, 2, 1, 1, 10, 3, 2, 1, 1, 3, 4, 4, 1, 1, 17, 4, 3, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.16, 13, 0.09, 15, 0.23]\n",
            "[5, 14, 5, 5, 2, 2, 4, 2, 3, 1, 1, 14, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 20, 0.21, 11, 0.13, 23, 0.15]\n",
            "[3, 12, 4, 7, 1, 2, 2, 4, 6, 2, 1, 4, 4, 3, 1, 1, 17, 3, 4, 2, 1, 12, 4, 2, 1, 2, 2, 15, 0.25, 13, 0.09, 16, 0.09]\n",
            "[5, 6, 4, 2, 1, 2, 15, 6, 2, 1, 1, 5, 4, 6, 1, 1, 17, 4, 4, 2, 2, 6, 5, 7, 2, 1, 1, 19, 0.19, 13, 0.12, 15, 0.09]\n",
            "[4, 11, 6, 6, 2, 1, 3, 4, 5, 2, 1, 5, 2, 5, 1, 2, 23, 6, 4, 1, 1, 16, 4, 3, 1, 2, 1, 21, 0.17, 14, 0.1, 17, 0.1]\n",
            "[5, 12, 4, 5, 2, 1, 6, 5, 4, 2, 2, 8, 2, 5, 2, 2, 17, 4, 6, 2, 2, 6, 6, 2, 2, 2, 3, 15, 0.31, 13, 0.09, 15, 0.15]\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n",
            "\n",
            " - GENERATION 11\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 4, 2, 1, 2, 10, 6, 2, 1, 1, 3, 4, 4, 1, 2, 17, 4, 4, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.19, 13, 0.06, 15, 0.09]\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_191 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_191 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_191 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_192 (Conv2D)         (None, 87, 64, 10)        730       \n",
            "                                                                 \n",
            " max_pooling2d_192 (MaxPooli  (None, 87, 64, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_192 (Ba  (None, 87, 64, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_193 (Conv2D)         (None, 87, 64, 3)         483       \n",
            "                                                                 \n",
            " max_pooling2d_193 (MaxPooli  (None, 87, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_193 (Ba  (None, 87, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_80 (Flatten)        (None, 8352)              0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 15)                125295    \n",
            "                                                                 \n",
            " dropout_138 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126,718\n",
            "Trainable params: 126,680\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 16s 20ms/step - loss: 0.4107 - accuracy: 0.2846 - val_loss: 0.2602 - val_accuracy: 0.3262\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.2403 - accuracy: 0.4060 - val_loss: 0.2620 - val_accuracy: 0.3938\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1891 - accuracy: 0.4525 - val_loss: 0.2215 - val_accuracy: 0.4863\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1741 - accuracy: 0.4616 - val_loss: 0.2271 - val_accuracy: 0.4502\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1637 - accuracy: 0.4735 - val_loss: 0.2995 - val_accuracy: 0.3960\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1580 - accuracy: 0.4779 - val_loss: 0.3014 - val_accuracy: 0.4399\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1553 - accuracy: 0.4815 - val_loss: 0.2721 - val_accuracy: 0.4255\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1525 - accuracy: 0.4845 - val_loss: 0.2875 - val_accuracy: 0.4674\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1427 - accuracy: 0.4877 - val_loss: 0.3054 - val_accuracy: 0.4424\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1381 - accuracy: 0.4930 - val_loss: 0.2507 - val_accuracy: 0.4486\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1320 - accuracy: 0.4935 - val_loss: 0.3353 - val_accuracy: 0.4241\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1297 - accuracy: 0.4996 - val_loss: 0.2543 - val_accuracy: 0.4787\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1279 - accuracy: 0.5040 - val_loss: 0.2980 - val_accuracy: 0.5352\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1231 - accuracy: 0.5061 - val_loss: 0.3426 - val_accuracy: 0.4594\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 14s 19ms/step - loss: 0.1215 - accuracy: 0.5127 - val_loss: 0.3249 - val_accuracy: 0.4687\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3249 - accuracy: 0.4687\n",
            "sklearn_accuracy: 0.695375\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 4, 2, 1, 1, 10, 3, 2, 1, 1, 3, 4, 4, 1, 1, 17, 4, 3, 2, 2, 6, 5, 2, 2, 2, 1, 15, 0.16, 13, 0.09, 15, 0.23]\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_194 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_194 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_194 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_195 (Conv2D)         (None, 87, 128, 10)       370       \n",
            "                                                                 \n",
            " max_pooling2d_195 (MaxPooli  (None, 87, 128, 10)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_195 (Ba  (None, 87, 128, 10)      40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_196 (Conv2D)         (None, 87, 128, 3)        483       \n",
            "                                                                 \n",
            " max_pooling2d_196 (MaxPooli  (None, 87, 128, 3)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_196 (Ba  (None, 87, 128, 3)       12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_81 (Flatten)        (None, 33408)             0         \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 15)                501135    \n",
            "                                                                 \n",
            " dropout_139 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 502,198\n",
            "Trainable params: 502,160\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.6965 - accuracy: 0.1749 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1897 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6931 - accuracy: 0.1251 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6935 - accuracy: 0.2853 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6934 - accuracy: 0.1504 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.2042 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1722 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1573 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1591 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.0855 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.2878 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.0759 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1967 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.2687 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.0692 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 14, 5, 5, 2, 2, 4, 2, 3, 1, 1, 14, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 20, 0.21, 11, 0.13, 23, 0.15]\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_197 (Conv2D)         (None, 87, 128, 14)       364       \n",
            "                                                                 \n",
            " max_pooling2d_197 (MaxPooli  (None, 44, 64, 14)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_197 (Ba  (None, 44, 64, 14)       56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_198 (Conv2D)         (None, 44, 64, 4)         340       \n",
            "                                                                 \n",
            " max_pooling2d_198 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_198 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_199 (Conv2D)         (None, 44, 64, 14)        1582      \n",
            "                                                                 \n",
            " max_pooling2d_199 (MaxPooli  (None, 44, 32, 14)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_199 (Ba  (None, 44, 32, 14)       56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_200 (Conv2D)         (None, 44, 32, 22)        7414      \n",
            "                                                                 \n",
            " max_pooling2d_200 (MaxPooli  (None, 22, 32, 22)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_200 (Ba  (None, 22, 32, 22)       88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_201 (Conv2D)         (None, 22, 32, 8)         1416      \n",
            "                                                                 \n",
            " max_pooling2d_201 (MaxPooli  (None, 22, 32, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_201 (Ba  (None, 22, 32, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_82 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 20)                112660    \n",
            "                                                                 \n",
            " dropout_140 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,129\n",
            "Trainable params: 124,005\n",
            "Non-trainable params: 124\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.3443 - accuracy: 0.3744 - val_loss: 0.2107 - val_accuracy: 0.3216\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.1663 - accuracy: 0.3563 - val_loss: 0.1465 - val_accuracy: 0.3231\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.1167 - accuracy: 0.3305 - val_loss: 0.4302 - val_accuracy: 0.3108\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0895 - accuracy: 0.3260 - val_loss: 0.1101 - val_accuracy: 0.3109\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0774 - accuracy: 0.3229 - val_loss: 0.1443 - val_accuracy: 0.2908\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0712 - accuracy: 0.3217 - val_loss: 0.1790 - val_accuracy: 0.2921\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0680 - accuracy: 0.3188 - val_loss: 0.1069 - val_accuracy: 0.3075\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0646 - accuracy: 0.3231 - val_loss: 0.0987 - val_accuracy: 0.2819\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0575 - accuracy: 0.3179 - val_loss: 0.1286 - val_accuracy: 0.2727\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0501 - accuracy: 0.3140 - val_loss: 0.1112 - val_accuracy: 0.2954\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0473 - accuracy: 0.3115 - val_loss: 0.1632 - val_accuracy: 0.2761\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0458 - accuracy: 0.3119 - val_loss: 0.2266 - val_accuracy: 0.2959\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0452 - accuracy: 0.3072 - val_loss: 0.0878 - val_accuracy: 0.3133\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0423 - accuracy: 0.3089 - val_loss: 0.1719 - val_accuracy: 0.2944\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 18ms/step - loss: 0.0387 - accuracy: 0.2945 - val_loss: 0.3650 - val_accuracy: 0.2712\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3650 - accuracy: 0.2712\n",
            "sklearn_accuracy: 0.8114375\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 12, 4, 7, 1, 2, 2, 4, 6, 2, 1, 4, 4, 3, 1, 1, 17, 3, 4, 2, 1, 12, 4, 2, 1, 2, 2, 15, 0.25, 13, 0.09, 16, 0.09]\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_202 (Conv2D)         (None, 87, 128, 12)       348       \n",
            "                                                                 \n",
            " max_pooling2d_202 (MaxPooli  (None, 87, 64, 12)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_202 (Ba  (None, 87, 64, 12)       48        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_203 (Conv2D)         (None, 87, 64, 2)         578       \n",
            "                                                                 \n",
            " max_pooling2d_203 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_203 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_204 (Conv2D)         (None, 44, 64, 4)         100       \n",
            "                                                                 \n",
            " max_pooling2d_204 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_204 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_83 (Flatten)        (None, 11264)             0         \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 15)                168975    \n",
            "                                                                 \n",
            " dropout_141 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 13)                208       \n",
            "                                                                 \n",
            " dropout_142 (Dropout)       (None, 13)                0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 5)                 70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 170,351\n",
            "Trainable params: 170,315\n",
            "Non-trainable params: 36\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 14s 18ms/step - loss: 0.5972 - accuracy: 0.1629 - val_loss: 0.4705 - val_accuracy: 0.2525\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.4331 - accuracy: 0.2698 - val_loss: 0.3239 - val_accuracy: 0.2394\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.3608 - accuracy: 0.2511 - val_loss: 0.2778 - val_accuracy: 0.2691\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.3370 - accuracy: 0.2573 - val_loss: 0.2646 - val_accuracy: 0.2629\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.3276 - accuracy: 0.2499 - val_loss: 0.3308 - val_accuracy: 0.2276\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.3172 - accuracy: 0.2533 - val_loss: 0.2615 - val_accuracy: 0.2771\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3118 - accuracy: 0.2518 - val_loss: 0.3062 - val_accuracy: 0.2512\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3070 - accuracy: 0.2530 - val_loss: 0.2984 - val_accuracy: 0.2592\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3036 - accuracy: 0.2450 - val_loss: 0.2490 - val_accuracy: 0.2486\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.2994 - accuracy: 0.2439 - val_loss: 0.3078 - val_accuracy: 0.2495\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.2964 - accuracy: 0.2461 - val_loss: 0.2523 - val_accuracy: 0.2466\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.2953 - accuracy: 0.2456 - val_loss: 0.2646 - val_accuracy: 0.2839\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2897 - accuracy: 0.2450 - val_loss: 0.3230 - val_accuracy: 0.2404\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2874 - accuracy: 0.2495 - val_loss: 0.3249 - val_accuracy: 0.2708\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.2848 - accuracy: 0.2472 - val_loss: 0.2721 - val_accuracy: 0.2540\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2721 - accuracy: 0.2540\n",
            "sklearn_accuracy: 0.624625\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 6, 4, 2, 1, 2, 15, 6, 2, 1, 1, 5, 4, 6, 1, 1, 17, 4, 4, 2, 2, 6, 5, 7, 2, 1, 1, 19, 0.19, 13, 0.12, 15, 0.09]\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_205 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_205 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_205 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_206 (Conv2D)         (None, 87, 64, 15)        1095      \n",
            "                                                                 \n",
            " max_pooling2d_206 (MaxPooli  (None, 87, 64, 15)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_206 (Ba  (None, 87, 64, 15)       60        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_207 (Conv2D)         (None, 87, 64, 5)         1805      \n",
            "                                                                 \n",
            " max_pooling2d_207 (MaxPooli  (None, 87, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_207 (Ba  (None, 87, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_208 (Conv2D)         (None, 87, 64, 17)        1377      \n",
            "                                                                 \n",
            " max_pooling2d_208 (MaxPooli  (None, 44, 32, 17)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_208 (Ba  (None, 44, 32, 17)       68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_209 (Conv2D)         (None, 44, 32, 6)         3576      \n",
            "                                                                 \n",
            " max_pooling2d_209 (MaxPooli  (None, 22, 32, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_209 (Ba  (None, 22, 32, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_84 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 19)                80275     \n",
            "                                                                 \n",
            " dropout_143 (Dropout)       (None, 19)                0         \n",
            "                                                                 \n",
            " dense_228 (Dense)           (None, 5)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88,478\n",
            "Trainable params: 88,380\n",
            "Non-trainable params: 98\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.3844 - accuracy: 0.2776 - val_loss: 0.2085 - val_accuracy: 0.4684\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.1549 - accuracy: 0.4812 - val_loss: 0.2730 - val_accuracy: 0.4457\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.1125 - accuracy: 0.5791 - val_loss: 0.0843 - val_accuracy: 0.5690\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0975 - accuracy: 0.6130 - val_loss: 0.1421 - val_accuracy: 0.7584\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0871 - accuracy: 0.6319 - val_loss: 0.1375 - val_accuracy: 0.6742\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0728 - accuracy: 0.6585 - val_loss: 0.0955 - val_accuracy: 0.6964\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0655 - accuracy: 0.6776 - val_loss: 0.0974 - val_accuracy: 0.6848\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0597 - accuracy: 0.6906 - val_loss: 0.1032 - val_accuracy: 0.6848\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0582 - accuracy: 0.6987 - val_loss: 0.5312 - val_accuracy: 0.7141\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0548 - accuracy: 0.7023 - val_loss: 0.1071 - val_accuracy: 0.6848\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0506 - accuracy: 0.7054 - val_loss: 0.3764 - val_accuracy: 0.6994\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0523 - accuracy: 0.7059 - val_loss: 0.2205 - val_accuracy: 0.6883\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0506 - accuracy: 0.7094 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0474 - accuracy: 0.7121 - val_loss: 0.0977 - val_accuracy: 0.6391\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.0469 - accuracy: 0.7185 - val_loss: 0.1963 - val_accuracy: 0.6856\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1963 - accuracy: 0.6856\n",
            "sklearn_accuracy: 0.8236875\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 11, 6, 6, 2, 1, 3, 4, 5, 2, 1, 5, 2, 5, 1, 2, 23, 6, 4, 1, 1, 16, 4, 3, 1, 2, 1, 21, 0.17, 14, 0.1, 17, 0.1]\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_210 (Conv2D)         (None, 87, 128, 11)       407       \n",
            "                                                                 \n",
            " max_pooling2d_210 (MaxPooli  (None, 44, 128, 11)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_210 (Ba  (None, 44, 128, 11)      44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_211 (Conv2D)         (None, 44, 128, 3)        663       \n",
            "                                                                 \n",
            " max_pooling2d_211 (MaxPooli  (None, 22, 128, 3)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_211 (Ba  (None, 22, 128, 3)       12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_212 (Conv2D)         (None, 22, 128, 5)        155       \n",
            "                                                                 \n",
            " max_pooling2d_212 (MaxPooli  (None, 22, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_212 (Ba  (None, 22, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_213 (Conv2D)         (None, 22, 64, 23)        2783      \n",
            "                                                                 \n",
            " max_pooling2d_213 (MaxPooli  (None, 22, 64, 23)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_213 (Ba  (None, 22, 64, 23)       92        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_85 (Flatten)        (None, 32384)             0         \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 21)                680085    \n",
            "                                                                 \n",
            " dropout_144 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 684,371\n",
            "Trainable params: 684,287\n",
            "Non-trainable params: 84\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 21s 26ms/step - loss: 0.5976 - accuracy: 0.1343 - val_loss: 0.5523 - val_accuracy: 0.1805\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5534 - accuracy: 0.1705 - val_loss: 0.5350 - val_accuracy: 0.1641\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5396 - accuracy: 0.1912 - val_loss: 0.5275 - val_accuracy: 0.2401\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5300 - accuracy: 0.2061 - val_loss: 0.4911 - val_accuracy: 0.2253\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5265 - accuracy: 0.2241 - val_loss: 0.4987 - val_accuracy: 0.2576\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5240 - accuracy: 0.2254 - val_loss: 0.4912 - val_accuracy: 0.2068\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5240 - accuracy: 0.2187 - val_loss: 0.5002 - val_accuracy: 0.2336\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5187 - accuracy: 0.2213 - val_loss: 0.4824 - val_accuracy: 0.2092\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5171 - accuracy: 0.2270 - val_loss: 0.4774 - val_accuracy: 0.2305\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5133 - accuracy: 0.2305 - val_loss: 0.4887 - val_accuracy: 0.2878\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5165 - accuracy: 0.2330 - val_loss: 0.4775 - val_accuracy: 0.2339\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5133 - accuracy: 0.2297 - val_loss: 0.4716 - val_accuracy: 0.1988\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5134 - accuracy: 0.2276 - val_loss: 0.4694 - val_accuracy: 0.3056\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5121 - accuracy: 0.2244 - val_loss: 0.4671 - val_accuracy: 0.2301\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.5135 - accuracy: 0.2274 - val_loss: 0.4748 - val_accuracy: 0.1939\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4748 - accuracy: 0.1939\n",
            "sklearn_accuracy: 0.122125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 12, 4, 5, 2, 1, 6, 5, 4, 2, 2, 8, 2, 5, 2, 2, 17, 4, 6, 2, 2, 6, 6, 2, 2, 2, 3, 15, 0.31, 13, 0.09, 15, 0.15]\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_214 (Conv2D)         (None, 87, 128, 12)       252       \n",
            "                                                                 \n",
            " max_pooling2d_214 (MaxPooli  (None, 44, 128, 12)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_214 (Ba  (None, 44, 128, 12)      48        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_215 (Conv2D)         (None, 44, 128, 6)        1446      \n",
            "                                                                 \n",
            " max_pooling2d_215 (MaxPooli  (None, 22, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_215 (Ba  (None, 22, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_216 (Conv2D)         (None, 22, 64, 8)         488       \n",
            "                                                                 \n",
            " max_pooling2d_216 (MaxPooli  (None, 11, 32, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_216 (Ba  (None, 11, 32, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_217 (Conv2D)         (None, 11, 32, 17)        3281      \n",
            "                                                                 \n",
            " max_pooling2d_217 (MaxPooli  (None, 6, 16, 17)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_217 (Ba  (None, 6, 16, 17)        68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_218 (Conv2D)         (None, 6, 16, 6)          1230      \n",
            "                                                                 \n",
            " max_pooling2d_218 (MaxPooli  (None, 3, 8, 6)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_218 (Ba  (None, 3, 8, 6)          24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_86 (Flatten)        (None, 144)               0         \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 15)                2175      \n",
            "                                                                 \n",
            " dropout_145 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_232 (Dense)           (None, 13)                208       \n",
            "                                                                 \n",
            " dropout_146 (Dropout)       (None, 13)                0         \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 15)                210       \n",
            "                                                                 \n",
            " dropout_147 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,566\n",
            "Trainable params: 9,468\n",
            "Non-trainable params: 98\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 24ms/step - loss: 0.5728 - accuracy: 0.1489 - val_loss: 0.4974 - val_accuracy: 0.0964\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.4688 - accuracy: 0.1381 - val_loss: 0.4409 - val_accuracy: 0.1053\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.4260 - accuracy: 0.2178 - val_loss: 0.4259 - val_accuracy: 0.3288\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3778 - accuracy: 0.3835 - val_loss: 0.3564 - val_accuracy: 0.3506\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3556 - accuracy: 0.4500 - val_loss: 0.3285 - val_accuracy: 0.5474\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3479 - accuracy: 0.4844 - val_loss: 0.4277 - val_accuracy: 0.3630\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.3403 - accuracy: 0.4967 - val_loss: 0.3616 - val_accuracy: 0.5714\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.3386 - accuracy: 0.5033 - val_loss: 0.3461 - val_accuracy: 0.5822\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.3333 - accuracy: 0.5057 - val_loss: 0.3667 - val_accuracy: 0.5829\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.3313 - accuracy: 0.5058 - val_loss: 0.3550 - val_accuracy: 0.6044\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.3289 - accuracy: 0.5136 - val_loss: 0.3261 - val_accuracy: 0.5707\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 18s 25ms/step - loss: 0.3268 - accuracy: 0.5107 - val_loss: 0.3829 - val_accuracy: 0.5892\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3248 - accuracy: 0.5215 - val_loss: 0.4839 - val_accuracy: 0.5203\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3213 - accuracy: 0.5247 - val_loss: 0.4007 - val_accuracy: 0.5974\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.3197 - accuracy: 0.5259 - val_loss: 0.3484 - val_accuracy: 0.5848\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3484 - accuracy: 0.5848\n",
            "sklearn_accuracy: 0.2338125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_219 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_219 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_219 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_220 (Conv2D)         (None, 87, 128, 19)       2071      \n",
            "                                                                 \n",
            " max_pooling2d_220 (MaxPooli  (None, 87, 128, 19)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_220 (Ba  (None, 87, 128, 19)      76        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_221 (Conv2D)         (None, 87, 128, 9)        4797      \n",
            "                                                                 \n",
            " max_pooling2d_221 (MaxPooli  (None, 87, 64, 9)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_221 (Ba  (None, 87, 64, 9)        36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_222 (Conv2D)         (None, 87, 64, 22)        4774      \n",
            "                                                                 \n",
            " max_pooling2d_222 (MaxPooli  (None, 44, 64, 22)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_222 (Ba  (None, 44, 64, 22)       88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_223 (Conv2D)         (None, 44, 64, 8)         1416      \n",
            "                                                                 \n",
            " max_pooling2d_223 (MaxPooli  (None, 44, 64, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_223 (Ba  (None, 44, 64, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_87 (Flatten)        (None, 22528)             0         \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 21)                473109    \n",
            "                                                                 \n",
            " dropout_148 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_236 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 486,587\n",
            "Trainable params: 486,459\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 46s 60ms/step - loss: 0.4311 - accuracy: 0.3051 - val_loss: 0.2830 - val_accuracy: 0.4804\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.2263 - accuracy: 0.4491 - val_loss: 0.1462 - val_accuracy: 0.4241\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1992 - accuracy: 0.4281 - val_loss: 0.1527 - val_accuracy: 0.3887\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1409 - accuracy: 0.4526 - val_loss: 0.1052 - val_accuracy: 0.4913\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1136 - accuracy: 0.4878 - val_loss: 0.0927 - val_accuracy: 0.4835\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1069 - accuracy: 0.4914 - val_loss: 0.1554 - val_accuracy: 0.5307\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1063 - accuracy: 0.4943 - val_loss: 0.1273 - val_accuracy: 0.5116\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0990 - accuracy: 0.4979 - val_loss: 0.1544 - val_accuracy: 0.5409\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0987 - accuracy: 0.5015 - val_loss: 0.1220 - val_accuracy: 0.4901\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0990 - accuracy: 0.5006 - val_loss: 0.1409 - val_accuracy: 0.5563\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0911 - accuracy: 0.5063 - val_loss: 0.1161 - val_accuracy: 0.5121\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0844 - accuracy: 0.4979 - val_loss: 0.1200 - val_accuracy: 0.5188\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0831 - accuracy: 0.5023 - val_loss: 0.1256 - val_accuracy: 0.5167\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0813 - accuracy: 0.4980 - val_loss: 0.0984 - val_accuracy: 0.4657\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0800 - accuracy: 0.4983 - val_loss: 0.0824 - val_accuracy: 0.5022\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0824 - accuracy: 0.5022\n",
            "sklearn_accuracy: 0.905\n",
            "\n",
            "(main) 11' population has been evaluated\n",
            "best individual: [[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]]\n",
            "statistics: {'min': 0.03125, 'max': 0.905, 'average': 0.5309140625}\n",
            "(main) 12' population initialized\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n",
            "[3, 6, 5, 2, 1, 2, 10, 6, 2, 2, 1, 3, 4, 4, 1, 2, 17, 4, 6, 2, 2, 6, 5, 2, 1, 1, 2, 25, 0.18, 6, 0.14, 12, 0.29]\n",
            "[5, 26, 6, 5, 2, 2, 4, 5, 3, 1, 2, 14, 4, 7, 1, 2, 24, 3, 6, 1, 1, 8, 2, 3, 1, 1, 1, 20, 0.21, 11, 0.13, 28, 0.15]\n",
            "[5, 11, 4, 2, 1, 2, 20, 6, 2, 1, 1, 5, 4, 6, 2, 1, 17, 2, 6, 2, 2, 12, 4, 2, 1, 2, 2, 15, 0.25, 18, 0.09, 16, 0.09]\n",
            "[3, 12, 6, 2, 1, 2, 2, 4, 6, 2, 1, 4, 4, 6, 1, 2, 17, 3, 4, 2, 1, 12, 4, 2, 1, 2, 2, 15, 0.25, 13, 0.1, 16, 0.09]\n",
            "[3, 6, 4, 2, 2, 2, 10, 6, 6, 1, 1, 3, 7, 4, 1, 1, 17, 5, 4, 1, 2, 19, 4, 4, 2, 2, 1, 21, 0.17, 14, 0.05, 17, 0.1]\n",
            "[5, 26, 6, 5, 2, 2, 4, 5, 3, 1, 2, 14, 4, 7, 1, 2, 24, 3, 6, 1, 1, 8, 2, 3, 1, 1, 1, 20, 0.21, 11, 0.13, 28, 0.15]\n",
            "[5, 6, 4, 2, 1, 2, 15, 2, 7, 1, 1, 5, 4, 6, 1, 1, 17, 4, 4, 2, 1, 9, 4, 3, 1, 2, 1, 22, 0.28, 11, 0.13, 30, 0.07]\n",
            "\n",
            " - GENERATION 12\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_224 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_224 (MaxPooli  (None, 87, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_224 (Ba  (None, 87, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_225 (Conv2D)         (None, 87, 128, 19)       2071      \n",
            "                                                                 \n",
            " max_pooling2d_225 (MaxPooli  (None, 87, 128, 19)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_225 (Ba  (None, 87, 128, 19)      76        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_226 (Conv2D)         (None, 87, 128, 9)        4797      \n",
            "                                                                 \n",
            " max_pooling2d_226 (MaxPooli  (None, 87, 64, 9)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_226 (Ba  (None, 87, 64, 9)        36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_227 (Conv2D)         (None, 87, 64, 22)        4774      \n",
            "                                                                 \n",
            " max_pooling2d_227 (MaxPooli  (None, 44, 64, 22)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_227 (Ba  (None, 44, 64, 22)       88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_228 (Conv2D)         (None, 44, 64, 8)         1416      \n",
            "                                                                 \n",
            " max_pooling2d_228 (MaxPooli  (None, 44, 64, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_228 (Ba  (None, 44, 64, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_88 (Flatten)        (None, 22528)             0         \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 21)                473109    \n",
            "                                                                 \n",
            " dropout_149 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 486,587\n",
            "Trainable params: 486,459\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 46s 60ms/step - loss: 0.5627 - accuracy: 0.2650 - val_loss: 0.4861 - val_accuracy: 0.2371\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.4947 - accuracy: 0.2467 - val_loss: 0.4765 - val_accuracy: 0.3003\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.4239 - accuracy: 0.2943 - val_loss: 0.3124 - val_accuracy: 0.3765\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.3651 - accuracy: 0.3454 - val_loss: 0.3048 - val_accuracy: 0.4303\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.2411 - accuracy: 0.3679 - val_loss: 0.1515 - val_accuracy: 0.5500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1797 - accuracy: 0.5065 - val_loss: 0.1450 - val_accuracy: 0.4701\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1595 - accuracy: 0.6148 - val_loss: 0.1044 - val_accuracy: 0.6659\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1515 - accuracy: 0.6170 - val_loss: 0.1335 - val_accuracy: 0.6712\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1492 - accuracy: 0.6185 - val_loss: 0.1172 - val_accuracy: 0.6749\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1462 - accuracy: 0.6302 - val_loss: 0.1072 - val_accuracy: 0.7218\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1470 - accuracy: 0.6205 - val_loss: 0.1271 - val_accuracy: 0.5073\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1427 - accuracy: 0.6345 - val_loss: 0.1429 - val_accuracy: 0.6505\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1274 - accuracy: 0.6919 - val_loss: 0.0968 - val_accuracy: 0.8037\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.1183 - accuracy: 0.7329 - val_loss: 0.1680 - val_accuracy: 0.8391\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.1084 - accuracy: 0.6877 - val_loss: 0.1047 - val_accuracy: 0.6992\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.1047 - accuracy: 0.6992\n",
            "sklearn_accuracy: 0.9046875\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 5, 2, 1, 2, 10, 6, 2, 2, 1, 3, 4, 4, 1, 2, 17, 4, 6, 2, 2, 6, 5, 2, 1, 1, 2, 25, 0.18, 6, 0.14, 12, 0.29]\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_229 (Conv2D)         (None, 87, 128, 6)        66        \n",
            "                                                                 \n",
            " max_pooling2d_229 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_229 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_230 (Conv2D)         (None, 87, 64, 10)        730       \n",
            "                                                                 \n",
            " max_pooling2d_230 (MaxPooli  (None, 44, 64, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_230 (Ba  (None, 44, 64, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_231 (Conv2D)         (None, 44, 64, 3)         483       \n",
            "                                                                 \n",
            " max_pooling2d_231 (MaxPooli  (None, 44, 32, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_231 (Ba  (None, 44, 32, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_89 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 25)                105625    \n",
            "                                                                 \n",
            " dropout_150 (Dropout)       (None, 25)                0         \n",
            "                                                                 \n",
            " dense_240 (Dense)           (None, 6)                 156       \n",
            "                                                                 \n",
            " dropout_151 (Dropout)       (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_241 (Dense)           (None, 5)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,171\n",
            "Trainable params: 107,133\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.5228 - accuracy: 0.2234 - val_loss: 0.3752 - val_accuracy: 0.2278\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.3686 - accuracy: 0.2506 - val_loss: 0.2795 - val_accuracy: 0.2901\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.3145 - accuracy: 0.3176 - val_loss: 0.2380 - val_accuracy: 0.3486\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2865 - accuracy: 0.3601 - val_loss: 0.2433 - val_accuracy: 0.3576\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2659 - accuracy: 0.3620 - val_loss: 0.2563 - val_accuracy: 0.3467\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2581 - accuracy: 0.3640 - val_loss: 0.1950 - val_accuracy: 0.3819\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2492 - accuracy: 0.3709 - val_loss: 0.1933 - val_accuracy: 0.3716\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2378 - accuracy: 0.3741 - val_loss: 0.2361 - val_accuracy: 0.3638\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2339 - accuracy: 0.3772 - val_loss: 0.2533 - val_accuracy: 0.3570\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2310 - accuracy: 0.3697 - val_loss: 0.2040 - val_accuracy: 0.3919\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2213 - accuracy: 0.3718 - val_loss: 0.2314 - val_accuracy: 0.3932\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2151 - accuracy: 0.3719 - val_loss: 0.1848 - val_accuracy: 0.3869\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2117 - accuracy: 0.3671 - val_loss: 0.2009 - val_accuracy: 0.4095\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2113 - accuracy: 0.3677 - val_loss: 0.1555 - val_accuracy: 0.3984\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.2076 - accuracy: 0.3692 - val_loss: 0.2102 - val_accuracy: 0.3748\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2102 - accuracy: 0.3748\n",
            "sklearn_accuracy: 0.7305625\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 26, 6, 5, 2, 2, 4, 5, 3, 1, 2, 14, 4, 7, 1, 2, 24, 3, 6, 1, 1, 8, 2, 3, 1, 1, 1, 20, 0.21, 11, 0.13, 28, 0.15]\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_232 (Conv2D)         (None, 87, 128, 26)       806       \n",
            "                                                                 \n",
            " max_pooling2d_232 (MaxPooli  (None, 44, 64, 26)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_232 (Ba  (None, 44, 64, 26)       104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_233 (Conv2D)         (None, 44, 64, 4)         1564      \n",
            "                                                                 \n",
            " max_pooling2d_233 (MaxPooli  (None, 44, 32, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_233 (Ba  (None, 44, 32, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_234 (Conv2D)         (None, 44, 32, 14)        1582      \n",
            "                                                                 \n",
            " max_pooling2d_234 (MaxPooli  (None, 44, 16, 14)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_234 (Ba  (None, 44, 16, 14)       56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_235 (Conv2D)         (None, 44, 16, 24)        6072      \n",
            "                                                                 \n",
            " max_pooling2d_235 (MaxPooli  (None, 44, 16, 24)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_235 (Ba  (None, 44, 16, 24)       96        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_236 (Conv2D)         (None, 44, 16, 8)         1160      \n",
            "                                                                 \n",
            " max_pooling2d_236 (MaxPooli  (None, 44, 16, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_236 (Ba  (None, 44, 16, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_90 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_242 (Dense)           (None, 20)                112660    \n",
            "                                                                 \n",
            " dropout_152 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_243 (Dense)           (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,253\n",
            "Trainable params: 124,101\n",
            "Non-trainable params: 152\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.3766 - accuracy: 0.3337 - val_loss: 0.2279 - val_accuracy: 0.4018\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1659 - accuracy: 0.5476 - val_loss: 0.1159 - val_accuracy: 0.6607\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1056 - accuracy: 0.6027 - val_loss: 0.1688 - val_accuracy: 0.6579\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0804 - accuracy: 0.5984 - val_loss: 0.1248 - val_accuracy: 0.6121\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0685 - accuracy: 0.5944 - val_loss: 0.1279 - val_accuracy: 0.5866\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0631 - accuracy: 0.5969 - val_loss: 0.1980 - val_accuracy: 0.6435\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0572 - accuracy: 0.6119 - val_loss: 0.1815 - val_accuracy: 0.5122\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0563 - accuracy: 0.6130 - val_loss: 0.1276 - val_accuracy: 0.5709\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0549 - accuracy: 0.6091 - val_loss: 0.2591 - val_accuracy: 0.6557\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0495 - accuracy: 0.6180 - val_loss: 0.2475 - val_accuracy: 0.5779\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0470 - accuracy: 0.6264 - val_loss: 0.1515 - val_accuracy: 0.6233\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0442 - accuracy: 0.6292 - val_loss: 0.1368 - val_accuracy: 0.5907\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0417 - accuracy: 0.6442 - val_loss: 0.1890 - val_accuracy: 0.6521\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0401 - accuracy: 0.6643 - val_loss: 0.3126 - val_accuracy: 0.6602\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0383 - accuracy: 0.6525 - val_loss: 0.2503 - val_accuracy: 0.6957\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.2503 - accuracy: 0.6957\n",
            "sklearn_accuracy: 0.8214375\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 11, 4, 2, 1, 2, 20, 6, 2, 1, 1, 5, 4, 6, 2, 1, 17, 2, 6, 2, 2, 12, 4, 2, 1, 2, 2, 15, 0.25, 18, 0.09, 16, 0.09]\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_237 (Conv2D)         (None, 87, 128, 11)       99        \n",
            "                                                                 \n",
            " max_pooling2d_237 (MaxPooli  (None, 87, 64, 11)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_237 (Ba  (None, 87, 64, 11)       44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_238 (Conv2D)         (None, 87, 64, 20)        2660      \n",
            "                                                                 \n",
            " max_pooling2d_238 (MaxPooli  (None, 87, 64, 20)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_238 (Ba  (None, 87, 64, 20)       80        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_239 (Conv2D)         (None, 87, 64, 5)         2405      \n",
            "                                                                 \n",
            " max_pooling2d_239 (MaxPooli  (None, 44, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_239 (Ba  (None, 44, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_240 (Conv2D)         (None, 44, 64, 17)        1037      \n",
            "                                                                 \n",
            " max_pooling2d_240 (MaxPooli  (None, 22, 32, 17)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_240 (Ba  (None, 22, 32, 17)       68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_241 (Conv2D)         (None, 22, 32, 12)        1644      \n",
            "                                                                 \n",
            " max_pooling2d_241 (MaxPooli  (None, 22, 16, 12)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_241 (Ba  (None, 22, 16, 12)       48        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_91 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_244 (Dense)           (None, 15)                63375     \n",
            "                                                                 \n",
            " dropout_153 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_245 (Dense)           (None, 18)                288       \n",
            "                                                                 \n",
            " dropout_154 (Dropout)       (None, 18)                0         \n",
            "                                                                 \n",
            " dense_246 (Dense)           (None, 5)                 95        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71,863\n",
            "Trainable params: 71,733\n",
            "Non-trainable params: 130\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.4751 - accuracy: 0.2465 - val_loss: 0.3159 - val_accuracy: 0.3694\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2862 - accuracy: 0.3856 - val_loss: 0.1701 - val_accuracy: 0.4199\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2074 - accuracy: 0.4556 - val_loss: 0.1449 - val_accuracy: 0.4406\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1693 - accuracy: 0.5031 - val_loss: 0.1365 - val_accuracy: 0.3705\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1490 - accuracy: 0.5147 - val_loss: 0.1255 - val_accuracy: 0.4276\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.1393 - accuracy: 0.5238 - val_loss: 0.0809 - val_accuracy: 0.4734\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1213 - accuracy: 0.5364 - val_loss: 0.5400 - val_accuracy: 0.6313\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1112 - accuracy: 0.5369 - val_loss: 0.0849 - val_accuracy: 0.5061\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.1091 - accuracy: 0.5390 - val_loss: 0.0914 - val_accuracy: 0.5915\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.1038 - accuracy: 0.5402 - val_loss: 0.1225 - val_accuracy: 0.5054\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.1024 - accuracy: 0.5350 - val_loss: 0.1011 - val_accuracy: 0.5491\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1000 - accuracy: 0.5278 - val_loss: 0.1004 - val_accuracy: 0.4219\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0980 - accuracy: 0.5208 - val_loss: 0.0860 - val_accuracy: 0.4723\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0940 - accuracy: 0.5169 - val_loss: 0.2147 - val_accuracy: 0.6100\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0929 - accuracy: 0.5094 - val_loss: 0.1263 - val_accuracy: 0.5026\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.5026\n",
            "sklearn_accuracy: 0.865375\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 12, 6, 2, 1, 2, 2, 4, 6, 2, 1, 4, 4, 6, 1, 2, 17, 3, 4, 2, 1, 12, 4, 2, 1, 2, 2, 15, 0.25, 13, 0.1, 16, 0.09]\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_242 (Conv2D)         (None, 87, 128, 12)       156       \n",
            "                                                                 \n",
            " max_pooling2d_242 (MaxPooli  (None, 87, 64, 12)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_242 (Ba  (None, 87, 64, 12)       48        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_243 (Conv2D)         (None, 87, 64, 2)         578       \n",
            "                                                                 \n",
            " max_pooling2d_243 (MaxPooli  (None, 44, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_243 (Ba  (None, 44, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_244 (Conv2D)         (None, 44, 64, 4)         196       \n",
            "                                                                 \n",
            " max_pooling2d_244 (MaxPooli  (None, 44, 32, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_244 (Ba  (None, 44, 32, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_92 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_247 (Dense)           (None, 15)                84495     \n",
            "                                                                 \n",
            " dropout_155 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_248 (Dense)           (None, 13)                208       \n",
            "                                                                 \n",
            " dropout_156 (Dropout)       (None, 13)                0         \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 5)                 70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,775\n",
            "Trainable params: 85,739\n",
            "Non-trainable params: 36\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 24ms/step - loss: 0.5993 - accuracy: 0.1715 - val_loss: 0.4786 - val_accuracy: 0.1708\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.4909 - accuracy: 0.2035 - val_loss: 0.3941 - val_accuracy: 0.1908\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.4221 - accuracy: 0.2254 - val_loss: 0.3628 - val_accuracy: 0.2235\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3989 - accuracy: 0.2430 - val_loss: 0.3298 - val_accuracy: 0.2425\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3878 - accuracy: 0.2536 - val_loss: 0.3521 - val_accuracy: 0.2556\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3810 - accuracy: 0.2616 - val_loss: 0.3519 - val_accuracy: 0.2680\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3712 - accuracy: 0.2740 - val_loss: 0.3259 - val_accuracy: 0.2772\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3644 - accuracy: 0.2886 - val_loss: 0.3353 - val_accuracy: 0.3438\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3571 - accuracy: 0.2980 - val_loss: 0.3382 - val_accuracy: 0.3823\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3525 - accuracy: 0.3032 - val_loss: 0.3047 - val_accuracy: 0.3140\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3458 - accuracy: 0.3097 - val_loss: 0.3103 - val_accuracy: 0.3296\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3433 - accuracy: 0.3168 - val_loss: 0.3026 - val_accuracy: 0.3302\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3378 - accuracy: 0.3227 - val_loss: 0.2992 - val_accuracy: 0.3361\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3385 - accuracy: 0.3237 - val_loss: 0.3161 - val_accuracy: 0.3284\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.3346 - accuracy: 0.3254 - val_loss: 0.3131 - val_accuracy: 0.3414\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3131 - accuracy: 0.3414\n",
            "sklearn_accuracy: 0.431125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 4, 2, 2, 2, 10, 6, 6, 1, 1, 3, 7, 4, 1, 1, 17, 5, 4, 1, 2, 19, 4, 4, 2, 2, 1, 21, 0.17, 14, 0.05, 17, 0.1]\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_245 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_245 (MaxPooli  (None, 44, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_245 (Ba  (None, 44, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_246 (Conv2D)         (None, 44, 64, 10)        2170      \n",
            "                                                                 \n",
            " max_pooling2d_246 (MaxPooli  (None, 44, 64, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_246 (Ba  (None, 44, 64, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_247 (Conv2D)         (None, 44, 64, 3)         843       \n",
            "                                                                 \n",
            " max_pooling2d_247 (MaxPooli  (None, 44, 64, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_247 (Ba  (None, 44, 64, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_93 (Flatten)        (None, 8448)              0         \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 21)                177429    \n",
            "                                                                 \n",
            " dropout_157 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,682\n",
            "Trainable params: 180,644\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.3487 - accuracy: 0.2674 - val_loss: 0.1896 - val_accuracy: 0.3721\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.1405 - accuracy: 0.3451 - val_loss: 0.1373 - val_accuracy: 0.2946\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0915 - accuracy: 0.3543 - val_loss: 0.2071 - val_accuracy: 0.3503\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0777 - accuracy: 0.3433 - val_loss: 0.2160 - val_accuracy: 0.3605\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0609 - accuracy: 0.3546 - val_loss: 0.1708 - val_accuracy: 0.4052\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0540 - accuracy: 0.3702 - val_loss: 0.9203 - val_accuracy: 0.3828\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0511 - accuracy: 0.3788 - val_loss: 0.1854 - val_accuracy: 0.4579\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0497 - accuracy: 0.3760 - val_loss: 0.1885 - val_accuracy: 0.4018\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0471 - accuracy: 0.3860 - val_loss: 0.2136 - val_accuracy: 0.3811\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0457 - accuracy: 0.3881 - val_loss: 0.2355 - val_accuracy: 0.3772\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0453 - accuracy: 0.3933 - val_loss: 0.2825 - val_accuracy: 0.4080\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0459 - accuracy: 0.4006 - val_loss: 0.2017 - val_accuracy: 0.4224\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0413 - accuracy: 0.3954 - val_loss: 0.3496 - val_accuracy: 0.4326\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0406 - accuracy: 0.3808 - val_loss: 0.2337 - val_accuracy: 0.2949\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 16ms/step - loss: 0.0398 - accuracy: 0.3955 - val_loss: 0.2911 - val_accuracy: 0.4688\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2911 - accuracy: 0.4688\n",
            "sklearn_accuracy: 0.7840625\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 26, 6, 5, 2, 2, 4, 5, 3, 1, 2, 14, 4, 7, 1, 2, 24, 3, 6, 1, 1, 8, 2, 3, 1, 1, 1, 20, 0.21, 11, 0.13, 28, 0.15]\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_248 (Conv2D)         (None, 87, 128, 26)       806       \n",
            "                                                                 \n",
            " max_pooling2d_248 (MaxPooli  (None, 44, 64, 26)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_248 (Ba  (None, 44, 64, 26)       104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_249 (Conv2D)         (None, 44, 64, 4)         1564      \n",
            "                                                                 \n",
            " max_pooling2d_249 (MaxPooli  (None, 44, 32, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_249 (Ba  (None, 44, 32, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_250 (Conv2D)         (None, 44, 32, 14)        1582      \n",
            "                                                                 \n",
            " max_pooling2d_250 (MaxPooli  (None, 44, 16, 14)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_250 (Ba  (None, 44, 16, 14)       56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_251 (Conv2D)         (None, 44, 16, 24)        6072      \n",
            "                                                                 \n",
            " max_pooling2d_251 (MaxPooli  (None, 44, 16, 24)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_251 (Ba  (None, 44, 16, 24)       96        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_252 (Conv2D)         (None, 44, 16, 8)         1160      \n",
            "                                                                 \n",
            " max_pooling2d_252 (MaxPooli  (None, 44, 16, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_252 (Ba  (None, 44, 16, 8)        32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_94 (Flatten)        (None, 5632)              0         \n",
            "                                                                 \n",
            " dense_252 (Dense)           (None, 20)                112660    \n",
            "                                                                 \n",
            " dropout_158 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_253 (Dense)           (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,253\n",
            "Trainable params: 124,101\n",
            "Non-trainable params: 152\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.5032 - accuracy: 0.3637 - val_loss: 0.2688 - val_accuracy: 0.3954\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2324 - accuracy: 0.5384 - val_loss: 0.1448 - val_accuracy: 0.6252\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1622 - accuracy: 0.6459 - val_loss: 0.2656 - val_accuracy: 0.7362\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1194 - accuracy: 0.7050 - val_loss: 0.1879 - val_accuracy: 0.6768\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0945 - accuracy: 0.7306 - val_loss: 0.1903 - val_accuracy: 0.7172\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0808 - accuracy: 0.7453 - val_loss: 0.1238 - val_accuracy: 0.7451\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0641 - accuracy: 0.7655 - val_loss: 0.1286 - val_accuracy: 0.8045\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0588 - accuracy: 0.7738 - val_loss: 0.1180 - val_accuracy: 0.8263\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0553 - accuracy: 0.7786 - val_loss: 0.3070 - val_accuracy: 0.7629\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0475 - accuracy: 0.7825 - val_loss: 0.2185 - val_accuracy: 0.7780\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0483 - accuracy: 0.7856 - val_loss: 0.1365 - val_accuracy: 0.8087\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0441 - accuracy: 0.7903 - val_loss: 0.1301 - val_accuracy: 0.8048\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0433 - accuracy: 0.7963 - val_loss: 0.2831 - val_accuracy: 0.8038\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0421 - accuracy: 0.7964 - val_loss: 0.1317 - val_accuracy: 0.7901\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.0405 - accuracy: 0.7912 - val_loss: 0.1777 - val_accuracy: 0.7319\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.1777 - accuracy: 0.7319\n",
            "sklearn_accuracy: 0.788375\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 6, 4, 2, 1, 2, 15, 2, 7, 1, 1, 5, 4, 6, 1, 1, 17, 4, 4, 2, 1, 9, 4, 3, 1, 2, 1, 22, 0.28, 11, 0.13, 30, 0.07]\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_253 (Conv2D)         (None, 87, 128, 6)        54        \n",
            "                                                                 \n",
            " max_pooling2d_253 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_253 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_254 (Conv2D)         (None, 87, 64, 15)        1275      \n",
            "                                                                 \n",
            " max_pooling2d_254 (MaxPooli  (None, 87, 64, 15)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_254 (Ba  (None, 87, 64, 15)       60        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_255 (Conv2D)         (None, 87, 64, 5)         1805      \n",
            "                                                                 \n",
            " max_pooling2d_255 (MaxPooli  (None, 87, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_255 (Ba  (None, 87, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_256 (Conv2D)         (None, 87, 64, 17)        1377      \n",
            "                                                                 \n",
            " max_pooling2d_256 (MaxPooli  (None, 44, 64, 17)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_256 (Ba  (None, 44, 64, 17)       68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_257 (Conv2D)         (None, 44, 64, 9)         1845      \n",
            "                                                                 \n",
            " max_pooling2d_257 (MaxPooli  (None, 44, 32, 9)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_257 (Ba  (None, 44, 32, 9)        36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_95 (Flatten)        (None, 12672)             0         \n",
            "                                                                 \n",
            " dense_254 (Dense)           (None, 22)                278806    \n",
            "                                                                 \n",
            " dropout_159 (Dropout)       (None, 22)                0         \n",
            "                                                                 \n",
            " dense_255 (Dense)           (None, 5)                 115       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 285,485\n",
            "Trainable params: 285,381\n",
            "Non-trainable params: 104\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6116 - accuracy: 0.1507 - val_loss: 0.6729 - val_accuracy: 0.1912\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.5849 - accuracy: 0.1448 - val_loss: 0.5415 - val_accuracy: 0.1251\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.5706 - accuracy: 0.1455 - val_loss: 0.5123 - val_accuracy: 0.1406\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.5491 - accuracy: 0.1711 - val_loss: 0.4595 - val_accuracy: 0.1969\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.5001 - accuracy: 0.2033 - val_loss: 0.4557 - val_accuracy: 0.1855\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.4351 - accuracy: 0.3532 - val_loss: 0.3553 - val_accuracy: 0.3549\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3894 - accuracy: 0.4422 - val_loss: 0.3174 - val_accuracy: 0.3772\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.3739 - accuracy: 0.4489 - val_loss: 0.2925 - val_accuracy: 0.4038\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.3513 - accuracy: 0.4632 - val_loss: 0.2340 - val_accuracy: 0.4424\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.2710 - accuracy: 0.5082 - val_loss: 0.1293 - val_accuracy: 0.5214\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.2294 - accuracy: 0.5107 - val_loss: 0.1318 - val_accuracy: 0.4395\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1974 - accuracy: 0.4773 - val_loss: 0.1055 - val_accuracy: 0.4469\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1846 - accuracy: 0.4732 - val_loss: 0.1140 - val_accuracy: 0.4486\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1768 - accuracy: 0.4657 - val_loss: 0.1160 - val_accuracy: 0.4179\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1597 - accuracy: 0.4512 - val_loss: 0.1345 - val_accuracy: 0.4346\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.4346\n",
            "sklearn_accuracy: 0.8503125\n",
            "\n",
            "(main) 12' population has been evaluated\n",
            "best individual: [[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]]\n",
            "statistics: {'min': 0.431125, 'max': 0.9046875, 'average': 0.7719921875}\n",
            "(main) 13' population initialized\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 6, 1, 2, 20, 3, 4, 2, 1, 14, 2, 2, 1, 2, 2, 15, 0.25, 14, 0.1, 16, 0.08]\n",
            "[5, 29, 6, 5, 2, 2, 4, 5, 3, 1, 2, 14, 7, 7, 1, 2, 24, 3, 6, 1, 1, 8, 5, 3, 1, 2, 1, 22, 0.38, 14, 0.13, 30, 0.08]\n",
            "[5, 26, 6, 4, 2, 2, 4, 5, 3, 2, 2, 14, 7, 3, 2, 2, 26, 3, 3, 2, 1, 8, 6, 3, 1, 2, 1, 20, 0.12, 13, 0.18, 28, 0.15]\n",
            "[5, 11, 4, 2, 1, 2, 20, 6, 2, 1, 1, 5, 3, 6, 2, 1, 17, 3, 6, 2, 1, 12, 4, 2, 1, 2, 2, 23, 0.17, 14, 0.05, 17, 0.14]\n",
            "[2, 29, 6, 4, 2, 1, 4, 5, 4, 1, 1, 14, 3, 3, 2, 1, 31, 5, 3, 2, 1, 8, 2, 7, 1, 2, 1, 20, 0.12, 13, 0.18, 28, 0.15]\n",
            "[1, 6, 6, 2, 1, 2, 15, 2, 7, 1, 1, 5, 7, 3, 2, 2, 31, 3, 3, 2, 1, 8, 6, 3, 1, 2, 1, 21, 0.12, 13, 0.26, 28, 0.15]\n",
            "[5, 6, 2, 2, 2, 1, 23, 6, 3, 1, 1, 10, 4, 7, 2, 2, 24, 4, 6, 2, 1, 9, 4, 7, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.39]\n"
          ]
        }
      ],
      "source": [
        "# main\n",
        "\n",
        "\n",
        "\n",
        "# ------ LOADING DATA\n",
        "\n",
        "#DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/4__thesis/Datasets/effected_5effects_reduced.json'\n",
        "\n",
        "def load_data(data_path):\n",
        "  with open(data_path, \"r\") as fp:\n",
        "      data = json.load(fp)\n",
        "  return data\n",
        "\n",
        "# ------\n",
        "\n",
        "\n",
        "POPULATION_SIZE = 8\n",
        "NUM_GENERATIONS = 12\n",
        "CROSSOVER_PROB = 0.8\n",
        "MUTATION_PROB = 0.3\n",
        "\n",
        "def main(verbose=True):\n",
        "\n",
        "  #data = load_data_pickle(PICKLE_PATH_ENTIRE_NAMES) - new 1/3\n",
        "\n",
        "  statistics_dict = {\n",
        "      \"best_individuals\":[],\n",
        "      \"min\":[],\n",
        "      \"max\":[],\n",
        "      \"average\":[]\n",
        "  }\n",
        "\n",
        "  # build the first population\n",
        "  population = initialize_first_population(POPULATION_SIZE, verbose=False)\n",
        "  if verbose:\n",
        "    print(\"(main) first population initialized\")\n",
        "    for indiv in population:\n",
        "      print(indiv)\n",
        "\n",
        "\n",
        "  # new - load data separated use strato for test phase\n",
        "  data_train = load_data_pickle(PICKLE_PATH_NO_STRAT_ENTIRE)\n",
        "  data_test = load_data_pickle(PICKLE_PATH_STRAT_ENTIRE)\n",
        "  \n",
        "  X_train, y_train = load_data_not_from_file(data_train)\n",
        "  X_test, y_test = load_data_not_from_file(data_test)\n",
        "  \n",
        "  X_train = X_train[..., np.newaxis]\n",
        "  X_test = X_test[..., np.newaxis]\n",
        "\n",
        "  data = (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "  del data_train\n",
        "  del data_test\n",
        "\n",
        "  #load dataset\n",
        "  #X_train, X_valid, X_test, y_train, y_valid, y_test = prepare_dataset_for_cnn(data, 0.2, 0.2) - new 2/3\n",
        "  #data = (X_train, y_train), (X_valid, y_valid) - new 3/3\n",
        "  \n",
        "  \n",
        "  if verbose:\n",
        "    print(\"\\n(main) dataset loaded\")\n",
        "    print(f\"X_train dimension: {np.shape(X_train)}\")\n",
        "\n",
        "  \n",
        "  # START WITH GENERATIONS\n",
        "  for generation in range(NUM_GENERATIONS):\n",
        "\n",
        "    # EVALUATE\n",
        "    \n",
        "    print(f\"\\n - GENERATION {generation+1}\\n\")\n",
        "\n",
        "    population_eval  = population_evaluation(population, data)\n",
        "\n",
        "    # save statistics\n",
        "    statistics_dict[\"best_individuals\"].append(population_eval['best_individual'][0])\n",
        "    statistics_dict[\"min\"].append(population_eval['statistics'][\"min\"])\n",
        "    statistics_dict[\"max\"].append(population_eval['statistics'][\"max\"])\n",
        "    statistics_dict[\"average\"].append(population_eval['statistics'][\"average\"])\n",
        "\n",
        "    # consider elitism - save best individual for next generation\n",
        "    survived_individual = population_eval['best_individual'][0].copy()\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"\\n(main) {generation+1}' population has been evaluated\")\n",
        "      print(f\"best individual: {population_eval['best_individual']}\")\n",
        "      print(f\"statistics: {population_eval['statistics']}\")\n",
        "\n",
        "    # NEW POPULATION - selection, crossover, mutation\n",
        "\n",
        "    new_population = []\n",
        "    new_population.append(survived_individual)\n",
        "\n",
        "    for i in range(POPULATION_SIZE - 1):\n",
        "      \n",
        "      # selection\n",
        "      individual_1, individual_2 = select_two_individuals(population_eval)\n",
        "\n",
        "      # crossover\n",
        "      crossed_individual = single_point_crossover(individual_1,individual_2, CROSSOVER_PROB)\n",
        "\n",
        "      # mutation\n",
        "      mutated_individual = mutation(crossed_individual, MUTATION_PROB)\n",
        "\n",
        "      # append to new population\n",
        "      new_population.append(mutated_individual)\n",
        "\n",
        "    population = new_population  # or new_population.copy() ?\n",
        "\n",
        "    print(f\"(main) {generation+2}' population initialized\")\n",
        "    for indiv in population:\n",
        "      print(indiv)\n",
        "\n",
        "  return statistics_dict\n",
        "\n",
        "\n",
        "statistics = main()\n",
        "\n",
        "\n",
        "statistics_path = '/content/drive/MyDrive/Colab Notebooks/4__thesis/models/statistics_6ott.json'\n",
        "with open(statistics_path, \"w\") as fp:\n",
        "    json.dump(statistics, fp, indent=4)\n",
        "\n",
        "#population_eval ={\n",
        "#      \"population\":[],\n",
        "#      \"fitness\":[],\n",
        "#      \"probability\":[],\n",
        "#      \"best_individual\": [],\n",
        "#      \"statistics\": {\"min\":0, \"max\":0, \"average\":0}\n",
        "#  }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "statistics_path = '/content/drive/MyDrive/Colab Notebooks/4__thesis/models/statistics_5ott.json'\n",
        "with open(statistics_path, \"r\") as fp:\n",
        "    stat_genetic = json.load(fp)"
      ],
      "metadata": {
        "id": "TJF5Wuggcdul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "m3EQ49gKdg2y",
        "outputId": "339f346e-e4c8-44fd-e58a-dfb2a40f0a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['best_individuals', 'min', 'max', 'average'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load ad plot statistics\n",
        "print(stat_genetic.keys())\n",
        "\n",
        "#print(statistics['average'])\n",
        "#print(statistics['best_individuals'])\n",
        "\n",
        "generations = list(range(1, 13))\n",
        "\n",
        "plt.plot(generations, stat_genetic['average'], label='average', marker='o')\n",
        "plt.plot(generations, stat_genetic['max'], label='max', marker='o')\n",
        "plt.plot(generations, stat_genetic['min'], label='min', marker='o')\n",
        "\n",
        "plt.xlabel('Generations')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Genetic Algorithms Optimization')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#savepath = \n",
        "plt.savefig()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GkBwpngDEgJ"
      },
      "source": [
        "IMPLEMENT BEST MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_indiv_1 = statistics['best_individuals'][-1]\n",
        "best_indiv_2 = statistics['best_individuals'][-2]\n",
        "\n",
        "print(best_indiv_1)\n",
        "print(best_indiv_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGr_QGjpPaTl",
        "outputId": "d1a45b91-345e-4696-cbda-dbfadc049314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 2, 2, 2, 1, 23, 6, 3, 1, 1, 10, 4, 7, 2, 2, 24, 4, 6, 2, 1, 9, 4, 7, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.39]\n",
            "[5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvFmVZhzDEO1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2Q6aPpQGJuz"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48sd0nTcDigg"
      },
      "outputs": [],
      "source": [
        "# build and compile the model\n",
        "def build_and_compile_model(indiv, input_shape):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # create first conv layer + pooling layer\n",
        "  model.add(keras.layers.Conv2D(filters=indiv[1], kernel_size=(indiv[2], indiv[3]), input_shape=input_shape, activation='relu', padding='same'))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=(indiv[4], indiv[5]), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # create other conv layers + pooling layers\n",
        "  remain_conv_layer = indiv[0] - 1\n",
        "  for i in range(6, 6 + remain_conv_layer * 4, 5):\n",
        "    model.add(keras.layers.Conv2D(filters=indiv[i], kernel_size=(indiv[i+1], indiv[i+2]), activation='relu', padding='same'))\n",
        "    #model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "    \n",
        "  # flatten\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  # create dense layers + dropout\n",
        "  dense_layers = indiv[26]  # how many dense layers we have\n",
        "  for j in range(27, 27 + dense_layers * 2, 2):\n",
        "    model.add(keras.layers.Dense(units=indiv[j], activation='relu'))\n",
        "    model.add(keras.layers.Dropout(indiv[j+1]))\n",
        "\n",
        "  # add final layer\n",
        "  model.add(keras.layers.Dense(units=5, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCUaSZ0ra7iH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_dataset_for_guitar_cross_validation(data, test_guitar = 'strato'):\n",
        "\n",
        "    # 64000 segments in total2\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    N_test = []\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    N_train = []\n",
        "    \n",
        "    count_test = 0\n",
        "    count_train = 0\n",
        "    \n",
        "    # i goes from 0 to 63999\n",
        "    for i, name in enumerate(data['names']):\n",
        "      if name[:3] == test_guitar[:3]:   \n",
        "        \n",
        "        X_test.append(data['spectrogram'][i])\n",
        "        y_test.append(data['labels'][i])\n",
        "        N_test.append(data['names'][i])\n",
        "        count_test += 1\n",
        "\n",
        "      else:\n",
        "\n",
        "        X_train.append(data['spectrogram'][i])\n",
        "        y_train.append(data['labels'][i])\n",
        "        N_train.append(data['names'][i])\n",
        "        count_train += 1\n",
        "\n",
        "    print(f'train set: {count_train}')\n",
        "    print(f'test set: {count_test} (guitar: {test_guitar})')\n",
        "\n",
        "\n",
        "    # from list to numpy array \n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "    # add 3rd dimension\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, N_train, N_test\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'tele')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBnSHs-sBwyA"
      },
      "outputs": [],
      "source": [
        "# load statistics\n",
        "\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data\n",
        "  \n",
        "statistics_path = '/content/drive/MyDrive/Colab Notebooks/4__thesis/models/statistics_5ott.json'\n",
        "\n",
        "with open(statistics_path, 'r') as f:\n",
        "  statistics = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rTtSEciqtar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "888f3a5d-cb01-426b-cadf-48bd2e688f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: tele)\n",
            "max value obtained is: 0.905\n",
            "best individual is:\n",
            " [5, 6, 4, 2, 1, 1, 19, 6, 3, 1, 1, 9, 4, 7, 1, 2, 22, 4, 6, 2, 1, 8, 4, 2, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.29]\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_25 (Conv2D)          (None, 87, 128, 6)        30        \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 44, 128, 6)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 44, 128, 6)       24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 44, 128, 23)       2507      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 44, 128, 23)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 44, 128, 23)      92        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 44, 128, 10)       6450      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 22, 64, 10)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 22, 64, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 22, 64, 24)        5784      \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 11, 64, 24)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 11, 64, 24)       96        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 11, 64, 9)         6057      \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 11, 64, 9)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 11, 64, 9)        36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 6336)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 21)                133077    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 21)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 154,303\n",
            "Trainable params: 154,159\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.6347 - accuracy: 0.1103 - val_loss: 0.5430 - val_accuracy: 0.1244\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.5339 - accuracy: 0.1368 - val_loss: 0.4625 - val_accuracy: 0.2189\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.4726 - accuracy: 0.1388 - val_loss: 0.4250 - val_accuracy: 0.1977\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.4143 - accuracy: 0.1841 - val_loss: 0.3397 - val_accuracy: 0.2313\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3684 - accuracy: 0.2446 - val_loss: 0.3550 - val_accuracy: 0.2485\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3545 - accuracy: 0.2319 - val_loss: 0.3160 - val_accuracy: 0.2444\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3357 - accuracy: 0.2508 - val_loss: 0.2927 - val_accuracy: 0.2328\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2996 - accuracy: 0.2567 - val_loss: 0.2485 - val_accuracy: 0.2299\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2558 - accuracy: 0.2727 - val_loss: 0.2240 - val_accuracy: 0.2943\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2415 - accuracy: 0.2821 - val_loss: 0.2040 - val_accuracy: 0.2743\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2266 - accuracy: 0.2829 - val_loss: 0.2102 - val_accuracy: 0.2582\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2065 - accuracy: 0.2937 - val_loss: 0.2124 - val_accuracy: 0.2620\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1985 - accuracy: 0.2974 - val_loss: 0.2233 - val_accuracy: 0.3071\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1964 - accuracy: 0.3021 - val_loss: 0.1925 - val_accuracy: 0.2868\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1944 - accuracy: 0.3022 - val_loss: 0.2314 - val_accuracy: 0.3145\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 3s 5ms/step - loss: 0.2314 - accuracy: 0.3145\n",
            "test_accuracy: 0.31450000405311584\n",
            "sklearn accuracy:  0.506125\n"
          ]
        }
      ],
      "source": [
        "# destroy previous data to free space\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# load entire dataset\n",
        "data_complete = load_data_pickle(PICKLE_PATH_ENTIRE_NAMES)\n",
        "\n",
        "# new - test with 1 guitar as test set (ex: tele)\n",
        "X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'tele')\n",
        "del data_complete\n",
        "\n",
        "# implement the best model found\n",
        "best_index = np.argmax(statistics['max'])\n",
        "print('max value obtained is:', statistics['max'][best_index])\n",
        "best_individual = statistics[\"best_individuals\"][best_index]\n",
        "print(\"best individual is:\\n\", best_individual)\n",
        "\n",
        "# obtained looking at the optimiz process.. few parameters\n",
        "best_individual = [5, 11, 4, 2, 1, 2, 20, 6, 2, 1, 1, 5, 4, 6, 2, 1, 17, 2, 6, 2, 2, 12, 4, 2, 1, 2, 2, 15, 0.25, 18, 0.09, 16, 0.09]\n",
        "\n",
        "# second best of the optimization\n",
        "second_best_individual = [5, 6, 2, 2, 2, 1, 23, 6, 3, 1, 1, 10, 4, 7, 2, 2, 24, 4, 6, 2, 1, 9, 4, 7, 1, 1, 1, 21, 0.18, 6, 0.14, 12, 0.39]\n",
        "#best_individual_example = [3, 15, 5, 7, 2, 2, 6, 2, 6, 1, 2, 15, 4, 6, 1, 1, 35, 7, 3, 2, 2, 29, 3, 6, 1, 2, 1, 40, 0.16, 55, 0.37, 8, 0.36]\n",
        "\n",
        "input_shape = np.shape(X_train[1])\n",
        "best_model = build_and_compile_model(second_best_individual, input_shape)\n",
        "history = best_model.fit(X_train, y_train, epochs = 15, batch_size=64, validation_data = (X_test, y_test))\n",
        "plot_history(history)\n",
        "\n",
        "# evaluate on test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"test_accuracy:\", test_accuracy)\n",
        "\n",
        "# manual accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred = y_pred.round()\n",
        "sklearn_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"sklearn accuracy: \", sklearn_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJKsWB_6n4jg"
      },
      "outputs": [],
      "source": [
        "#data_strat = load_data_pickle(PICKLE_PATH_STRAT_RED)\n",
        "#X_strat, y_strat = load_data_not_from_file(data_strat)\n",
        "\n",
        "\n",
        "def which_class_wrong(y_pred, y_strat):\n",
        "  errors_dict = {\n",
        "      \"overdrive\": 0,\n",
        "      \"chorus\": 0,\n",
        "      \"tremolo\": 0,\n",
        "      \"delay\": 0,\n",
        "      \"reverb\": 0\n",
        "  }\n",
        "\n",
        "  for i, (pred, true) in enumerate(zip(y_pred, y_strat)):\n",
        "    #print(f\"{i+1} ) pred: {pred}, true: {true}\")\n",
        "\n",
        "    if pred[0] != true[0]:\n",
        "      errors_dict[\"overdrive\"] += 1\n",
        "    if pred[1] != true[1]:\n",
        "      errors_dict[\"chorus\"] += 1\n",
        "    if pred[2] != true[2]:\n",
        "      errors_dict[\"tremolo\"] += 1\n",
        "    if pred[3] != true[3]:\n",
        "      errors_dict[\"delay\"] += 1\n",
        "    if pred[4] != true[4]:\n",
        "      errors_dict[\"reverb\"] += 1\n",
        "\n",
        "  #error_list = [errors_dict[curren_effect] for curren_effect in errors_dict.keys()]\n",
        "\n",
        "  return errors_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new - want to consider the other effects when dealing with effects errors\n",
        "# ex: when delay fails knowing which other effects fail \n",
        "\n",
        "def which_class_wrong_when_overdrive_wrong(y_pred, y_strat):\n",
        "  errors_when_overdrive_wrong = {\n",
        "      #\"overdrive\": 0,\n",
        "      \"chorus\": 0,\n",
        "      \"tremolo\": 0,\n",
        "      \"delay\": 0,\n",
        "      \"reverb\": 0\n",
        "  }\n",
        "\n",
        "  for i, (pred, true) in enumerate(zip(y_pred, y_strat)):\n",
        "    #print(f\"{i+1} ) pred: {pred}, true: {true}\")\n",
        "\n",
        "    if pred[0] != true[0]:\n",
        "      errors_when_overdrive_wrong[\"overdrive\"] += 1\n",
        "      if pred[1] != true[1]:\n",
        "        errors_when_overdrive_wrong[\"chorus\"] += 1\n",
        "      if pred[2] != true[2]:\n",
        "        errors_when_overdrive_wrong[\"tremolo\"] += 1\n",
        "      if pred[3] != true[3]:\n",
        "        errors_when_overdrive_wrong[\"delay\"] += 1\n",
        "      if pred[4] != true[4]:\n",
        "        errors_when_overdrive_wrong[\"reverb\"] += 1\n",
        "\n",
        "  #error_list = [errors_dict[curren_effect] for curren_effect in errors_dict.keys()]\n",
        "\n",
        "  return errors_when_overdrive_wrong\n",
        "\n",
        "\n",
        "  # da fare: aggiungi questa funzione durante \"evaluate_model_no_start\" per vedere \n",
        "  # che correlazione c'è fra errore su overdr. e altri effetti\n",
        "   "
      ],
      "metadata": {
        "id": "uk79rnJwL6RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXTZyybShjUQ",
        "outputId": "11386c4a-8f39-436d-a27d-71058b714213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: les)\n",
            "input shape: (87, 128, 1)\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_80 (Conv2D)          (None, 87, 128, 11)       99        \n",
            "                                                                 \n",
            " max_pooling2d_80 (MaxPoolin  (None, 87, 64, 11)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_80 (Bat  (None, 87, 64, 11)       44        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 87, 64, 20)        2660      \n",
            "                                                                 \n",
            " max_pooling2d_81 (MaxPoolin  (None, 87, 64, 20)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_81 (Bat  (None, 87, 64, 20)       80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 87, 64, 5)         2405      \n",
            "                                                                 \n",
            " max_pooling2d_82 (MaxPoolin  (None, 44, 64, 5)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_82 (Bat  (None, 44, 64, 5)        20        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 44, 64, 17)        1037      \n",
            "                                                                 \n",
            " max_pooling2d_83 (MaxPoolin  (None, 22, 32, 17)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_83 (Bat  (None, 22, 32, 17)       68        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 22, 32, 12)        1644      \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 22, 16, 12)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_84 (Bat  (None, 22, 16, 12)       48        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 15)                63375     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 18)                288       \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 18)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 5)                 95        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71,863\n",
            "Trainable params: 71,733\n",
            "Non-trainable params: 130\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 29s 37ms/step - loss: 0.4469 - accuracy: 0.3090 - val_loss: 0.2437 - val_accuracy: 0.3430\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2470 - accuracy: 0.4696 - val_loss: 0.1359 - val_accuracy: 0.5296\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1847 - accuracy: 0.5440 - val_loss: 0.0995 - val_accuracy: 0.5307\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1588 - accuracy: 0.5574 - val_loss: 0.1019 - val_accuracy: 0.5869\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1432 - accuracy: 0.5543 - val_loss: 0.0831 - val_accuracy: 0.5442\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1346 - accuracy: 0.5531 - val_loss: 0.1306 - val_accuracy: 0.6438\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1229 - accuracy: 0.5497 - val_loss: 0.0926 - val_accuracy: 0.4801\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1136 - accuracy: 0.5562 - val_loss: 0.1050 - val_accuracy: 0.5538\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1113 - accuracy: 0.5532 - val_loss: 0.1096 - val_accuracy: 0.4785\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1075 - accuracy: 0.5617 - val_loss: 0.0822 - val_accuracy: 0.5326\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1021 - accuracy: 0.5588 - val_loss: 0.1785 - val_accuracy: 0.5922\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1017 - accuracy: 0.5650 - val_loss: 0.0933 - val_accuracy: 0.6518\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0972 - accuracy: 0.5799 - val_loss: 0.0723 - val_accuracy: 0.5897\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0976 - accuracy: 0.5905 - val_loss: 0.2240 - val_accuracy: 0.6947\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0940 - accuracy: 0.6033 - val_loss: 0.1298 - val_accuracy: 0.6749\n",
            "manual accuracy:  0.86825\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_85 (Conv2D)          (None, 87, 128, 11)       99        \n",
            "                                                                 \n",
            " max_pooling2d_85 (MaxPoolin  (None, 87, 64, 11)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_85 (Bat  (None, 87, 64, 11)       44        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 87, 64, 20)        2660      \n",
            "                                                                 \n",
            " max_pooling2d_86 (MaxPoolin  (None, 87, 64, 20)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_86 (Bat  (None, 87, 64, 20)       80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 87, 64, 5)         2405      \n",
            "                                                                 \n",
            " max_pooling2d_87 (MaxPoolin  (None, 44, 64, 5)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_87 (Bat  (None, 44, 64, 5)        20        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 44, 64, 17)        1037      \n",
            "                                                                 \n",
            " max_pooling2d_88 (MaxPoolin  (None, 22, 32, 17)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_88 (Bat  (None, 22, 32, 17)       68        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 22, 32, 12)        1644      \n",
            "                                                                 \n",
            " max_pooling2d_89 (MaxPoolin  (None, 22, 16, 12)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_89 (Bat  (None, 22, 16, 12)       48        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 15)                63375     \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 18)                288       \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 18)                0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 5)                 95        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71,863\n",
            "Trainable params: 71,733\n",
            "Non-trainable params: 130\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.5277 - accuracy: 0.2030 - val_loss: 0.3491 - val_accuracy: 0.1866\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3705 - accuracy: 0.2389 - val_loss: 0.2560 - val_accuracy: 0.2377\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2850 - accuracy: 0.2675 - val_loss: 0.2144 - val_accuracy: 0.2621\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2437 - accuracy: 0.2630 - val_loss: 0.1885 - val_accuracy: 0.2696\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2109 - accuracy: 0.2549 - val_loss: 0.1743 - val_accuracy: 0.2559\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1821 - accuracy: 0.2471 - val_loss: 0.1229 - val_accuracy: 0.2107\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1560 - accuracy: 0.2459 - val_loss: 0.0977 - val_accuracy: 0.2125\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1417 - accuracy: 0.2544 - val_loss: 0.1138 - val_accuracy: 0.2272\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1334 - accuracy: 0.2576 - val_loss: 0.1186 - val_accuracy: 0.2301\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1184 - accuracy: 0.2616 - val_loss: 0.0875 - val_accuracy: 0.2190\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1131 - accuracy: 0.2619 - val_loss: 0.1363 - val_accuracy: 0.2426\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1107 - accuracy: 0.2635 - val_loss: 0.1112 - val_accuracy: 0.2139\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1052 - accuracy: 0.2784 - val_loss: 0.1608 - val_accuracy: 0.2469\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1001 - accuracy: 0.2803 - val_loss: 0.1327 - val_accuracy: 0.2260\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0943 - accuracy: 0.2775 - val_loss: 0.1050 - val_accuracy: 0.2216\n",
            "manual accuracy:  0.8815\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_90 (Conv2D)          (None, 87, 128, 11)       99        \n",
            "                                                                 \n",
            " max_pooling2d_90 (MaxPoolin  (None, 87, 64, 11)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_90 (Bat  (None, 87, 64, 11)       44        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 87, 64, 20)        2660      \n",
            "                                                                 \n",
            " max_pooling2d_91 (MaxPoolin  (None, 87, 64, 20)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 87, 64, 20)       80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_92 (Conv2D)          (None, 87, 64, 5)         2405      \n",
            "                                                                 \n",
            " max_pooling2d_92 (MaxPoolin  (None, 44, 64, 5)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_92 (Bat  (None, 44, 64, 5)        20        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 44, 64, 17)        1037      \n",
            "                                                                 \n",
            " max_pooling2d_93 (MaxPoolin  (None, 22, 32, 17)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 22, 32, 17)       68        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 22, 32, 12)        1644      \n",
            "                                                                 \n",
            " max_pooling2d_94 (MaxPoolin  (None, 22, 16, 12)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 22, 16, 12)       48        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 15)                63375     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 18)                288       \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 18)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 5)                 95        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71,863\n",
            "Trainable params: 71,733\n",
            "Non-trainable params: 130\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.5412 - accuracy: 0.1851 - val_loss: 0.4065 - val_accuracy: 0.2371\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3429 - accuracy: 0.3058 - val_loss: 0.1670 - val_accuracy: 0.2737\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.2398 - accuracy: 0.3039 - val_loss: 0.1387 - val_accuracy: 0.3101\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1827 - accuracy: 0.2992 - val_loss: 0.1398 - val_accuracy: 0.3003\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1497 - accuracy: 0.2936 - val_loss: 0.1614 - val_accuracy: 0.2475\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1386 - accuracy: 0.2836 - val_loss: 0.0668 - val_accuracy: 0.2312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1270 - accuracy: 0.2810 - val_loss: 0.1133 - val_accuracy: 0.2518\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1136 - accuracy: 0.2882 - val_loss: 0.1091 - val_accuracy: 0.2492\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1043 - accuracy: 0.2863 - val_loss: 0.1346 - val_accuracy: 0.2352\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1000 - accuracy: 0.2854 - val_loss: 0.1250 - val_accuracy: 0.2260\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0963 - accuracy: 0.2813 - val_loss: 0.1010 - val_accuracy: 0.2099\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0939 - accuracy: 0.2798 - val_loss: 0.2233 - val_accuracy: 0.2199\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0905 - accuracy: 0.2802 - val_loss: 0.1276 - val_accuracy: 0.2441\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0889 - accuracy: 0.2759 - val_loss: 0.1251 - val_accuracy: 0.2624\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0876 - accuracy: 0.2850 - val_loss: 0.1087 - val_accuracy: 0.2600\n",
            "manual accuracy:  0.8368125\n"
          ]
        }
      ],
      "source": [
        "def load_data_not_from_file(data):\n",
        "    X = np.array(data[\"spectrogram\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def calculate_mean_std_class_errors(list_of_dict):\n",
        "  over = []\n",
        "  chor = []\n",
        "  trem = []\n",
        "  dela = []\n",
        "  reve = []\n",
        "\n",
        "  for dic in list_of_dict:\n",
        "    over.append(dic[\"overdrive\"])\n",
        "    chor.append(dic[\"chorus\"])\n",
        "    trem.append(dic[\"tremolo\"])\n",
        "    dela.append(dic[\"delay\"])\n",
        "    reve.append(dic[\"reverb\"])\n",
        "\n",
        "  mean_dict = {\n",
        "      \"over_mean\": np.mean(over),\n",
        "      \"chor_mean\": np.mean(chor),\n",
        "      \"trem_mean\": np.mean(trem),\n",
        "      \"dela_mean\": np.mean(dela),\n",
        "      \"reve_mean\": np.mean(reve)\n",
        "  }\n",
        "  std_dict = {\n",
        "      \"over_std\": np.std(over),\n",
        "      \"chor_std\": np.std(chor),\n",
        "      \"trem_std\": np.std(trem),\n",
        "      \"dela_std\": np.std(dela),\n",
        "      \"reve_std\": np.std(reve)\n",
        "  }\n",
        "  return mean_dict, std_dict\n",
        "  \n",
        "\n",
        "\n",
        "# train model without starto data reduced\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#best_indiv_example = [3, 15, 5, 7, 2, 2, 6, 2, 6, 1, 2, 15, 4, 6, 1, 1, 35, 7, 3, 2, 2, 29, 3, 6, 1, 2, 1, 40, 0.16, 55, 0.37, 8, 0.36]\n",
        "best_individual_few_param_5ott = [5, 11, 4, 2, 1, 2, 20, 6, 2, 1, 1, 5, 4, 6, 2, 1, 17, 2, 6, 2, 2, 12, 4, 2, 1, 2, 2, 15, 0.25, 18, 0.09, 16, 0.09]\n",
        "\n",
        "def evaluate_model_no_start(best_individual, test_guitar, repetitions=4):\n",
        "  \n",
        "  statistics = {\n",
        "      \"manual_accuracy\": [],\n",
        "      \"class_errors\": [],\n",
        "      \"class_errors_mean\": 0,\n",
        "      \"class_errors_std\": 0,\n",
        "      \"accuracy_mean\": 0,\n",
        "      \"accuracy_std\": 0,\n",
        "  }\n",
        "\n",
        "  # load data as X, y\n",
        "  # data_no_strat = load_data_pickle(path_no_strat)\n",
        "  # data_strat = load_data_pickle(path_strat)\n",
        "\n",
        "  # X_no_strat, y_no_strat = load_data_not_from_file(data_no_strat)\n",
        "  # X_strat, y_strat = load_data_not_from_file(data_strat)\n",
        "\n",
        "  # X_no_strat = X_no_strat[..., np.newaxis]\n",
        "  # X_strat = X_strat[..., np.newaxis]\n",
        "\n",
        "  # new \n",
        "  # load entire dataset\n",
        "  data_complete = load_data_pickle(PICKLE_PATH_ENTIRE_NAMES)\n",
        "\n",
        "  # new - test with 1 guitar as test set (ex: tele)\n",
        "  X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, test_guitar)\n",
        "  del data_complete\n",
        "\n",
        "\n",
        "  input_shape = np.shape(X_train[0])\n",
        "  print(f\"input shape: {input_shape}\")\n",
        "\n",
        "  # delete data to free memory\n",
        "  # del data_no_strat\n",
        "  # del data_strat\n",
        "  # gc.collect()\n",
        "\n",
        "  for i in range(repetitions):\n",
        "    \n",
        "    gc.collect()\n",
        "    # build, train, evaluate model\n",
        "    \n",
        "    model = build_and_compile_model(best_individual, input_shape)\n",
        "    history = model.fit(X_train, y_train, epochs = 15, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # manual accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = y_pred.round()\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"manual accuracy: \", accuracy)\n",
        "\n",
        "    # how many wrong labels for each class\n",
        "    class_errors_dict = which_class_wrong(y_test, y_pred)\n",
        "\n",
        "    statistics[\"class_errors\"].append(class_errors_dict)\n",
        "    statistics[\"manual_accuracy\"].append(accuracy)\n",
        "  statistics[\"accuracy_mean\"] = np.mean(statistics[\"manual_accuracy\"])\n",
        "  statistics[\"accuracy_std\"] = np.std(statistics[\"manual_accuracy\"])\n",
        "\n",
        "  # gest statistics of class errors\n",
        "  class_mean, class_std = calculate_mean_std_class_errors(statistics[\"class_errors\"])\n",
        "  statistics[\"class_errors_mean\"] = class_mean\n",
        "  statistics[\"class_errors_std\"] = class_std\n",
        "\n",
        "\n",
        "  return statistics\n",
        "\n",
        "statistics = evaluate_model_no_start(best_individual=best_individual_few_param_5ott, test_guitar='les', repetitions=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpMNcXjYsHKv",
        "outputId": "8a683e29-c715-494c-a58a-8c284e616cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'manual_accuracy': [0.86825, 0.8815, 0.8368125], 'class_errors': [{'overdrive': 989, 'chorus': 106, 'tremolo': 165, 'delay': 989, 'reverb': 52}, {'overdrive': 777, 'chorus': 54, 'tremolo': 105, 'delay': 930, 'reverb': 131}, {'overdrive': 557, 'chorus': 95, 'tremolo': 171, 'delay': 1850, 'reverb': 69}], 'class_errors_mean': {'over_mean': 774.3333333333334, 'chor_mean': 85.0, 'trem_mean': 147.0, 'dela_mean': 1256.3333333333333, 'reve_mean': 84.0}, 'class_errors_std': {'over_std': 176.3733413970364, 'chor_std': 22.37558192911788, 'trem_std': 29.79932885150268, 'dela_std': 420.4761850833198, 'reve_std': 33.95094500402996}, 'accuracy_mean': 0.8621875, 'accuracy_std': 0.01874048369617675}\n"
          ]
        }
      ],
      "source": [
        "guitar_name = 'les'\n",
        "accuracies_path = '/content/drive/MyDrive/Colab Notebooks/4__thesis/models/statistics_' + guitar_name + '.json'\n",
        "\n",
        "with open(accuracies_path, 'w') as fp:\n",
        "  json.dump(statistics, fp, indent=4)\n",
        "\n",
        "print(statistics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "akxR2ytXM_U7",
        "outputId": "dae1e93e-1830-45ec-c751-f710bec6f730"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot\n",
        "tot_tes_set = 16000\n",
        "labels = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "values = list(statistics['class_errors_mean'].values())\n",
        "values = np.array(values)\n",
        "values_normalized = values / tot_tes_set\n",
        "\n",
        "bars = plt.bar(labels, values_normalized)\n",
        "plt.ylabel('mean error')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpjFO2stiMEm"
      },
      "outputs": [],
      "source": [
        "# # implement 5-fold cross-validation\n",
        "# from sklearn.model_selection import RepeatedKFold\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# N_SPLITS = 5\n",
        "\n",
        "# best_indiv_example = [3, 15, 5, 7, 2, 2, 6, 2, 6, 1, 2, 15, 4, 6, 1, 1, 35, 7, 3, 2, 2, 29, 3, 6, 1, 2, 1, 40, 0.16, 55, 0.37, 8, 0.36]\n",
        "\n",
        "\n",
        "# def evaluate_model_with_statistics(data_path, best_individual):\n",
        "#   accuracy_list = []\n",
        "\n",
        "#   # load data as X, y\n",
        "#   data = load_data_pickle(data_path)\n",
        "#   X, y = load_data_not_from_file(data)\n",
        "\n",
        "#   # delete data to free memory\n",
        "#   del data\n",
        "#   gc.collect()\n",
        "\n",
        "#   # create splits for 5-fold cross-validation\n",
        "#   cv = RepeatedKFold(n_splits=N_SPLITS, n_repeats=1, random_state=10)\n",
        "\n",
        "#   # cv.split(X) returns a generator that returns indices of train and test set\n",
        "#   # es: 1' iteration could return a tuple: ([0, 1, 3, 4, 5, 7], [2, 6]) ..are numpy arrays\n",
        "#   for train_index, test_index in cv.split(X):\n",
        "#     X_train, X_test = X[train_index], X[test_index]\n",
        "#     y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#     # add new dimension to feed the CNN\n",
        "#     X_train = X_train[..., np.newaxis]\n",
        "#     X_test = X_test[..., np.newaxis]\n",
        "\n",
        "#     # build compile and train the model\n",
        "#     gc.collect()\n",
        "#     input_shape = np.shape(X_train[0])\n",
        "#     model = build_and_compile_model(best_individual, input_shape)\n",
        "#     model.fit(X_train, y_train, epochs = 15, batch_size=40)\n",
        "\n",
        "#     # make predictions and round\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     y_pred = y_pred.round()\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     print(f\"current accuracy: %.2f:\" % accuracy)\n",
        "\n",
        "#     accuracy_list.append(accuracy)\n",
        "    \n",
        "  \n",
        "#   accuracy_mean = np.mean(accuracy_list)\n",
        "#   accuracy_std = np.std(accuracy_list)\n",
        "\n",
        "#   return accuracy_mean, accuracy_std, accuracy_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzpiJuNeuyYk"
      },
      "outputs": [],
      "source": [
        "#accuracy_mean, accuracy_std, accuracy_list = evaluate_model_with_statistics(PICKLE_PATH_ENTIRE_NAMES_SEGM, best_indiv_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9hllHOgyTrL",
        "outputId": "bb116e97-806f-4c92-e983-0ef18c9e4bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9591093749999999 0.026716310195623028\n",
            "[0.963515625, 0.965234375, 0.978125, 0.981171875, 0.9075]\n"
          ]
        }
      ],
      "source": [
        "# # accuracy_mean, accuracy_std, accuracy_list\n",
        "# print(accuracy_mean, accuracy_std)\n",
        "# print(accuracy_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELABORATE RESULTS"
      ],
      "metadata": {
        "id": "qMaFFR1oJ15K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLhHy6MqJ00T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1beW3egT2P9TUk4NN4A8YrPq7Px0hTmHA",
      "authorship_tag": "ABX9TyNFI5RrcF6Q+rFua3f5JHcY",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}